{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saidineshpola/detectron2/blob/main/Copy_of_queryInst_for_testing_mmdet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EokzqTToqttr"
      },
      "source": [
        "![AIcrowd-Logo](https://raw.githubusercontent.com/AIcrowd/AIcrowd/master/app/assets/images/misc/aicrowd-horizontal.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57cc_H7z-N0o"
      },
      "source": [
        "# üçï Food Recognition Benchmark\n",
        "\n",
        "\n",
        "# Problem Statement\n",
        "Detecting & Segmenting various kinds of food from an image. For ex. Someone got into new restaurent and get a food that he has never seen, well our DL model is in rescue, so our DL model will help indentifying which food it is from the class our model is being trained on!    \n",
        "\n",
        "<img src=\"https://i.imgur.com/zS2Nbf0.png\" width=\"300\" />\n",
        "\n",
        "\n",
        "# Dataset\n",
        "We will be using data from Food Recognition Challenge - A benchmark for image-based food recognition challange which is running since 2020.\n",
        "\n",
        "\n",
        "https://www.aicrowd.com/challenges/food-recognition-benchmark-2022#datasets\n",
        "\n",
        "We have a total of **39k training images** with **3k validation set** and **4k public-testing set**. All the images are RGB and annotations exist in **MS-COCO format**. \n",
        "\n",
        "<img src=\"https://lh5.googleusercontent.com/iySoTCAHFoEKxjvzELzCJKbZaTG2TzMcjuBxAlBVGupjkpE_XI1xNPnE71UIBthTu9_fZ4A1tz-ArABpI0DD2ZeF87qHPccRogEezd-UbhkQgZcQBYCE1HMeDusaKtj8ClCWjw-p\">\n",
        "\n",
        "<small>Reference: This notebook is based on the notebook created by [Shraddhaa Mohan](https://www.linkedin.com/in/shraddhaa-mohan-20a008185/) and [Rohit Midha](https://www.linkedin.com/in/rohitmidha/) for previous iteration of the challenge. You can find the [original notebook here](https://colab.research.google.com/drive/1vKAQ9D3dgubbBc2jGYGQB0-lZXlT8hTh#scrollTo=Dha6_NXmIzB9).</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhuIg5-yqtt2"
      },
      "source": [
        "In this Notebook, we will first do an analysis of the Food Recognition Dataset and then use maskrcnn for training on the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piyKwiK0qtt6"
      },
      "source": [
        "## The Challenge\n",
        "\n",
        "\n",
        "*   Given Images of Food, we are asked to provide Instance Segmentation over the images for the food items.\n",
        "*   The Training Data is provided in the COCO format, making it simpler to load with pre-available COCO data processors in popular libraries.\n",
        "*   The test set provided in the public dataset is similar to Validation set, but with no annotations.\n",
        "*   The test set after submission is much larger and contains private images upon which every submission is evaluated.\n",
        "*   Pariticipants have to submit their trained model along with trained weights. Immediately after the submission the AICrowd Grader picks up the submitted model and produces inference on the private test set using Cloud GPUs.\n",
        "*   This requires Users to structure their repositories and follow a provided paradigm for submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd3Gi0g5qtuE"
      },
      "source": [
        "## The Notebook\n",
        "> *  Installation of MMDetection\n",
        "> *  Training a simple model with MMDetection\n",
        "> *  Local Evaluation/Quick Submision using MMDetection\n",
        "> * Active Submission using trained model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l2EucOyJL3u"
      },
      "source": [
        "# GPU Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx5Yb4oKRpkK"
      },
      "source": [
        "Do a quick check if you have been allocated a GPU. \n",
        "\n",
        "If this command fails for you, please go to `Runtime` -> `Change Runtime Type` -> `Hardware Accelerator` -> `GPU`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H0j5oHHMNUd",
        "outputId": "768f4bc1-bb79-4ae5-923c-3850d7827dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  2 17:54:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sahi slicing"
      ],
      "metadata": {
        "id": "1mkhMNC8yvlb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO4MYQ3OwiI-",
        "outputId": "70261614-be56-45f5-d9e6-178ae331797a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       26696420 kB\n"
          ]
        }
      ],
      "source": [
        "!grep MemTotal /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwDa7_wkVQhK"
      },
      "source": [
        "# Setting our Workspace üíº\n",
        "\n",
        "In this section we will be downloading our dataset, unzipping it & downloading mmdetection repo/library and importing all libraries that we will be using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXhfQ9xp-aJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506d1d6e-3c27-49e0-dc41-e55816714370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[33mGitlab oauth token invalid or absent.\n",
            "It is highly recommended to simply run `aicrowd login` without passing the API Key.\u001b[0m\n",
            "\u001b[32mSaved details successfully!\u001b[0m\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Login to AIcrowd\n",
        "!pip install aicrowd-cli > /dev/null\n",
        "#!aicrowd login\n",
        "\n",
        "########## or ################\n",
        "# Get your API key from https://www.aicrowd.com/participants/me\n",
        "API_KEY = \"61a473a8ff6ff34c77e7f9f8544ef7dd\"\n",
        "!aicrowd login --api-key $API_KEY\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRdC5yyd-c0N"
      },
      "outputs": [],
      "source": [
        "# List dataset for this challenge\n",
        "!aicrowd dataset list -c food-recognition-benchmark-2022\n",
        "\n",
        "# Download dataset\n",
        "!aicrowd dataset download -c food-recognition-benchmark-2022 6 # 4  7  #6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTwjnrWz-igm"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/ data/train data/val data/test\n",
        "!echo \"Extracting test dataset\" && tar -xvf public_test_release_2.1.tar.gz -C data/test  > /dev/null\n",
        "!echo \"Extracting val dataset\" && tar -xvf public_validation_set_release_2.1.tar.gz -C data/val  > /dev/null\n",
        "!echo \"Extracting train dataset\" && tar -xvf public_training_set_release_2.1.tar.gz -C data/train  > /dev/null\n",
        "!rm -r *.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sahi stuff"
      ],
      "metadata": {
        "id": "R8FnduUvr3r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Author: Gaurav Singhal\n",
        "'''\n",
        "\n",
        "import json\n",
        "import cv2\n",
        "from pycocotools import coco, mask\n",
        "import pycocotools.mask as maskUtils\n",
        "import tqdm\n",
        "\n",
        "# +\n",
        "def read_annotation(ann_path: str):\n",
        "    '''\n",
        "    Read the annotations\n",
        "    '''\n",
        "    \n",
        "    with open(ann_path, \"r\") as f:\n",
        "        annotations = json.load(f)\n",
        "    return annotations\n",
        "\n",
        "def reset_image_dims(images: list, image_path: str):\n",
        "    '''\n",
        "    Reset the image height and width in the annotations with original \n",
        "    image dimension\n",
        "    '''\n",
        "    for i in range(len(images)):\n",
        "        dim_tup = cv2.imread(f\"{image_path}/{images[i]['file_name']}\").shape\n",
        "        images[i]['height'], images[i]['width'] = dim_tup[0], dim_tup[1]\n",
        "    return images\n",
        "\n",
        "def preprocess_images(annotations: dict, image_path: str):\n",
        "    '''\n",
        "    1. Remove the bad images which have rotated annotations\n",
        "    2. Reset the image height and width in the annotations with original \n",
        "    image dimension\n",
        "    '''\n",
        "    useless = []\n",
        "    # Check for bad images\n",
        "    for i in tqdm.tqdm(annotations['images']):\n",
        "        im = cv2.imread(f\"{image_path}/{i['file_name']}\")\n",
        "        if((im.shape[0]!=i['height']) or (im.shape[1]!=i['width'])):\n",
        "            useless.append(i)\n",
        "        \n",
        "        # Update the dimensions\n",
        "        i['height'], i['width'] = im.shape[0], im.shape[1]\n",
        "        del im # Clean up memory\n",
        "\n",
        "    # Remove bad images\n",
        "    if len(useless) > 0:\n",
        "        bad_ids = [item[\"id\"] for item in useless]\n",
        "        for i, item in enumerate(annotations['images']):\n",
        "            if item[\"id\"] in bad_ids:\n",
        "                del annotations[\"images\"][i]\n",
        "\n",
        "        # Remove bad annotations for these images\n",
        "        for i, item in enumerate(annotations['annotations']):\n",
        "            if item[\"image_id\"] in bad_ids:\n",
        "                del annotations[\"annotations\"][i]\n",
        "\n",
        "    return annotations\n",
        "\n",
        "def remove_bad_segmentation(segmentations: list):\n",
        "    '''\n",
        "    Remove segmentations which has less than 3 coordinates\n",
        "    '''\n",
        "    for i, ann in enumerate(tqdm.tqdm(segmentations)):\n",
        "        segments = [seg for seg in ann['segmentation'] if len(seg)>=6]\n",
        "        segmentations[i]['segmentation'] = segments\n",
        "    return segmentations\n",
        "\n",
        "def redraw_boxes(annotations: list, coco_ds):\n",
        "    for item in tqdm.tqdm(annotations):\n",
        "        try:\n",
        "            # convert the item to a binary mask\n",
        "            bin_mask = coco_ds.annToMask(item)\n",
        "            new_bbox = mask.toBbox(mask.encode(bin_mask))\n",
        "            item['bbox'] = list(new_bbox)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(\"Error with image\", item['image_id'])\n",
        "            print(type(e), e)\n",
        "    return annotations\n",
        "\n",
        "def preprocess_pipeline(work_dir: str):\n",
        "    '''\n",
        "    Executes the pre-processing pipeline\n",
        "    '''\n",
        "    # Read the annotations\n",
        "    print(\"**Reading the annotations**\")\n",
        "    annotations = read_annotation(f\"{work_dir}/annotations.json\")\n",
        "    coco_ds = coco.COCO(f\"{work_dir}/annotations.json\")\n",
        "    print(f\"Total images: {len(annotations['images'])},\\\n",
        "        \\tTotal annotations: {len(annotations['annotations'])}\")\n",
        "    \n",
        "    # Correct the images\n",
        "    print(\"**Removing bad images and correcting image dimensions**\")\n",
        "    annotations = preprocess_images(annotations, f\"{work_dir}/images\")\n",
        "    print(f\"Total images: {len(annotations['images'])},\\\n",
        "        \\tTotal annotations: {len(annotations['annotations'])}\")\n",
        "    \n",
        "    # Remove bad segmentations\n",
        "    print(\"**Removing segments with less than 3 coordinates**\")\n",
        "    annotations['annotations'] = remove_bad_segmentation(annotations['annotations'])\n",
        "    print(f\"Total images: {len(annotations['images'])},\\\n",
        "        \\tTotal annotations: {len(annotations['annotations'])}\")\n",
        "    \n",
        "    # Remove bad bounding boxes\n",
        "    print(\"**Re-drawing bounding boxes**\")\n",
        "    annotations['annotations'] = redraw_boxes(annotations['annotations'], coco_ds)\n",
        "    print(f\"Total images: {len(annotations['images'])},\\\n",
        "        \\tTotal annotations: {len(annotations['annotations'])}\")\n",
        "    \n",
        "    return annotations\n",
        "    \n",
        "    \n",
        "def do_preprocess():\n",
        "    # For training annotations\n",
        "    print(\"**Working with training annotations**\")\n",
        "    train_dir = \"data/train\"\n",
        "    train_annotations = preprocess_pipeline(train_dir)\n",
        "    save_annotations(train_annotations, train_dir)\n",
        "    \n",
        "    # For validation annotations\n",
        "    print(\"\\n\\n**Working with validation annotations**\")\n",
        "    val_dir = \"data/val\"\n",
        "    val_annotations = preprocess_pipeline(val_dir)\n",
        "    save_annotations(val_annotations, val_dir)\n",
        "\n",
        "\n",
        "def save_annotations(annotations: dict, work_dir: str):\n",
        "    '''\n",
        "    Save the annotations\n",
        "    '''\n",
        "    file_name = f\"{work_dir}/annotations_new.json\"\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(json.dumps(annotations))\n",
        "    print(f\"New annotations saved: {file_name}\")\n",
        "\n",
        "\n",
        "# -\n",
        "\n",
        "do_preprocess()\n",
        "\n",
        "\n",
        "\n",
        "# +\n",
        "# import matplotlib.pyplot as plt\n",
        "# from pycocotools import coco\n",
        "# import numpy as np\n",
        "# ann = coco.COCO(\"data/train/annotations.json\")\n",
        "# def visualize(image_path: str):\n",
        "#     # Get annotation\n",
        "#     image_id = int(image_path.split(\"/\")[-1].split(\".\")[0])\n",
        "#     annIds = ann.getAnnIds(imgIds=[image_id])\n",
        "#     anns = ann.loadAnns(annIds)\n",
        "#     plt_im = plt.imread(image_path)\n",
        "#     plt.imshow(plt_im)\n",
        "#     #plt.imshow(np.rot90(plt_im, 3))\n",
        "#     ann.showAnns(anns)\n",
        "    \n",
        "# visualize(f\"{train_dir}/images/008934.jpg\")\n"
      ],
      "metadata": {
        "id": "qZJpFvozzTq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -U torch sahi #mmdet mmcv-full"
      ],
      "metadata": {
        "id": "t7temqMZzhKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sahi"
      ],
      "metadata": {
        "id": "a0OQrBwB6Dmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "collapsed": true,
        "id": "9_amZaW_AVxA",
        "outputId": "33fd2824-738b-4bb6-8ff1-e0b015116672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.3 MB 6.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.1.0\n",
            "    Uninstalling Pillow-9.1.0:\n",
            "      Successfully uninstalled Pillow-9.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install Pillow==9.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test_coco psudolabeling"
      ],
      "metadata": {
        "id": "Mr3hqOaysO-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## sub-sample-train to 20%\n",
        "\n",
        "from sahi.utils.coco import Coco\n",
        "from sahi.utils.file import save_json\n",
        "# specify coco dataset path\n",
        "coco_path = \"data/train/annotations_new.json\"\n",
        "\n",
        "# init Coco object\n",
        "coco = Coco.from_coco_dict_or_path(coco_path)\n",
        "\n",
        "# create a Coco object with 1/10 of total images\n",
        "subsampled_coco = coco.get_subsampled_coco(subsample_ratio=4)\n",
        "\n",
        "# export subsampled COCO dataset\n",
        "save_json(subsampled_coco.json, \"data/train/subsampled_20_coco.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c52QycDKsVt2",
        "outputId": "e1f34458-9a98-43cc-952a-035b6c4b4cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexing coco dataset annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading coco annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54392/54392 [00:12<00:00, 4528.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########copying files\n",
        "import shutil\n",
        "import os\n",
        "import glob    \n",
        "source_dir = '/content/data/test/images'\n",
        "target_dir = '/content/data/train/images'\n",
        "    \n",
        "file_names = os.listdir(source_dir)\n",
        "import tqdm    \n",
        "for file_name in tqdm.tqdm(glob.iglob(os.path.join(source_dir, \"*.jpg\"))):\n",
        "    shutil.copy(file_name, target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQHe2e_HPGnn",
        "outputId": "f175b761-d84d-418a-a31f-f41ce3ad1656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2819it [00:02, 993.29it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classes.json') as f:\n",
        "  classes=json.load(f)\n",
        "desired_name2id={}\n",
        "for each in classes:\n",
        "  desired_name2id[each[\"name\"]]=each['id']"
      ],
      "metadata": {
        "id": "l1DXVBAjTTP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Merge CoCo\n",
        "from sahi.utils.coco import Coco\n",
        "from sahi.utils.file import save_json\n",
        "\n",
        "# init Coco objects by specifying coco dataset paths and image folder directories\n",
        "coco_1 = Coco.from_coco_dict_or_path(\"data/train/subsampled_20_coco.json\", image_dir=\"data/train/images\")\n",
        "coco_2 = Coco.from_coco_dict_or_path(\"/content/drive/MyDrive/Preds/query_ep22_test_preds_coco_th0.1_new.json\", image_dir=\"data/train/images\")\n",
        "\n",
        "# merge Coco datasets desired_name2id : dict {\"human\": 1, \"car\": 2, \"big_vehicle\": 3}\n",
        "coco_1.merge(coco_2,desired_name2id)\n",
        "\n",
        "# export merged COCO dataset\n",
        "save_json(coco_1.json, \"data/train/merged_coco.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luqkNnANxZb-",
        "outputId": "49a2cc75-0748-4fb5-cc9f-c93a1e958217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexing coco dataset annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading coco annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13598/13598 [00:04<00:00, 3200.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexing coco dataset annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading coco annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2819/2819 [00:04<00:00, 654.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories are formed as:\n",
            " [{'id': 50, 'name': 'beetroot-steamed-without-addition-of-salt', 'supercategory': 'beetroot-steamed-without-addition-of-salt'}, {'id': 101246, 'name': 'bread_wholemeal', 'supercategory': 'bread_wholemeal'}, {'id': 100546, 'name': 'jam', 'supercategory': 'jam'}, {'id': 101129, 'name': 'water', 'supercategory': 'water'}, {'id': 101243, 'name': 'bread', 'supercategory': 'bread'}, {'id': 100133, 'name': 'banana', 'supercategory': 'banana'}, {'id': 101306, 'name': 'soft_cheese', 'supercategory': 'soft_cheese'}, {'id': 101126, 'name': 'ham_raw', 'supercategory': 'ham_raw'}, {'id': 101305, 'name': 'hard_cheese', 'supercategory': 'hard_cheese'}, {'id': 100206, 'name': 'cottage_cheese', 'supercategory': 'cottage_cheese'}, {'id': 101178, 'name': 'coffee', 'supercategory': 'coffee'}, {'id': 101150, 'name': 'fruit_mixed', 'supercategory': 'fruit_mixed'}, {'id': 101185, 'name': 'pancake', 'supercategory': 'pancake'}, {'id': 101166, 'name': 'tea', 'supercategory': 'tea'}, {'id': 100966, 'name': 'salmon_smoked', 'supercategory': 'salmon_smoked'}, {'id': 100078, 'name': 'avocado', 'supercategory': 'avocado'}, {'id': 100107, 'name': 'spring_onion_scallion', 'supercategory': 'spring_onion_scallion'}, {'id': 101181, 'name': 'ristretto_with_caffeine', 'supercategory': 'ristretto_with_caffeine'}, {'id': 101335, 'name': 'ham_n_s', 'supercategory': 'ham_n_s'}, {'id': 100523, 'name': 'egg', 'supercategory': 'egg'}, {'id': 101291, 'name': 'bacon', 'supercategory': 'bacon'}, {'id': 100063, 'name': 'chips_french_fries', 'supercategory': 'chips_french_fries'}, {'id': 101219, 'name': 'juice_apple', 'supercategory': 'juice_apple'}, {'id': 101308, 'name': 'chicken', 'supercategory': 'chicken'}, {'id': 100089, 'name': 'tomato', 'supercategory': 'tomato'}, {'id': 101183, 'name': 'broccoli', 'supercategory': 'broccoli'}, {'id': 101279, 'name': 'shrimp_prawn', 'supercategory': 'shrimp_prawn'}, {'id': 101188, 'name': 'carrot', 'supercategory': 'carrot'}, {'id': 101311, 'name': 'chickpeas', 'supercategory': 'chickpeas'}, {'id': 101214, 'name': 'french_salad_dressing', 'supercategory': 'french_salad_dressing'}, {'id': 100321, 'name': 'pasta_hornli_ch', 'supercategory': 'pasta_hornli_ch'}, {'id': 101275, 'name': 'sauce_cream', 'supercategory': 'sauce_cream'}, {'id': 100319, 'name': 'pasta_n_s', 'supercategory': 'pasta_n_s'}, {'id': 100838, 'name': 'tomato_sauce', 'supercategory': 'tomato_sauce'}, {'id': 101302, 'name': 'cheese_n_s', 'supercategory': 'cheese_n_s'}, {'id': 101347, 'name': 'pear', 'supercategory': 'pear'}, {'id': 100184, 'name': 'cashew_nut', 'supercategory': 'cashew_nut'}, {'id': 100182, 'name': 'almonds', 'supercategory': 'almonds'}, {'id': 101282, 'name': 'lentil_n_s', 'supercategory': 'lentil_n_s'}, {'id': 101144, 'name': 'mixed_vegetables', 'supercategory': 'mixed_vegetables'}, {'id': 100175, 'name': 'peanut_butter', 'supercategory': 'peanut_butter'}, {'id': 100130, 'name': 'apple', 'supercategory': 'apple'}, {'id': 100145, 'name': 'blueberries', 'supercategory': 'blueberries'}, {'id': 100083, 'name': 'cucumber', 'supercategory': 'cucumber'}, {'id': 101355, 'name': 'yogurt', 'supercategory': 'yogurt'}, {'id': 101194, 'name': 'butter', 'supercategory': 'butter'}, {'id': 101284, 'name': 'mayonnaise', 'supercategory': 'mayonnaise'}, {'id': 101314, 'name': 'soup', 'supercategory': 'soup'}, {'id': 100790, 'name': 'wine_red', 'supercategory': 'wine_red'}, {'id': 101165, 'name': 'wine_white', 'supercategory': 'wine_white'}, {'id': 100022, 'name': 'green_bean_steamed_without_addition_of_salt', 'supercategory': 'green_bean_steamed_without_addition_of_salt'}, {'id': 101354, 'name': 'sausage', 'supercategory': 'sausage'}, {'id': 101172, 'name': 'pizza_margherita_baked', 'supercategory': 'pizza_margherita_baked'}, {'id': 100456, 'name': 'salami_ch', 'supercategory': 'salami_ch'}, {'id': 101236, 'name': 'mushroom', 'supercategory': 'mushroom'}, {'id': 100710, 'name': 'tart_n_s', 'supercategory': 'tart_n_s'}, {'id': 101197, 'name': 'rice', 'supercategory': 'rice'}, {'id': 101180, 'name': 'white_coffee', 'supercategory': 'white_coffee'}, {'id': 100180, 'name': 'sunflower_seeds', 'supercategory': 'sunflower_seeds'}, {'id': 101294, 'name': 'bell_pepper_red_raw', 'supercategory': 'bell_pepper_red_raw'}, {'id': 101193, 'name': 'zucchini', 'supercategory': 'zucchini'}, {'id': 101138, 'name': 'asparagus', 'supercategory': 'asparagus'}, {'id': 100843, 'name': 'tartar_sauce', 'supercategory': 'tartar_sauce'}, {'id': 100352, 'name': 'lye_pretzel_soft', 'supercategory': 'lye_pretzel_soft'}, {'id': 100082, 'name': 'cucumber_pickled_ch', 'supercategory': 'cucumber_pickled_ch'}, {'id': 101043, 'name': 'curry_vegetarian', 'supercategory': 'curry_vegetarian'}, {'id': 101022, 'name': 'soup_of_lentils_dahl_dhal', 'supercategory': 'soup_of_lentils_dahl_dhal'}, {'id': 100486, 'name': 'salmon', 'supercategory': 'salmon'}, {'id': 100929, 'name': 'salt_cake_ch_vegetables_filled', 'supercategory': 'salt_cake_ch_vegetables_filled'}, {'id': 100161, 'name': 'orange', 'supercategory': 'orange'}, {'id': 101265, 'name': 'pasta_noodles', 'supercategory': 'pasta_noodles'}, {'id': 101361, 'name': 'cream_double_cream_heavy_cream_45', 'supercategory': 'cream_double_cream_heavy_cream_45'}, {'id': 100674, 'name': 'cake_chocolate', 'supercategory': 'cake_chocolate'}, {'id': 101260, 'name': 'pasta_spaghetti', 'supercategory': 'pasta_spaghetti'}, {'id': 100196, 'name': 'black_olives', 'supercategory': 'black_olives'}, {'id': 100245, 'name': 'parmesan', 'supercategory': 'parmesan'}, {'id': 100318, 'name': 'spaetzle', 'supercategory': 'spaetzle'}, {'id': 101210, 'name': 'salad_lambs_ear', 'supercategory': 'salad_lambs_ear'}, {'id': 101208, 'name': 'salad_leaf_salad_green', 'supercategory': 'salad_leaf_salad_green'}, {'id': 101148, 'name': 'potato', 'supercategory': 'potato'}, {'id': 100102, 'name': 'white_cabbage', 'supercategory': 'white_cabbage'}, {'id': 100235, 'name': 'halloumi', 'supercategory': 'halloumi'}, {'id': 100093, 'name': 'beetroot_raw', 'supercategory': 'beetroot_raw'}, {'id': 101248, 'name': 'bread_grain', 'supercategory': 'bread_grain'}, {'id': 101358, 'name': 'applesauce', 'supercategory': 'applesauce'}, {'id': 100249, 'name': 'cheese_for_raclette_ch', 'supercategory': 'cheese_for_raclette_ch'}, {'id': 101255, 'name': 'bread_white', 'supercategory': 'bread_white'}, {'id': 101326, 'name': 'curds_natural', 'supercategory': 'curds_natural'}, {'id': 101215, 'name': 'quiche', 'supercategory': 'quiche'}, {'id': 101292, 'name': 'beef_n_s', 'supercategory': 'beef_n_s'}, {'id': 100963, 'name': 'taboule_prepared_with_couscous', 'supercategory': 'taboule_prepared_with_couscous'}, {'id': 100077, 'name': 'aubergine_eggplant', 'supercategory': 'aubergine_eggplant'}, {'id': 100243, 'name': 'mozzarella', 'supercategory': 'mozzarella'}, {'id': 101258, 'name': 'pasta_penne', 'supercategory': 'pasta_penne'}, {'id': 101027, 'name': 'lasagne_vegetable_prepared', 'supercategory': 'lasagne_vegetable_prepared'}, {'id': 100156, 'name': 'mandarine', 'supercategory': 'mandarine'}, {'id': 100152, 'name': 'kiwi', 'supercategory': 'kiwi'}, {'id': 100080, 'name': 'french_beans', 'supercategory': 'french_beans'}, {'id': 100925, 'name': 'spring_roll_fried', 'supercategory': 'spring_roll_fried'}, {'id': 100960, 'name': 'caprese_salad_tomato_mozzarella', 'supercategory': 'caprese_salad_tomato_mozzarella'}, {'id': 100072, 'name': 'leaf_spinach', 'supercategory': 'leaf_spinach'}, {'id': 100338, 'name': 'roll_of_half_white_or_white_flour_with_large_void', 'supercategory': 'roll_of_half_white_or_white_flour_with_large_void'}, {'id': 100687, 'name': 'omelette_with_flour_thick_crepe_plain', 'supercategory': 'omelette_with_flour_thick_crepe_plain'}, {'id': 100495, 'name': 'tuna', 'supercategory': 'tuna'}, {'id': 100563, 'name': 'dark_chocolate', 'supercategory': 'dark_chocolate'}, {'id': 100826, 'name': 'sauce_savoury_n_s', 'supercategory': 'sauce_savoury_n_s'}, {'id': 100172, 'name': 'raisins_dried', 'supercategory': 'raisins_dried'}, {'id': 100757, 'name': 'ice_tea_on_black_tea_basis', 'supercategory': 'ice_tea_on_black_tea_basis'}, {'id': 100150, 'name': 'kaki', 'supercategory': 'kaki'}, {'id': 100752, 'name': 'smoothie', 'supercategory': 'smoothie'}, {'id': 100652, 'name': 'crepe_with_flour_plain', 'supercategory': 'crepe_with_flour_plain'}, {'id': 101310, 'name': 'nuggets', 'supercategory': 'nuggets'}, {'id': 100962, 'name': 'chili_con_carne_prepared', 'supercategory': 'chili_con_carne_prepared'}, {'id': 101177, 'name': 'veggie_burger', 'supercategory': 'veggie_burger'}, {'id': 100099, 'name': 'chinese_cabbage', 'supercategory': 'chinese_cabbage'}, {'id': 101176, 'name': 'hamburger', 'supercategory': 'hamburger'}, {'id': 101317, 'name': 'soup_pumpkin', 'supercategory': 'soup_pumpkin'}, {'id': 100942, 'name': 'sushi', 'supercategory': 'sushi'}, {'id': 100176, 'name': 'chestnuts_ch', 'supercategory': 'chestnuts_ch'}, {'id': 100883, 'name': 'sauce_soya', 'supercategory': 'sauce_soya'}, {'id': 101212, 'name': 'balsamic_salad_dressing', 'supercategory': 'balsamic_salad_dressing'}, {'id': 101262, 'name': 'pasta_twist', 'supercategory': 'pasta_twist'}, {'id': 100836, 'name': 'bolognaise_sauce', 'supercategory': 'bolognaise_sauce'}, {'id': 101340, 'name': 'leek', 'supercategory': 'leek'}, {'id': 100993, 'name': 'fajita_bread_only', 'supercategory': 'fajita_bread_only'}, {'id': 100060, 'name': 'potato_gnocchi', 'supercategory': 'potato_gnocchi'}, {'id': 100300, 'name': 'rice_noodles_vermicelli', 'supercategory': 'rice_noodles_vermicelli'}, {'id': 101254, 'name': 'bread_whole_wheat', 'supercategory': 'bread_whole_wheat'}, {'id': 101285, 'name': 'onion', 'supercategory': 'onion'}, {'id': 100108, 'name': 'garlic', 'supercategory': 'garlic'}, {'id': 100949, 'name': 'hummus', 'supercategory': 'hummus'}, {'id': 101168, 'name': 'pizza_with_vegetables_baked', 'supercategory': 'pizza_with_vegetables_baked'}, {'id': 101297, 'name': 'beer', 'supercategory': 'beer'}, {'id': 100974, 'name': 'glucose_drink_50g', 'supercategory': 'glucose_drink_50g'}, {'id': 100069, 'name': 'ratatouille', 'supercategory': 'ratatouille'}, {'id': 101187, 'name': 'peanut', 'supercategory': 'peanut'}, {'id': 101322, 'name': 'cauliflower', 'supercategory': 'cauliflower'}, {'id': 100195, 'name': 'green_olives', 'supercategory': 'green_olives'}, {'id': 100333, 'name': 'bread_pita', 'supercategory': 'bread_pita'}, {'id': 100325, 'name': 'pasta_wholemeal', 'supercategory': 'pasta_wholemeal'}, {'id': 101272, 'name': 'sauce_pesto', 'supercategory': 'sauce_pesto'}, {'id': 100302, 'name': 'couscous', 'supercategory': 'couscous'}, {'id': 101268, 'name': 'sauce', 'supercategory': 'sauce'}, {'id': 100335, 'name': 'bread_toast', 'supercategory': 'bread_toast'}, {'id': 101009, 'name': 'water_with_lemon_juice', 'supercategory': 'water_with_lemon_juice'}, {'id': 101182, 'name': 'espresso', 'supercategory': 'espresso'}, {'id': 101156, 'name': 'egg_scrambled', 'supercategory': 'egg_scrambled'}, {'id': 101220, 'name': 'juice_orange', 'supercategory': 'juice_orange'}, {'id': 100355, 'name': 'braided_white_loaf_ch', 'supercategory': 'braided_white_loaf_ch'}, {'id': 100224, 'name': 'emmental_cheese_ch', 'supercategory': 'emmental_cheese_ch'}, {'id': 100594, 'name': 'hazelnut_chocolate_spread_nutella_ovomaltine_caotina', 'supercategory': 'hazelnut_chocolate_spread_nutella_ovomaltine_caotina'}, {'id': 100264, 'name': 'tomme_ch', 'supercategory': 'tomme_ch'}, {'id': 100185, 'name': 'hazelnut', 'supercategory': 'hazelnut'}, {'id': 101346, 'name': 'peach', 'supercategory': 'peach'}, {'id': 100142, 'name': 'figs', 'supercategory': 'figs'}, {'id': 100937, 'name': 'mashed_potatoes_prepared_with_full_fat_milk_with_butter', 'supercategory': 'mashed_potatoes_prepared_with_full_fat_milk_with_butter'}, {'id': 100086, 'name': 'pumpkin', 'supercategory': 'pumpkin'}, {'id': 100111, 'name': 'swiss_chard', 'supercategory': 'swiss_chard'}, {'id': 101360, 'name': 'red_cabbage_raw', 'supercategory': 'red_cabbage_raw'}, {'id': 101200, 'name': 'spinach_raw', 'supercategory': 'spinach_raw'}, {'id': 100978, 'name': 'chicken_curry_cream_coconut_milk_curry_spices_paste', 'supercategory': 'chicken_curry_cream_coconut_milk_curry_spices_paste'}, {'id': 101324, 'name': 'crunch_muesli', 'supercategory': 'crunch_muesli'}, {'id': 101201, 'name': 'biscuit', 'supercategory': 'biscuit'}, {'id': 100442, 'name': 'meatloaf_ch', 'supercategory': 'meatloaf_ch'}, {'id': 100229, 'name': 'fresh_cheese_n_s', 'supercategory': 'fresh_cheese_n_s'}, {'id': 101296, 'name': 'honey', 'supercategory': 'honey'}, {'id': 100067, 'name': 'vegetable_mix_peas_and_carrots', 'supercategory': 'vegetable_mix_peas_and_carrots'}, {'id': 100859, 'name': 'parsley', 'supercategory': 'parsley'}, {'id': 100645, 'name': 'brownie', 'supercategory': 'brownie'}, {'id': 101363, 'name': 'ice_cream_n_s', 'supercategory': 'ice_cream_n_s'}, {'id': 101213, 'name': 'salad_dressing', 'supercategory': 'salad_dressing'}, {'id': 100445, 'name': 'dried_meat_n_s', 'supercategory': 'dried_meat_n_s'}, {'id': 100421, 'name': 'chicken_breast', 'supercategory': 'chicken_breast'}, {'id': 100070, 'name': 'mixed_salad_chopped_without_sauce', 'supercategory': 'mixed_salad_chopped_without_sauce'}, {'id': 101190, 'name': 'feta', 'supercategory': 'feta'}, {'id': 100537, 'name': 'praline_n_s', 'supercategory': 'praline_n_s'}, {'id': 100183, 'name': 'walnut', 'supercategory': 'walnut'}, {'id': 101141, 'name': 'potato_salad', 'supercategory': 'potato_salad'}, {'id': 101338, 'name': 'kolhrabi', 'supercategory': 'kolhrabi'}, {'id': 100115, 'name': 'alfa_sprouts', 'supercategory': 'alfa_sprouts'}, {'id': 101298, 'name': 'brussel_sprouts', 'supercategory': 'brussel_sprouts'}, {'id': 100234, 'name': 'gruyere_ch', 'supercategory': 'gruyere_ch'}, {'id': 100301, 'name': 'bulgur', 'supercategory': 'bulgur'}, {'id': 100171, 'name': 'grapes', 'supercategory': 'grapes'}, {'id': 100607, 'name': 'chocolate_egg_small', 'supercategory': 'chocolate_egg_small'}, {'id': 101114, 'name': 'cappuccino', 'supercategory': 'cappuccino'}, {'id': 101247, 'name': 'crisp_bread', 'supercategory': 'crisp_bread'}, {'id': 101256, 'name': 'bread_black', 'supercategory': 'bread_black'}, {'id': 100064, 'name': 'rosti_n_s', 'supercategory': 'rosti_n_s'}, {'id': 100157, 'name': 'mango', 'supercategory': 'mango'}, {'id': 101325, 'name': 'muesli_dry', 'supercategory': 'muesli_dry'}, {'id': 101199, 'name': 'spinach', 'supercategory': 'spinach'}, {'id': 100477, 'name': 'fish_n_s', 'supercategory': 'fish_n_s'}, {'id': 101135, 'name': 'risotto', 'supercategory': 'risotto'}, {'id': 100916, 'name': 'crisps_ch', 'supercategory': 'crisps_ch'}, {'id': 101349, 'name': 'pork_n_s', 'supercategory': 'pork_n_s'}, {'id': 100131, 'name': 'pomegranate', 'supercategory': 'pomegranate'}, {'id': 101147, 'name': 'sweet_corn', 'supercategory': 'sweet_corn'}, {'id': 101329, 'name': 'flakes', 'supercategory': 'flakes'}, {'id': 100951, 'name': 'greek_salad', 'supercategory': 'greek_salad'}, {'id': 100192, 'name': 'sesame_seeds', 'supercategory': 'sesame_seeds'}, {'id': 101123, 'name': 'bouillon', 'supercategory': 'bouillon'}, {'id': 101149, 'name': 'baked_potato', 'supercategory': 'baked_potato'}, {'id': 101328, 'name': 'fennel', 'supercategory': 'fennel'}, {'id': 101341, 'name': 'meat_n_s', 'supercategory': 'meat_n_s'}, {'id': 100911, 'name': 'croutons', 'supercategory': 'croutons'}, {'id': 101295, 'name': 'bell_pepper_red_stewed', 'supercategory': 'bell_pepper_red_stewed'}, {'id': 101121, 'name': 'nuts', 'supercategory': 'nuts'}, {'id': 100360, 'name': 'breadcrumbs_unspiced', 'supercategory': 'breadcrumbs_unspiced'}, {'id': 101331, 'name': 'fondue', 'supercategory': 'fondue'}, {'id': 101273, 'name': 'sauce_mushroom', 'supercategory': 'sauce_mushroom'}, {'id': 100141, 'name': 'strawberries', 'supercategory': 'strawberries'}, {'id': 101229, 'name': 'pie_plum_baked_with_cake_dough', 'supercategory': 'pie_plum_baked_with_cake_dough'}, {'id': 100982, 'name': 'potatoes_au_gratin_dauphinois_prepared', 'supercategory': 'potatoes_au_gratin_dauphinois_prepared'}, {'id': 100084, 'name': 'capers', 'supercategory': 'capers'}, {'id': 101257, 'name': 'bread_wholemeal_toast', 'supercategory': 'bread_wholemeal_toast'}, {'id': 100092, 'name': 'red_radish', 'supercategory': 'red_radish'}, {'id': 100658, 'name': 'fruit_tart', 'supercategory': 'fruit_tart'}, {'id': 100123, 'name': 'beans_kidney', 'supercategory': 'beans_kidney'}, {'id': 100101, 'name': 'sauerkraut', 'supercategory': 'sauerkraut'}, {'id': 101343, 'name': 'mustard', 'supercategory': 'mustard'}, {'id': 100059, 'name': 'country_fries', 'supercategory': 'country_fries'}, {'id': 100834, 'name': 'ketchup', 'supercategory': 'ketchup'}, {'id': 100324, 'name': 'pasta_linguini_parpadelle_tagliatelle', 'supercategory': 'pasta_linguini_parpadelle_tagliatelle'}, {'id': 101309, 'name': 'chicken_cut_into_stripes_only_meat', 'supercategory': 'chicken_cut_into_stripes_only_meat'}, {'id': 100725, 'name': 'cookies', 'supercategory': 'cookies'}, {'id': 101012, 'name': 'sun_dried_tomatoe', 'supercategory': 'sun_dried_tomatoe'}, {'id': 100334, 'name': 'bread_ticino_ch', 'supercategory': 'bread_ticino_ch'}, {'id': 101304, 'name': 'semi_hard_cheese', 'supercategory': 'semi_hard_cheese'}, {'id': 101038, 'name': 'porridge_prepared_with_partially_skimmed_milk', 'supercategory': 'porridge_prepared_with_partially_skimmed_milk'}, {'id': 101218, 'name': 'juice', 'supercategory': 'juice'}, {'id': 101238, 'name': 'chocolate_milk', 'supercategory': 'chocolate_milk'}, {'id': 100332, 'name': 'bread_fruit', 'supercategory': 'bread_fruit'}, {'id': 100105, 'name': 'corn', 'supercategory': 'corn'}, {'id': 100140, 'name': 'dates', 'supercategory': 'dates'}, {'id': 100190, 'name': 'pistachio', 'supercategory': 'pistachio'}, {'id': 100250, 'name': 'cream_cheese_n_s', 'supercategory': 'cream_cheese_n_s'}, {'id': 101244, 'name': 'bread_rye', 'supercategory': 'bread_rye'}, {'id': 100073, 'name': 'witloof_chicory', 'supercategory': 'witloof_chicory'}, {'id': 101307, 'name': 'goat_cheese_soft', 'supercategory': 'goat_cheese_soft'}, {'id': 100143, 'name': 'grapefruit_pomelo', 'supercategory': 'grapefruit_pomelo'}, {'id': 101303, 'name': 'blue_mould_cheese', 'supercategory': 'blue_mould_cheese'}, {'id': 100842, 'name': 'guacamole', 'supercategory': 'guacamole'}, {'id': 100475, 'name': 'tofu', 'supercategory': 'tofu'}, {'id': 101189, 'name': 'cordon_bleu', 'supercategory': 'cordon_bleu'}, {'id': 100314, 'name': 'quinoa', 'supercategory': 'quinoa'}, {'id': 100200, 'name': 'kefir_drink', 'supercategory': 'kefir_drink'}, {'id': 101209, 'name': 'salad_rocket', 'supercategory': 'salad_rocket'}, {'id': 101170, 'name': 'pizza_with_ham_with_mushrooms_baked', 'supercategory': 'pizza_with_ham_with_mushrooms_baked'}, {'id': 101014, 'name': 'fruit_coulis', 'supercategory': 'fruit_coulis'}, {'id': 100164, 'name': 'plums', 'supercategory': 'plums'}, {'id': 101173, 'name': 'pizza_with_ham_baked', 'supercategory': 'pizza_with_ham_baked'}, {'id': 100129, 'name': 'pineapple', 'supercategory': 'pineapple'}, {'id': 100177, 'name': 'seeds_n_s', 'supercategory': 'seeds_n_s'}, {'id': 100349, 'name': 'focaccia', 'supercategory': 'focaccia'}, {'id': 101237, 'name': 'mixed_milk_beverage', 'supercategory': 'mixed_milk_beverage'}, {'id': 100068, 'name': 'coleslaw_chopped_without_sauce', 'supercategory': 'coleslaw_chopped_without_sauce'}, {'id': 100057, 'name': 'sweet_potato', 'supercategory': 'sweet_potato'}, {'id': 100423, 'name': 'chicken_leg', 'supercategory': 'chicken_leg'}, {'id': 101159, 'name': 'croissant', 'supercategory': 'croissant'}, {'id': 100958, 'name': 'cheesecake', 'supercategory': 'cheesecake'}, {'id': 101271, 'name': 'sauce_cocktail', 'supercategory': 'sauce_cocktail'}, {'id': 100719, 'name': 'croissant_with_chocolate_filling', 'supercategory': 'croissant_with_chocolate_filling'}, {'id': 100178, 'name': 'pumpkin_seeds', 'supercategory': 'pumpkin_seeds'}, {'id': 100076, 'name': 'artichoke', 'supercategory': 'artichoke'}, {'id': 101327, 'name': 'soft_drink_with_a_taste', 'supercategory': 'soft_drink_with_a_taste'}, {'id': 101231, 'name': 'apple_pie', 'supercategory': 'apple_pie'}, {'id': 100348, 'name': 'white_bread_with_butter_eggs_and_milk', 'supercategory': 'white_bread_with_butter_eggs_and_milk'}, {'id': 100907, 'name': 'savoury_pastry_stick', 'supercategory': 'savoury_pastry_stick'}, {'id': 100049, 'name': 'tuna_in_oil_drained', 'supercategory': 'tuna_in_oil_drained'}, {'id': 100467, 'name': 'meat_terrine_pate', 'supercategory': 'meat_terrine_pate'}, {'id': 100895, 'name': 'falafel_balls', 'supercategory': 'falafel_balls'}, {'id': 100135, 'name': 'berries_n_s', 'supercategory': 'berries_n_s'}, {'id': 101153, 'name': 'latte_macchiato', 'supercategory': 'latte_macchiato'}, {'id': 100158, 'name': 'sugar_melon_galia_honeydew_cantaloupe', 'supercategory': 'sugar_melon_galia_honeydew_cantaloupe'}, {'id': 100181, 'name': 'mixed_seeds_n_s', 'supercategory': 'mixed_seeds_n_s'}, {'id': 100840, 'name': 'oil_vinegar_salad_dressing', 'supercategory': 'oil_vinegar_salad_dressing'}, {'id': 101323, 'name': 'celeriac', 'supercategory': 'celeriac'}, {'id': 100957, 'name': 'chocolate_mousse', 'supercategory': 'chocolate_mousse'}, {'id': 100173, 'name': 'lemon', 'supercategory': 'lemon'}, {'id': 100742, 'name': 'chocolate_cookies', 'supercategory': 'chocolate_cookies'}, {'id': 100992, 'name': 'birchermuesli_prepared_no_sugar_added', 'supercategory': 'birchermuesli_prepared_no_sugar_added'}, {'id': 100681, 'name': 'muffin', 'supercategory': 'muffin'}, {'id': 100179, 'name': 'pine_nuts', 'supercategory': 'pine_nuts'}, {'id': 101029, 'name': 'french_pizza_from_alsace_baked', 'supercategory': 'french_pizza_from_alsace_baked'}, {'id': 101240, 'name': 'chocolate_n_s', 'supercategory': 'chocolate_n_s'}, {'id': 100310, 'name': 'grits_polenta_maize_flour', 'supercategory': 'grits_polenta_maize_flour'}, {'id': 101164, 'name': 'wine_rose', 'supercategory': 'wine_rose'}, {'id': 101290, 'name': 'cola_based_drink', 'supercategory': 'cola_based_drink'}, {'id': 100146, 'name': 'raspberries', 'supercategory': 'raspberries'}, {'id': 100346, 'name': 'roll_with_pieces_of_chocolate', 'supercategory': 'roll_with_pieces_of_chocolate'}, {'id': 100649, 'name': 'cake_lemon', 'supercategory': 'cake_lemon'}, {'id': 100315, 'name': 'rice_wild', 'supercategory': 'rice_wild'}, {'id': 101249, 'name': 'gluten_free_bread', 'supercategory': 'gluten_free_bread'}, {'id': 101118, 'name': 'pearl_onion', 'supercategory': 'pearl_onion'}, {'id': 100844, 'name': 'tzatziki', 'supercategory': 'tzatziki'}, {'id': 100926, 'name': 'ham_croissant_ch', 'supercategory': 'ham_croissant_ch'}, {'id': 100909, 'name': 'corn_crisps', 'supercategory': 'corn_crisps'}, {'id': 101283, 'name': 'lentils_green_du_puy_du_berry', 'supercategory': 'lentils_green_du_puy_du_berry'}, {'id': 101196, 'name': 'rice_whole_grain', 'supercategory': 'rice_whole_grain'}, {'id': 100437, 'name': 'cervelat_ch', 'supercategory': 'cervelat_ch'}, {'id': 100781, 'name': 'aperitif_with_alcohol_n_s_aperol_spritz', 'supercategory': 'aperitif_with_alcohol_n_s_aperol_spritz'}, {'id': 100104, 'name': 'peas', 'supercategory': 'peas'}, {'id': 100282, 'name': 'tiramisu', 'supercategory': 'tiramisu'}, {'id': 100132, 'name': 'apricots', 'supercategory': 'apricots'}, {'id': 100936, 'name': 'lasagne_meat_prepared', 'supercategory': 'lasagne_meat_prepared'}, {'id': 100337, 'name': 'brioche', 'supercategory': 'brioche'}, {'id': 101032, 'name': 'vegetable_au_gratin_baked', 'supercategory': 'vegetable_au_gratin_baked'}, {'id': 100848, 'name': 'basil', 'supercategory': 'basil'}, {'id': 101006, 'name': 'butter_spread_puree_almond', 'supercategory': 'butter_spread_puree_almond'}, {'id': 101228, 'name': 'pie_apricot', 'supercategory': 'pie_apricot'}, {'id': 100364, 'name': 'rusk_wholemeal', 'supercategory': 'rusk_wholemeal'}, {'id': 101266, 'name': 'pasta_in_conch_form', 'supercategory': 'pasta_in_conch_form'}, {'id': 100322, 'name': 'pasta_in_butterfly_form_farfalle', 'supercategory': 'pasta_in_butterfly_form_farfalle'}, {'id': 100174, 'name': 'damson_plum', 'supercategory': 'damson_plum'}, {'id': 100114, 'name': 'shoots_n_s', 'supercategory': 'shoots_n_s'}, {'id': 100186, 'name': 'coconut', 'supercategory': 'coconut'}, {'id': 101077, 'name': 'banana_cake', 'supercategory': 'banana_cake'}, {'id': 101274, 'name': 'sauce_curry', 'supercategory': 'sauce_curry'}, {'id': 100031, 'name': 'watermelon_fresh', 'supercategory': 'watermelon_fresh'}, {'id': 100113, 'name': 'white_asparagus', 'supercategory': 'white_asparagus'}, {'id': 100151, 'name': 'cherries', 'supercategory': 'cherries'}, {'id': 100160, 'name': 'nectarine', 'supercategory': 'nectarine'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/train/merged_coco.json\") as f:\n",
        "  train_data=json.load(f)"
      ],
      "metadata": {
        "id": "5i6IET2pR-85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['annotations'][14000]"
      ],
      "metadata": {
        "id": "UnaLpTPxSI32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/Preds/query_ep22_test_preds_coco_th0.1_new.json') as f:\n",
        "  test_data=json.load(f)\n",
        "\n",
        "with open(\"data/train/annotations_new.json\") as f:\n",
        "  train_data=json.load(f)"
      ],
      "metadata": {
        "id": "AXeAwPEe_l_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key1,key2 in zip(test_data['annotations'],train_data['annotations']):\n",
        "  #if key['category_id']=='101129':\n",
        "  #key['category_id']=str(key['id'])\n",
        "  print(key1)\n",
        "  print(key2)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxRUXkyv766n",
        "outputId": "7428ee56-97c2-4f00-ba99-5cef9df1e066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image_id': 178479, 'bbox': [889, 0, 134, 193], 'score': 0.1068185418844223, 'category_id': 101129, 'category_name': 'water', 'segmentation': [[899, 0, 899, 2, 898, 3, 898, 9, 897, 10, 897, 18, 896, 19, 896, 25, 895, 26, 895, 35, 894, 36, 894, 45, 893, 46, 893, 55, 892, 56, 892, 72, 891, 73, 891, 90, 890, 91, 890, 116, 889, 117, 889, 141, 890, 142, 890, 153, 891, 154, 891, 158, 892, 159, 892, 160, 893, 161, 893, 163, 895, 165, 895, 166, 903, 174, 903, 175, 907, 179, 908, 179, 910, 181, 911, 181, 912, 182, 913, 182, 915, 184, 916, 184, 917, 185, 918, 185, 919, 186, 920, 186, 921, 187, 923, 187, 924, 188, 925, 188, 926, 189, 927, 189, 928, 190, 931, 190, 932, 191, 940, 191, 941, 192, 951, 192, 952, 193, 957, 193, 958, 192, 959, 192, 960, 193, 966, 193, 967, 192, 972, 192, 973, 193, 974, 193, 975, 192, 984, 192, 985, 191, 987, 191, 988, 190, 992, 190, 993, 189, 994, 189, 995, 188, 996, 188, 998, 186, 999, 186, 1000, 185, 1001, 185, 1002, 184, 1003, 184, 1004, 183, 1005, 183, 1006, 182, 1007, 182, 1010, 179, 1011, 179, 1013, 177, 1013, 176, 1015, 174, 1015, 173, 1016, 172, 1016, 171, 1018, 169, 1018, 168, 1019, 167, 1019, 166, 1020, 165, 1020, 163, 1021, 162, 1021, 160, 1022, 159, 1022, 155, 1023, 154, 1023, 0]], 'iscrowd': 0, 'area': 24224}\n",
            "{'id': 184123, 'image_id': 131072, 'category_id': 101246, 'segmentation': [[169.0, 379.5, 130.0, 374.5, 112.0, 363.5, 94.5, 340.0, 61.5, 213.0, 61.5, 188.0, 70.5, 168.0, 87.0, 152.5, 103.0, 143.5, 123.0, 139.5, 185.0, 118.5, 226.0, 90.5, 249.0, 87.5, 309.0, 88.5, 339.0, 110.5, 350.5, 125.00000000000001, 354.5, 155.0, 382.5, 231.0, 383.5, 277.0, 360.0, 303.5, 327.0, 331.5, 308.0, 343.5, 216.0, 373.5]], 'area': 71393.0, 'bbox': [62.0, 88.0, 322.0, 292.0], 'iscrowd': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for each in data['augmentation']"
      ],
      "metadata": {
        "id": "3dAvPsN-Oq2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in test_data['annotations']:\n",
        "  #print(key)\n",
        "  key['category_id']=int(key['category_id'])\n",
        "  # print(key)\n",
        "  #break"
      ],
      "metadata": {
        "id": "utPGdLlBApjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Preds/query_ep22_test_preds_coco_th0.1_new.json','w') as f:\n",
        "  json.dump(test_data,f)"
      ],
      "metadata": {
        "id": "iW5WqWOZ--qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Moving the test images to train folder\n",
        "import shutil\n",
        "import os\n",
        "    \n",
        "source_dir = '/path/to/source_folder'\n",
        "target_dir = '/path/to/dest_folder'\n",
        "    \n",
        "file_names = os.listdir(source_dir)\n",
        "    \n",
        "for file_name in file_names:\n",
        "    shutil.move(os.path.join(source_dir, file_name), target_dir)"
      ],
      "metadata": {
        "id": "i8kH4UuWtqQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "from sahi.slicing import slice_coco\n",
        "\n",
        "coco_dict,coco_path=slice_coco(\n",
        "coco_annotation_file_path='/content/data/train/annotations_new.json',\n",
        "image_dir='/content/data/train/images',\n",
        "output_coco_annotation_file_name='sliced_ann.json',\n",
        "ignore_negative_samples=True,\n",
        "output_dir= '/content/images',\n",
        "slice_height=512,\n",
        "slice_width=512,\n",
        "overlap_height_ratio=0.2,\n",
        "overlap_width_ratio=0.2,\n",
        "min_area_ratio=0.1,\n",
        "verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "D7_lWcfEzmC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/slice_ann.json','w') as f:\n",
        "  json.dump(coco_dict,f)"
      ],
      "metadata": {
        "id": "UaHe3Bim7Ixj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGQXbjCPV0_g"
      },
      "source": [
        "## Mount the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kXSsyJk_rGQ"
      },
      "outputs": [],
      "source": [
        "#alternatively copy files from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDNcibwIxRPm"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJkCDXw49FJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac669f9-a1a2-4105-fbcf-529d5c160ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__.split(\"+\")[0]\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "#we have used torch version 1.10.0 and cuda 11.1 as it is preinstalled in this colab version\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "#don't forget to restart the runtime \n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "#!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "!git clone https://github.com/saidineshpola/QueryInst.git mmdetection\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install Pillow\n",
        "!pip uninstall pycocotools -y\n",
        "!pip install -q git+https://github.com/waleedka/coco.git#subdirectory=PythonAPI\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oswZEmthIcAf"
      },
      "source": [
        "#### **Note:** Before continuing restart runtime\n",
        "\n",
        "To restart runtime : `Runtime` > `Restart Runtime`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4Uwa47-XuNu"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdDzM_8-qtuL",
        "outputId": "abff6213-dd98-49bb-829d-fc7a292f2b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/\n",
            "data/train\n",
            "data/test\n",
            "data/test/images\n",
            "data/val\n",
            "data/val/images\n"
          ]
        }
      ],
      "source": [
        "#%cd /content/\n",
        "\n",
        "#Directories present\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('data/'):\n",
        "        print(dirname)\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"mmdetection\")\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pPSEFV4gryz"
      },
      "source": [
        "So, the `data` directory is something like this:\n",
        "\n",
        "<img src=\"https://images.aicrowd.com/uploads/ckeditor/pictures/674/content_carbon__3_.png\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ0LiLXFI9k4"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5QSFOoV8x8H"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "# For reading annotations file\n",
        "import json\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Reading annotations.json\n",
        "TRAIN_ANNOTATIONS_PATH = \"data/train/annotations.json\"\n",
        "TRAIN_IMAGE_DIRECTIORY = \"data/train/images/\"\n",
        "\n",
        "VAL_ANNOTATIONS_PATH = \"data/val/annotations.json\"\n",
        "VAL_IMAGE_DIRECTIORY = \"data/val/images/\"\n",
        "\n",
        "train_coco = COCO(TRAIN_ANNOTATIONS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwzbU8zaKUw3"
      },
      "outputs": [],
      "source": [
        "# Reading the annotation files\n",
        "with open(TRAIN_ANNOTATIONS_PATH) as f:\n",
        "  train_annotations_data = json.load(f)\n",
        "\n",
        "with open(VAL_ANNOTATIONS_PATH) as f:\n",
        "  val_annotations_data = json.load(f)\n",
        "#train_annotations_data['annotations'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-rglUXYaB8g"
      },
      "source": [
        "## Fixing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTPhgkXkA4OE",
        "outputId": "f9a730af-20a4-437d-85a8-fd97f893c931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54392/54392 [05:10<00:00, 175.21it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 946/946 [00:05<00:00, 181.61it/s]\n"
          ]
        }
      ],
      "source": [
        "#fix dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reading annotations.json\n",
        "TRAIN_ANNOTATIONS_PATH = \"data/train/annotations.json\"\n",
        "TRAIN_IMAGE_DIRECTIORY = \"data/train/images/\"\n",
        "\n",
        "VAL_ANNOTATIONS_PATH = \"data/val/annotations.json\"\n",
        "VAL_IMAGE_DIRECTIORY = \"data/val/images/\"\n",
        "\n",
        "# train_coco = COCO(TRAIN_ANNOTATIONS_PATH)\n",
        "\n",
        "# Reading the annotation files\n",
        "with open(TRAIN_ANNOTATIONS_PATH) as f:\n",
        "  train_annotations_data = json.load(f)\n",
        "\n",
        "with open(VAL_ANNOTATIONS_PATH) as f:\n",
        "  val_annotations_data = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "# Function for taking a annotation & directiory of images and returning new annoation json with fixed image size info\n",
        "def fix_data(annotations, directiory, VERBOSE = False):\n",
        "  for n, i in enumerate(tqdm((annotations['images']))):\n",
        "   \n",
        "      img = cv2.imread(directiory+i[\"file_name\"])\n",
        " \n",
        "      if img.shape[0] != i['height']:\n",
        "          annotations['images'][n]['height'] = img.shape[0]\n",
        "          if VERBOSE:\n",
        "            print(i[\"file_name\"])\n",
        "            print(annotations['images'][n], img.shape)\n",
        "\n",
        "      if img.shape[1] != i['width']:\n",
        "          annotations['images'][n]['width'] = img.shape[1]\n",
        "          if VERBOSE:\n",
        "            print(i[\"file_name\"])\n",
        "            print(annotations['images'][n], img.shape)\n",
        "\n",
        "  return annotations\n",
        "\n",
        "train_annotations_data = fix_data(train_annotations_data, TRAIN_IMAGE_DIRECTIORY)\n",
        "\n",
        "with open('data/train/new_ann.json', 'w') as f:\n",
        "    json.dump(train_annotations_data, f)\n",
        "\n",
        "val_annotations_data = fix_data(val_annotations_data, VAL_IMAGE_DIRECTIORY)\n",
        "\n",
        "with open('data/val/new_ann.json', 'w') as f:\n",
        "    json.dump(val_annotations_data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TOQaXMDfWo4"
      },
      "source": [
        "## Setting up hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veNf4K3FXT0_"
      },
      "source": [
        "Modify the model configuration hyperparameters for our training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ecXHv0Su06"
      },
      "source": [
        "* Load the configuration files and modify them for our dataset.\n",
        "* Set the desired hyperparameters as well\n",
        "* Start training and logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tHtoyJt9gRUm",
        "outputId": "87738f03-dac8-4721-b597-9a1c2efc95b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mmdetection/configs/swin/mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can add more model configs like below.\n",
        "MODELS_CONFIG = {\n",
        "    'mask_rcnn_swin-s': {\n",
        "        'config_file': 'configs/swin/mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "selected_model = 'mask_rcnn_swin-s' # chose any config you want from the MODELS_CONFIG\n",
        "\n",
        "# Name of the config file.\n",
        "config_file = MODELS_CONFIG[selected_model]['config_file']\n",
        "\n",
        "config_fname = os.path.join('mmdetection', config_file)\n",
        "assert os.path.isfile(config_fname), '`{}` not exist'.format(config_fname)\n",
        "config_fname"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pEFUeZH1JEp"
      },
      "source": [
        "### Edit config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUytmAQW9MH"
      },
      "source": [
        "We will edit the config to be suited to the food dataset, there are a lot of parameters other than the ones we have changed below that one can edit in the existing config file that might lead to a better score. We leave that upto you, do feel free to explore documentation for [mmdetection](https://github.com/open-mmlab/mmdetection/tree/master/docs).\n",
        "\n",
        "**Note:** Instead of using regular expressions to edit the existing file, feel free to download the config file and edit it using the text editor of your choice and then reupload the same and have the variable config_fname point to the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ow9qkmgRFs"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# fname = config_fname\n",
        "# with open(fname) as f:\n",
        "#     s = f.read()\n",
        "\n",
        "#     s = re.sub('num_classes=.*?,',\n",
        "#                'num_classes={},'.format(len(classes_names)), s)\n",
        "\n",
        "# with open(fname, 'w') as f:\n",
        "#     f.write(s)\n",
        "# #lets check if the changes have been updated\n",
        "# !cat {config_fname}\n",
        "# #print(len(classes_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mId3_vhbLo_2"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# fname2 = 'mmdetection/configs/htc/htc_without_semantic_r50_fpn_1x_coco.py'\n",
        "\n",
        "# with open(fname2) as f:\n",
        "#     s = f.read()\n",
        "\n",
        "#     s = re.sub('num_classes=.*?,',\n",
        "#                'num_classes={},'.format(len(classes_names)), s)\n",
        "# with open(fname2, 'w') as f:\n",
        "#     f.write(s)    \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpZBAJngAVxH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "fname2 = 'mmdetection/configs/_base_/datasets/coco_instance.py'\n",
        "\n",
        "with open(fname2) as f:\n",
        "    s = f.read()\n",
        "    s = re.sub(\"data_root = 'data/coco/'\",\n",
        "                \"data_root = 'data/'\", s)\n",
        "    s = re.sub(\"annotations/instances_train2017.json\",\n",
        "                \"train/new_ann.json\", s)\n",
        "    s = re.sub(\"annotations/instances_val2017.json\",\n",
        "                \"val/new_ann.json\", s)\n",
        "    s = re.sub(\"annotations/instances_val2017.json\",\n",
        "                \"val/new_ann.json\", s)\n",
        "    s = re.sub(\"train2017\", \"train/images\", s)\n",
        "    s = re.sub(\"val2017\", \"val/images\", s)\n",
        "    s = re.sub(\"workers_per_gpu=2\",\"workers_per_gpu=0\",s)\n",
        "    s = re.sub(\"samples_per_gpu=2\",\"samples_per_gpu=4\",s) \n",
        "   \n",
        "\n",
        "with open(fname2, 'w') as f:\n",
        "    f.write(s)\n",
        "\n",
        "#to check if the changes have been updated\n",
        "# !cat {fname2}\n",
        "\n",
        "\n",
        "total_epochs = 22\n",
        "fname = 'mmdetection/configs/_base_/schedules/schedule_1x.py'\n",
        "with open(fname) as f:\n",
        "    s = f.read()\n",
        "    s = re.sub('max_epochs=\\d+',\n",
        "               'max_epochs={}'.format(total_epochs), s)\n",
        "    s = re.sub(\"lr=0.02\",\"lr=0.0001\",s)  #need to change lr to 0.0025 since we are working with only 1 gpu\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPmik-f4VE-W"
      },
      "source": [
        "### Just Run this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdCf_A0ML8vT",
        "outputId": "44935e2a-c386-4100-9ded-77d32461957f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mmdetection/mmdet/datasets/coco.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mmdetection/mmdet/datasets/coco.py\n",
        "\n",
        "#@title Don't forget to run this cell, Modify coco dataset mmdet file (set classes list) { display-mode: \"form\" }\n",
        "# Copyright (c) OpenMMLab. All rights reserved.\n",
        "import contextlib\n",
        "import io\n",
        "import itertools\n",
        "import logging\n",
        "import os.path as osp\n",
        "import tempfile\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "from mmcv.utils import print_log\n",
        "from terminaltables import AsciiTable\n",
        "\n",
        "from mmdet.core import eval_recalls\n",
        "from .api_wrappers import COCO, COCOeval\n",
        "from .builder import DATASETS\n",
        "from .custom import CustomDataset\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class CocoDataset(CustomDataset):\n",
        "\n",
        "    CLASSES = ('bread-wholemeal', 'jam', 'water', 'bread-sourdough', 'banana', 'soft-cheese', 'ham-raw', 'hard-cheese', 'cottage-cheese', 'bread-half-white', 'coffee-with-caffeine', 'fruit-salad', 'pancakes', 'tea', 'salmon-smoked', 'avocado', 'spring-onion-scallion', 'ristretto-with-caffeine', 'ham', 'egg', 'bacon-frying', 'chips-french-fries', 'juice-apple', 'chicken', 'tomato-raw', 'broccoli', 'shrimp-boiled', 'beetroot-steamed-without-addition-of-salt', 'carrot-raw', 'chickpeas', 'french-salad-dressing', 'pasta-hornli', 'sauce-cream', 'meat-balls', 'pasta', 'tomato-sauce', 'cheese', 'pear', 'cashew-nut', 'almonds', 'lentils', 'mixed-vegetables', 'peanut-butter', 'apple', 'blueberries', 'cucumber', 'cocoa-powder', 'greek-yaourt-yahourt-yogourt-ou-yoghourt', 'maple-syrup-concentrate', 'buckwheat-grain-peeled', 'butter', 'herbal-tea', 'mayonnaise', 'soup-vegetable', 'wine-red', 'wine-white', 'green-bean-steamed-without-addition-of-salt', 'sausage', 'pizza-margherita-baked', 'salami', 'mushroom', 'bread-meat-substitute-lettuce-sauce', 'tart', 'tea-verveine', 'rice', 'white-coffee-with-caffeine', 'linseeds', 'sunflower-seeds', 'ham-cooked', 'bell-pepper-red-raw', 'zucchini', 'green-asparagus', 'tartar-sauce', 'lye-pretzel-soft', 'cucumber-pickled', 'curry-vegetarian', 'yaourt-yahourt-yogourt-ou-yoghourt-natural', 'soup-of-lentils-dahl-dhal', 'soup-cream-of-vegetables', 'balsamic-vinegar', 'salmon', 'salt-cake-vegetables-filled', 'bacon', 'orange', 'pasta-noodles', 'cream', 'cake-chocolate', 'pasta-spaghetti', 'black-olives', 'parmesan', 'spaetzle', 'salad-lambs-ear', 'salad-leaf-salad-green', 'potatoes-steamed', 'white-cabbage', 'halloumi', 'beetroot-raw', 'bread-grain', 'applesauce-unsweetened-canned', 'cheese-for-raclette', 'mushrooms', 'bread-white', 'curds-natural-with-at-most-10-fidm', 'bagel-without-filling', 'quiche-with-cheese-baked-with-puff-pastry', 'soup-potato', 'bouillon-vegetable', 'beef-sirloin-steak', 'taboule-prepared-with-couscous', 'eggplant', 'bread', 'turnover-with-meat-small-meat-pie-empanadas', 'mungbean-sprouts', 'mozzarella', 'pasta-penne', 'lasagne-vegetable-prepared', 'mandarine', 'kiwi', 'french-beans', 'tartar-meat', 'spring-roll-fried', 'pork-chop', 'caprese-salad-tomato-mozzarella', 'leaf-spinach', 'roll-of-half-white-or-white-flour-with-large-void', 'pasta-ravioli-stuffing', 'omelette-plain', 'tuna', 'dark-chocolate', 'sauce-savoury', 'dried-raisins', 'ice-tea', 'kaki', 'macaroon', 'smoothie', 'crepe-plain', 'chicken-nuggets', 'chili-con-carne-prepared', 'veggie-burger', 'cream-spinach', 'cod', 'chinese-cabbage', 'hamburger-bread-meat-ketchup', 'soup-pumpkin', 'sushi', 'chestnuts', 'coffee-decaffeinated', 'sauce-soya', 'balsamic-salad-dressing', 'pasta-twist', 'bolognaise-sauce', 'leek', 'fajita-bread-only', 'potato-gnocchi', 'beef-cut-into-stripes-only-meat', 'rice-noodles-vermicelli', 'tea-ginger', 'tea-green', 'bread-whole-wheat', 'onion', 'garlic', 'hummus', 'pizza-with-vegetables-baked', 'beer', 'glucose-drink-50g', 'chicken-wing', 'ratatouille', 'peanut', 'high-protein-pasta-made-of-lentils-peas', 'cauliflower', 'quiche-with-spinach-baked-with-cake-dough', 'green-olives', 'brazil-nut', 'eggplant-caviar', 'bread-pita', 'pasta-wholemeal', 'sauce-pesto', 'oil', 'couscous', 'sauce-roast', 'prosecco', 'crackers', 'bread-toast', 'shrimp-prawn-small', 'panna-cotta', 'romanesco', 'water-with-lemon-juice', 'espresso-with-caffeine', 'egg-scrambled-prepared', 'juice-orange', 'ice-cubes', 'braided-white-loaf', 'emmental-cheese', 'croissant-wholegrain', 'hazelnut-chocolate-spread-nutella-ovomaltine-caotina', 'tomme', 'water-mineral', 'hazelnut', 'bacon-raw', 'bread-nut', 'black-forest-tart', 'soup-miso', 'peach', 'figs', 'beef-filet', 'mustard-dijon', 'rice-basmati', 'mashed-potatoes-prepared-with-full-fat-milk-with-butter', 'dumplings', 'pumpkin', 'swiss-chard', 'red-cabbage', 'spinach-raw', 'naan-indien-bread', 'chicken-curry-cream-coconut-milk-curry-spices-paste', 'crunch-muesli', 'biscuits', 'bread-french-white-flour', 'meatloaf', 'fresh-cheese', 'honey', 'vegetable-mix-peas-and-carrots', 'parsley', 'brownie', 'dairy-ice-cream', 'tea-black', 'carrot-cake', 'fish-fingers-breaded', 'salad-dressing', 'dried-meat', 'chicken-breast', 'mixed-salad-chopped-without-sauce', 'feta', 'praline', 'tea-peppermint', 'walnut', 'potato-salad-with-mayonnaise-yogurt-dressing', 'kebab-in-pita-bread', 'kolhrabi', 'alfa-sprouts', 'brussel-sprouts', 'bacon-cooking', 'gruyere', 'bulgur', 'grapes', 'pork-escalope', 'chocolate-egg-small', 'cappuccino', 'zucchini-stewed-without-addition-of-fat-without-addition-of-salt', 'crisp-bread-wasa', 'bread-black', 'perch-fillets-lake', 'rosti', 'mango', 'sandwich-ham-cheese-and-butter', 'muesli', 'spinach-steamed-without-addition-of-salt', 'fish', 'risotto-without-cheese-cooked', 'milk-chocolate-with-hazelnuts', 'cake-oblong', 'crisps', 'pork', 'pomegranate', 'sweet-corn-canned', 'flakes-oat', 'greek-salad', 'cantonese-fried-rice', 'sesame-seeds', 'bouillon', 'baked-potato', 'fennel', 'meat', 'bread-olive', 'croutons', 'philadelphia', 'mushroom-average-stewed-without-addition-of-fat-without-addition-of-salt', 'bell-pepper-red-stewed-without-addition-of-fat-without-addition-of-salt', 'white-chocolate', 'mixed-nuts', 'breadcrumbs-unspiced', 'fondue', 'sauce-mushroom', 'tea-spice', 'strawberries', 'tea-rooibos', 'pie-plum-baked-with-cake-dough', 'potatoes-au-gratin-dauphinois-prepared', 'capers', 'vegetables', 'bread-wholemeal-toast', 'red-radish', 'fruit-tart', 'beans-kidney', 'sauerkraut', 'mustard', 'country-fries', 'ketchup', 'pasta-linguini-parpadelle-tagliatelle', 'chicken-cut-into-stripes-only-meat', 'cookies', 'sun-dried-tomatoe', 'bread-ticino', 'semi-hard-cheese', 'margarine', 'porridge-prepared-with-partially-skimmed-milk', 'soya-drink-soy-milk', 'juice-multifruit', 'popcorn-salted', 'chocolate-filled', 'milk-chocolate', 'bread-fruit', 'mix-of-dried-fruits-and-nuts', 'corn', 'tete-de-moine', 'dates', 'pistachio', 'celery', 'white-radish', 'oat-milk', 'cream-cheese', 'bread-rye', 'witloof-chicory', 'apple-crumble', 'goat-cheese-soft', 'grapefruit-pomelo', 'risotto-with-mushrooms-cooked', 'blue-mould-cheese', 'biscuit-with-butter', 'guacamole', 'pecan-nut', 'tofu', 'cordon-bleu-from-pork-schnitzel-fried', 'paprika-chips', 'quinoa', 'kefir-drink', 'm-m-s', 'salad-rocket', 'bread-spelt', 'pizza-with-ham-with-mushrooms-baked', 'fruit-coulis', 'plums', 'beef-minced-only-meat', 'pizza-with-ham-baked', 'pineapple', 'soup-tomato', 'cheddar', 'tea-fruit', 'rice-jasmin', 'seeds', 'focaccia', 'milk', 'coleslaw-chopped-without-sauce', 'pastry-flaky', 'curd', 'savoury-puff-pastry-stick', 'sweet-potato', 'chicken-leg', 'croissant', 'sour-cream', 'ham-turkey', 'processed-cheese', 'fruit-compotes', 'cheesecake', 'pasta-tortelloni-stuffing', 'sauce-cocktail', 'croissant-with-chocolate-filling', 'pumpkin-seeds', 'artichoke', 'champagne', 'grissini', 'sweets-candies', 'brie', 'wienerli-swiss-sausage', 'syrup-diluted-ready-to-drink', 'apple-pie', 'white-bread-with-butter-eggs-and-milk', 'savoury-puff-pastry', 'anchovies', 'tuna-in-oil-drained', 'lemon-pie', 'meat-terrine-pate', 'coriander', 'falafel-balls', 'berries', 'latte-macchiato-with-caffeine', 'faux-mage-cashew-vegan-chers', 'beans-white', 'sugar-melon', 'mixed-seeds', 'hamburger', 'hamburger-bun', 'oil-vinegar-salad-dressing', 'soya-yaourt-yahourt-yogourt-ou-yoghourt', 'chocolate-milk-chocolate-drink', 'celeriac', 'chocolate-mousse', 'cenovis-yeast-spread', 'thickened-cream-35', 'meringue', 'lamb-chop', 'shrimp-prawn-large', 'beef', 'lemon', 'croque-monsieur', 'chives', 'chocolate-cookies', 'birchermuesli-prepared-no-sugar-added', 'fish-crunchies-battered', 'muffin', 'savoy-cabbage-steamed-without-addition-of-salt', 'pine-nuts', 'chorizo', 'chia-grains', 'frying-sausage', 'french-pizza-from-alsace-baked', 'chocolate', 'cooked-sausage', 'grits-polenta-maize-flour', 'gummi-bears-fruit-jellies-jelly-babies-with-fruit-essence', 'wine-rose', 'coca-cola', 'raspberries', 'roll-with-pieces-of-chocolate', 'goat-average-raw', 'lemon-cake', 'coconut-milk', 'rice-wild', 'gluten-free-bread', 'pearl-onions', 'buckwheat-pancake', 'bread-5-grain', 'light-beer', 'sugar-glazing', 'tzatziki', 'butter-herb', 'ham-croissant', 'corn-crisps', 'lentils-green-du-puy-du-berry', 'cocktail', 'rice-whole-grain', 'veal-sausage', 'cervelat', 'sorbet', 'aperitif-with-alcohol-aperol-spritz', 'dips', 'corn-flakes', 'peas', 'tiramisu', 'apricots', 'cake-marble', 'lamb', 'lasagne-meat-prepared', 'coca-cola-zero', 'cake-salted', 'dough-puff-pastry-shortcrust-bread-pizza-dough', 'rice-waffels', 'sekt', 'brioche', 'vegetable-au-gratin-baked', 'mango-dried', 'processed-meat-charcuterie', 'mousse', 'sauce-sweet-sour', 'basil', 'butter-spread-puree-almond', 'pie-apricot-baked-with-cake-dough', 'rusk-wholemeal', 'beef-roast', 'vanille-cream-cooked-custard-creme-dessert', 'pasta-in-conch-form', 'nuts', 'sauce-carbonara', 'fig-dried', 'pasta-in-butterfly-form-farfalle', 'minced-meat', 'carrot-steamed-without-addition-of-salt', 'ebly', 'damson-plum', 'shoots', 'bouquet-garni', 'coconut', 'banana-cake', 'waffle', 'apricot-dried', 'sauce-curry', 'watermelon-fresh', 'sauce-sweet-salted-asian', 'pork-roast', 'blackberry', 'smoked-cooked-sausage-of-pork-and-beef-meat-sausag', 'bean-seeds', 'italian-salad-dressing', 'white-asparagus', 'pie-rhubarb-baked-with-cake-dough', 'tomato-stewed-without-addition-of-fat-without-addition-of-salt', 'cherries', 'nectarine')\n",
        "\n",
        "    def load_annotations(self, ann_file):\n",
        "        \"\"\"Load annotation from COCO style annotation file.\n",
        "\n",
        "        Args:\n",
        "            ann_file (str): Path of annotation file.\n",
        "\n",
        "        Returns:\n",
        "            list[dict]: Annotation info from COCO api.\n",
        "        \"\"\"\n",
        "\n",
        "        self.coco = COCO('./data/train/new_ann.json')\n",
        "        # The order of returned `cat_ids` will not\n",
        "        # change with the order of the CLASSES\n",
        "        self.cat_ids = self.coco.getCatIds()\n",
        "\n",
        "        self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}\n",
        "        self.img_ids = self.coco.getImgIds()\n",
        "        data_infos = []\n",
        "        total_ann_ids = []\n",
        "        for i in self.img_ids:\n",
        "            info = self.coco.load_imgs([i])[0]\n",
        "            info['filename'] = info['file_name']\n",
        "            data_infos.append(info)\n",
        "            ann_ids = self.coco.get_ann_ids(img_ids=[i])\n",
        "            total_ann_ids.extend(ann_ids)\n",
        "        assert len(set(total_ann_ids)) == len(\n",
        "            total_ann_ids), f\"Annotation ids in '{ann_file}' are not unique!\"\n",
        "        return data_infos\n",
        "\n",
        "    def get_ann_info(self, idx):\n",
        "        \"\"\"Get COCO annotation by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            dict: Annotation info of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return self._parse_ann_info(self.data_infos[idx], ann_info)\n",
        "\n",
        "    def getCatIds(self, idx):\n",
        "        \"\"\"Get COCO category ids by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: All categories in the image of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return [ann['category_id'] for ann in ann_info]\n",
        "\n",
        "    def _filter_imgs(self, min_size=32):\n",
        "        \"\"\"Filter images too small or without ground truths.\"\"\"\n",
        "        valid_inds = []\n",
        "        # obtain images that contain annotation\n",
        "        ids_with_ann = set(_['image_id'] for _ in self.coco.anns.values())\n",
        "        # obtain images that contain annotations of the required categories\n",
        "        ids_in_cat = set()\n",
        "        for i, class_id in enumerate(self.cat_ids):\n",
        "            ids_in_cat |= set(self.coco.cat_img_map[class_id])\n",
        "        # merge the image id sets of the two conditions and use the merged set\n",
        "        # to filter out images if self.filter_empty_gt=True\n",
        "        ids_in_cat &= ids_with_ann\n",
        "\n",
        "        valid_img_ids = []\n",
        "        for i, img_info in enumerate(self.data_infos):\n",
        "            img_id = self.img_ids[i]\n",
        "            if self.filter_empty_gt and img_id not in ids_in_cat:\n",
        "                continue\n",
        "            if min(img_info['width'], img_info['height']) >= min_size:\n",
        "                valid_inds.append(i)\n",
        "                valid_img_ids.append(img_id)\n",
        "        self.img_ids = valid_img_ids\n",
        "        return valid_inds\n",
        "\n",
        "    def _parse_ann_info(self, img_info, ann_info):\n",
        "        \"\"\"Parse bbox and mask annotation.\n",
        "\n",
        "        Args:\n",
        "            ann_info (list[dict]): Annotation info of an image.\n",
        "            with_mask (bool): Whether to parse mask annotations.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dict containing the following keys: bboxes, bboxes_ignore,\\\n",
        "                labels, masks, seg_map. \"masks\" are raw annotations and not \\\n",
        "                decoded into binary masks.\n",
        "        \"\"\"\n",
        "        gt_bboxes = []\n",
        "        gt_labels = []\n",
        "        gt_bboxes_ignore = []\n",
        "        gt_masks_ann = []\n",
        "        for i, ann in enumerate(ann_info):\n",
        "            if ann.get('ignore', False):\n",
        "                continue\n",
        "            x1, y1, w, h = ann['bbox']\n",
        "            inter_w = max(0, min(x1 + w, img_info['width']) - max(x1, 0))\n",
        "            inter_h = max(0, min(y1 + h, img_info['height']) - max(y1, 0))\n",
        "            if inter_w * inter_h == 0:\n",
        "                continue\n",
        "            if ann['area'] <= 0 or w < 1 or h < 1:\n",
        "                continue\n",
        "            if ann['category_id'] not in self.cat_ids:\n",
        "                continue\n",
        "            bbox = [x1, y1, x1 + w, y1 + h]\n",
        "            if ann.get('iscrowd', False):\n",
        "                gt_bboxes_ignore.append(bbox)\n",
        "            else:\n",
        "                gt_bboxes.append(bbox)\n",
        "                gt_labels.append(self.cat2label[ann['category_id']])\n",
        "                gt_masks_ann.append(ann.get('segmentation', None))\n",
        "\n",
        "        if gt_bboxes:\n",
        "            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n",
        "            gt_labels = np.array(gt_labels, dtype=np.int64)\n",
        "        else:\n",
        "            gt_bboxes = np.zeros((0, 4), dtype=np.float32)\n",
        "            gt_labels = np.array([], dtype=np.int64)\n",
        "\n",
        "        if gt_bboxes_ignore:\n",
        "            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n",
        "        else:\n",
        "            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n",
        "\n",
        "        seg_map = img_info['filename'].replace('jpg', 'png')\n",
        "\n",
        "        ann = dict(\n",
        "            bboxes=gt_bboxes,\n",
        "            labels=gt_labels,\n",
        "            bboxes_ignore=gt_bboxes_ignore,\n",
        "            masks=gt_masks_ann,\n",
        "            seg_map=seg_map)\n",
        "\n",
        "        return ann\n",
        "\n",
        "    def xyxy2xywh(self, bbox):\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\n",
        "        evaluation.\n",
        "\n",
        "        Args:\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\n",
        "                ``xyxy`` order.\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\n",
        "        \"\"\"\n",
        "\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0],\n",
        "            _bbox[3] - _bbox[1],\n",
        "        ]\n",
        "\n",
        "    def _proposal2json(self, results):\n",
        "        \"\"\"Convert proposal results to COCO json style.\"\"\"\n",
        "        json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            bboxes = results[idx]\n",
        "            for i in range(bboxes.shape[0]):\n",
        "                data = dict()\n",
        "                data['image_id'] = img_id\n",
        "                data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                data['score'] = float(bboxes[i][4])\n",
        "                data['category_id'] = 1\n",
        "                json_results.append(data)\n",
        "        return json_results\n",
        "\n",
        "    def _det2json(self, results):\n",
        "        \"\"\"Convert detection results to COCO json style.\"\"\"\n",
        "        json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            result = results[idx]\n",
        "            for label in range(len(result)):\n",
        "                bboxes = result[label]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(bboxes[i][4])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    json_results.append(data)\n",
        "        return json_results\n",
        "\n",
        "    def _segm2json(self, results):\n",
        "        \"\"\"Convert instance segmentation results to COCO json style.\"\"\"\n",
        "        bbox_json_results = []\n",
        "        segm_json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            det, seg = results[idx]\n",
        "            for label in range(len(det)):\n",
        "                # bbox results\n",
        "                bboxes = det[label]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(bboxes[i][4])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    bbox_json_results.append(data)\n",
        "\n",
        "                # segm results\n",
        "                # some detectors use different scores for bbox and mask\n",
        "                if isinstance(seg, tuple):\n",
        "                    segms = seg[0][label]\n",
        "                    mask_score = seg[1][label]\n",
        "                else:\n",
        "                    segms = seg[label]\n",
        "                    mask_score = [bbox[4] for bbox in bboxes]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(mask_score[i])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    if isinstance(segms[i]['counts'], bytes):\n",
        "                        segms[i]['counts'] = segms[i]['counts'].decode()\n",
        "                    data['segmentation'] = segms[i]\n",
        "                    segm_json_results.append(data)\n",
        "        return bbox_json_results, segm_json_results\n",
        "\n",
        "    def results2json(self, results, outfile_prefix):\n",
        "        \"\"\"Dump the detection results to a COCO style json file.\n",
        "\n",
        "        There are 3 types of results: proposals, bbox predictions, mask\n",
        "        predictions, and they have different data types. This method will\n",
        "        automatically recognize the type, and dump them to json files.\n",
        "\n",
        "        Args:\n",
        "            results (list[list | tuple | ndarray]): Testing results of the\n",
        "                dataset.\n",
        "            outfile_prefix (str): The filename prefix of the json files. If the\n",
        "                prefix is \"somepath/xxx\", the json files will be named\n",
        "                \"somepath/xxx.bbox.json\", \"somepath/xxx.segm.json\",\n",
        "                \"somepath/xxx.proposal.json\".\n",
        "\n",
        "        Returns:\n",
        "            dict[str: str]: Possible keys are \"bbox\", \"segm\", \"proposal\", and \\\n",
        "                values are corresponding filenames.\n",
        "        \"\"\"\n",
        "        result_files = dict()\n",
        "        if isinstance(results[0], list):\n",
        "            json_results = self._det2json(results)\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\n",
        "            mmcv.dump(json_results, result_files['bbox'])\n",
        "        elif isinstance(results[0], tuple):\n",
        "            json_results = self._segm2json(results)\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['segm'] = f'{outfile_prefix}.segm.json'\n",
        "            mmcv.dump(json_results[0], result_files['bbox'])\n",
        "            mmcv.dump(json_results[1], result_files['segm'])\n",
        "        elif isinstance(results[0], np.ndarray):\n",
        "            json_results = self._proposal2json(results)\n",
        "            result_files['proposal'] = f'{outfile_prefix}.proposal.json'\n",
        "            mmcv.dump(json_results, result_files['proposal'])\n",
        "        else:\n",
        "            raise TypeError('invalid type of results')\n",
        "        return result_files\n",
        "\n",
        "    def fast_eval_recall(self, results, proposal_nums, iou_thrs, logger=None):\n",
        "        gt_bboxes = []\n",
        "        for i in range(len(self.img_ids)):\n",
        "            ann_ids = self.coco.get_ann_ids(img_ids=self.img_ids[i])\n",
        "            ann_info = self.coco.load_anns(ann_ids)\n",
        "            if len(ann_info) == 0:\n",
        "                gt_bboxes.append(np.zeros((0, 4)))\n",
        "                continue\n",
        "            bboxes = []\n",
        "            for ann in ann_info:\n",
        "                if ann.get('ignore', False) or ann['iscrowd']:\n",
        "                    continue\n",
        "                x1, y1, w, h = ann['bbox']\n",
        "                bboxes.append([x1, y1, x1 + w, y1 + h])\n",
        "            bboxes = np.array(bboxes, dtype=np.float32)\n",
        "            if bboxes.shape[0] == 0:\n",
        "                bboxes = np.zeros((0, 4))\n",
        "            gt_bboxes.append(bboxes)\n",
        "\n",
        "        recalls = eval_recalls(\n",
        "            gt_bboxes, results, proposal_nums, iou_thrs, logger=logger)\n",
        "        ar = recalls.mean(axis=1)\n",
        "        return ar\n",
        "\n",
        "    def format_results(self, results, jsonfile_prefix=None, **kwargs):\n",
        "        \"\"\"Format the results to json (standard format for COCO evaluation).\n",
        "\n",
        "        Args:\n",
        "            results (list[tuple | numpy.ndarray]): Testing results of the\n",
        "                dataset.\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\n",
        "                If not specified, a temp file will be created. Default: None.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (result_files, tmp_dir), result_files is a dict containing \\\n",
        "                the json filepaths, tmp_dir is the temporal directory created \\\n",
        "                for saving json files when jsonfile_prefix is not specified.\n",
        "        \"\"\"\n",
        "        assert isinstance(results, list), 'results must be a list'\n",
        "        assert len(results) == len(self), (\n",
        "            'The length of results is not equal to the dataset len: {} != {}'.\n",
        "            format(len(results), len(self)))\n",
        "\n",
        "        if jsonfile_prefix is None:\n",
        "            tmp_dir = tempfile.TemporaryDirectory()\n",
        "            jsonfile_prefix = osp.join(tmp_dir.name, 'results')\n",
        "        else:\n",
        "            tmp_dir = None\n",
        "        result_files = self.results2json(results, jsonfile_prefix)\n",
        "        return result_files, tmp_dir\n",
        "\n",
        "    def evaluate(self,\n",
        "                 results,\n",
        "                 metric='bbox',\n",
        "                 logger=None,\n",
        "                 jsonfile_prefix=None,\n",
        "                 classwise=False,\n",
        "                 proposal_nums=(100, 300, 1000),\n",
        "                 iou_thrs=None,\n",
        "                 metric_items=None):\n",
        "        \"\"\"Evaluation in COCO protocol.\n",
        "\n",
        "        Args:\n",
        "            results (list[list | tuple]): Testing results of the dataset.\n",
        "            metric (str | list[str]): Metrics to be evaluated. Options are\n",
        "                'bbox', 'segm', 'proposal', 'proposal_fast'.\n",
        "            logger (logging.Logger | str | None): Logger used for printing\n",
        "                related information during evaluation. Default: None.\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\n",
        "                If not specified, a temp file will be created. Default: None.\n",
        "            classwise (bool): Whether to evaluating the AP for each class.\n",
        "            proposal_nums (Sequence[int]): Proposal number used for evaluating\n",
        "                recalls, such as recall@100, recall@1000.\n",
        "                Default: (100, 300, 1000).\n",
        "            iou_thrs (Sequence[float], optional): IoU threshold used for\n",
        "                evaluating recalls/mAPs. If set to a list, the average of all\n",
        "                IoUs will also be computed. If not specified, [0.50, 0.55,\n",
        "                0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.\n",
        "                Default: None.\n",
        "            metric_items (list[str] | str, optional): Metric items that will\n",
        "                be returned. If not specified, ``['AR@100', 'AR@300',\n",
        "                'AR@1000', 'AR_s@1000', 'AR_m@1000', 'AR_l@1000' ]`` will be\n",
        "                used when ``metric=='proposal'``, ``['mAP', 'mAP_50', 'mAP_75',\n",
        "                'mAP_s', 'mAP_m', 'mAP_l']`` will be used when\n",
        "                ``metric=='bbox' or metric=='segm'``.\n",
        "\n",
        "        Returns:\n",
        "            dict[str, float]: COCO style evaluation metric.\n",
        "        \"\"\"\n",
        "\n",
        "        metrics = metric if isinstance(metric, list) else [metric]\n",
        "        allowed_metrics = ['bbox', 'segm', 'proposal', 'proposal_fast']\n",
        "        for metric in metrics:\n",
        "            if metric not in allowed_metrics:\n",
        "                raise KeyError(f'metric {metric} is not supported')\n",
        "        if iou_thrs is None:\n",
        "            iou_thrs = np.linspace(\n",
        "                .5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n",
        "        if metric_items is not None:\n",
        "            if not isinstance(metric_items, list):\n",
        "                metric_items = [metric_items]\n",
        "\n",
        "        result_files, tmp_dir = self.format_results(results, jsonfile_prefix)\n",
        "\n",
        "        eval_results = OrderedDict()\n",
        "        cocoGt = self.coco\n",
        "        for metric in metrics:\n",
        "            msg = f'Evaluating {metric}...'\n",
        "            if logger is None:\n",
        "                msg = '\\n' + msg\n",
        "            print_log(msg, logger=logger)\n",
        "\n",
        "            if metric == 'proposal_fast':\n",
        "                ar = self.fast_eval_recall(\n",
        "                    results, proposal_nums, iou_thrs, logger='silent')\n",
        "                log_msg = []\n",
        "                for i, num in enumerate(proposal_nums):\n",
        "                    eval_results[f'AR@{num}'] = ar[i]\n",
        "                    log_msg.append(f'\\nAR@{num}\\t{ar[i]:.4f}')\n",
        "                log_msg = ''.join(log_msg)\n",
        "                print_log(log_msg, logger=logger)\n",
        "                continue\n",
        "\n",
        "            iou_type = 'bbox' if metric == 'proposal' else metric\n",
        "            if metric not in result_files:\n",
        "                raise KeyError(f'{metric} is not in results')\n",
        "            try:\n",
        "                predictions = mmcv.load(result_files[metric])\n",
        "                if iou_type == 'segm':\n",
        "                    # Refer to https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py#L331  # noqa\n",
        "                    # When evaluating mask AP, if the results contain bbox,\n",
        "                    # cocoapi will use the box area instead of the mask area\n",
        "                    # for calculating the instance area. Though the overall AP\n",
        "                    # is not affected, this leads to different\n",
        "                    # small/medium/large mask AP results.\n",
        "                    for x in predictions:\n",
        "                        x.pop('bbox')\n",
        "                    warnings.simplefilter('once')\n",
        "                    warnings.warn(\n",
        "                        'The key \"bbox\" is deleted for more accurate mask AP '\n",
        "                        'of small/medium/large instances since v2.12.0. This '\n",
        "                        'does not change the overall mAP calculation.',\n",
        "                        UserWarning)\n",
        "                cocoDt = cocoGt.loadRes(predictions)\n",
        "            except IndexError:\n",
        "                print_log(\n",
        "                    'The testing results of the whole dataset is empty.',\n",
        "                    logger=logger,\n",
        "                    level=logging.ERROR)\n",
        "                break\n",
        "\n",
        "            cocoEval = COCOeval(cocoGt, cocoDt, iou_type)\n",
        "            cocoEval.params.catIds = self.cat_ids\n",
        "            cocoEval.params.imgIds = self.img_ids\n",
        "            cocoEval.params.maxDets = list(proposal_nums)\n",
        "            cocoEval.params.iouThrs = iou_thrs\n",
        "            # mapping of cocoEval.stats\n",
        "            coco_metric_names = {\n",
        "                'mAP': 0,\n",
        "                'mAP_50': 1,\n",
        "                'mAP_75': 2,\n",
        "                'mAP_s': 3,\n",
        "                'mAP_m': 4,\n",
        "                'mAP_l': 5,\n",
        "                'AR@100': 6,\n",
        "                'AR@300': 7,\n",
        "                'AR@1000': 8,\n",
        "                'AR_s@1000': 9,\n",
        "                'AR_m@1000': 10,\n",
        "                'AR_l@1000': 11\n",
        "            }\n",
        "            if metric_items is not None:\n",
        "                for metric_item in metric_items:\n",
        "                    if metric_item not in coco_metric_names:\n",
        "                        raise KeyError(\n",
        "                            f'metric item {metric_item} is not supported')\n",
        "\n",
        "            if metric == 'proposal':\n",
        "                cocoEval.params.useCats = 0\n",
        "                cocoEval.evaluate()\n",
        "                cocoEval.accumulate()\n",
        "\n",
        "                # Save coco summarize print information to logger\n",
        "                redirect_string = io.StringIO()\n",
        "                with contextlib.redirect_stdout(redirect_string):\n",
        "                    cocoEval.summarize()\n",
        "                print_log('\\n' + redirect_string.getvalue(), logger=logger)\n",
        "\n",
        "                if metric_items is None:\n",
        "                    metric_items = [\n",
        "                        'AR@100', 'AR@300', 'AR@1000', 'AR_s@1000',\n",
        "                        'AR_m@1000', 'AR_l@1000'\n",
        "                    ]\n",
        "\n",
        "                for item in metric_items:\n",
        "                    val = float(\n",
        "                        f'{cocoEval.stats[coco_metric_names[item]]:.3f}')\n",
        "                    eval_results[item] = val\n",
        "            else:\n",
        "                cocoEval.evaluate()\n",
        "                cocoEval.accumulate()\n",
        "\n",
        "                # Save coco summarize print information to logger\n",
        "                redirect_string = io.StringIO()\n",
        "                with contextlib.redirect_stdout(redirect_string):\n",
        "                    cocoEval.summarize()\n",
        "                print_log('\\n' + redirect_string.getvalue(), logger=logger)\n",
        "\n",
        "                if classwise:  # Compute per-category AP\n",
        "                    # Compute per-category AP\n",
        "                    # from https://github.com/facebookresearch/detectron2/\n",
        "                    precisions = cocoEval.eval['precision']\n",
        "                    # precision: (iou, recall, cls, area range, max dets)\n",
        "                    assert len(self.cat_ids) == precisions.shape[2]\n",
        "\n",
        "                    results_per_category = []\n",
        "                    for idx, catId in enumerate(self.cat_ids):\n",
        "                        # area range index 0: all area ranges\n",
        "                        # max dets index -1: typically 100 per image\n",
        "                        nm = self.coco.loadCats(catId)[0]\n",
        "                        precision = precisions[:, :, idx, 0, -1]\n",
        "                        precision = precision[precision > -1]\n",
        "                        if precision.size:\n",
        "                            ap = np.mean(precision)\n",
        "                        else:\n",
        "                            ap = float('nan')\n",
        "                        results_per_category.append(\n",
        "                            (f'{nm[\"name\"]}', f'{float(ap):0.3f}'))\n",
        "\n",
        "                    num_columns = min(6, len(results_per_category) * 2)\n",
        "                    results_flatten = list(\n",
        "                        itertools.chain(*results_per_category))\n",
        "                    headers = ['category', 'AP'] * (num_columns // 2)\n",
        "                    results_2d = itertools.zip_longest(*[\n",
        "                        results_flatten[i::num_columns]\n",
        "                        for i in range(num_columns)\n",
        "                    ])\n",
        "                    table_data = [headers]\n",
        "                    table_data += [result for result in results_2d]\n",
        "                    table = AsciiTable(table_data)\n",
        "                    print_log('\\n' + table.table, logger=logger)\n",
        "\n",
        "                if metric_items is None:\n",
        "                    metric_items = [\n",
        "                        'mAP', 'mAP_50', 'mAP_75', 'mAP_s', 'mAP_m', 'mAP_l'\n",
        "                    ]\n",
        "\n",
        "                for metric_item in metric_items:\n",
        "                    key = f'{metric}_{metric_item}'\n",
        "                    val = float(\n",
        "                        f'{cocoEval.stats[coco_metric_names[metric_item]]:.3f}'\n",
        "                    )\n",
        "                    eval_results[key] = val\n",
        "                ap = cocoEval.stats[:6]\n",
        "                eval_results[f'{metric}_mAP_copypaste'] = (\n",
        "                    f'{ap[0]:.3f} {ap[1]:.3f} {ap[2]:.3f} {ap[3]:.3f} '\n",
        "                    f'{ap[4]:.3f} {ap[5]:.3f}')\n",
        "        if tmp_dir is not None:\n",
        "            tmp_dir.cleanup()\n",
        "        return eval_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A8_s1WAv29h"
      },
      "source": [
        "## Resume Experiment or Start a new training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzWq6hbr_TDX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#if you want to continue experiment from your last checkpoint, set the RESUME to True and paste the model path in model_path variable,\n",
        "#don't forget to use the same architecture/parameters in above config\n",
        "\n",
        "RESUME = True\n",
        "if RESUME:\n",
        "  model_path = \"'../input/epoch5/epoch_5.pth'\"\n",
        "  fname = 'mmdetection/configs/_base_/default_runtime.py'\n",
        "  with open(fname) as f:\n",
        "    \n",
        "      s = f.read()\n",
        "      s = re.sub('load_from = None','load_from = {}'.format(model_path), s)\n",
        "      #s = re.sub('load_from = None','resume_from = {}'.format(model_path), s)\n",
        "\n",
        "      s = re.sub(r'CLASSES = \\(.*?\\)',\"EMPTY\",s)\n",
        "\n",
        "  with open(fname, 'w') as f:\n",
        "      f.write(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwrJY9SekxTi"
      },
      "source": [
        "## My_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUVi9rrUk0OL",
        "outputId": "01598f97-7b3a-404e-ff75-d598f684279d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting query_large.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile query_large.py\n",
        "\n",
        "dataset_type = 'CocoDataset'\n",
        "data_root = 'data/coco/'\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "CLASSES = ['beetroot-steamed-without-addition-of-salt', 'bread_wholemeal', 'jam', 'water', 'bread', 'banana', 'soft_cheese', 'ham_raw', 'hard_cheese', 'cottage_cheese', 'coffee', 'fruit_mixed', 'pancake', 'tea', 'salmon_smoked', 'avocado', 'spring_onion_scallion', 'ristretto_with_caffeine', 'ham_n_s', 'egg', 'bacon', 'chips_french_fries', 'juice_apple', 'chicken', 'tomato', 'broccoli', 'shrimp_prawn', 'carrot', 'chickpeas', 'french_salad_dressing', 'pasta_hornli_ch', 'sauce_cream', 'pasta_n_s', 'tomato_sauce', 'cheese_n_s', 'pear', 'cashew_nut', 'almonds', 'lentil_n_s', 'mixed_vegetables', 'peanut_butter', 'apple', 'blueberries', 'cucumber', 'yogurt', 'butter', 'mayonnaise', 'soup', 'wine_red', 'wine_white', 'green_bean_steamed_without_addition_of_salt', 'sausage', 'pizza_margherita_baked', 'salami_ch', 'mushroom', 'tart_n_s', 'rice', 'white_coffee', 'sunflower_seeds', 'bell_pepper_red_raw', 'zucchini', 'asparagus', 'tartar_sauce', 'lye_pretzel_soft', 'cucumber_pickled_ch', 'curry_vegetarian', 'soup_of_lentils_dahl_dhal', 'salmon', 'salt_cake_ch_vegetables_filled', 'orange', 'pasta_noodles', 'cream_double_cream_heavy_cream_45', 'cake_chocolate', 'pasta_spaghetti', 'black_olives', 'parmesan', 'spaetzle', 'salad_lambs_ear', 'salad_leaf_salad_green', 'potato', 'white_cabbage', 'halloumi', 'beetroot_raw', 'bread_grain', 'applesauce', 'cheese_for_raclette_ch', 'bread_white', 'curds_natural', 'quiche', 'beef_n_s', 'taboule_prepared_with_couscous', 'aubergine_eggplant', 'mozzarella', 'pasta_penne', 'lasagne_vegetable_prepared', 'mandarine', 'kiwi', 'french_beans', 'spring_roll_fried', 'caprese_salad_tomato_mozzarella', 'leaf_spinach', 'roll_of_half_white_or_white_flour_with_large_void', 'omelette_with_flour_thick_crepe_plain', 'tuna', 'dark_chocolate', 'sauce_savoury_n_s', 'raisins_dried', 'ice_tea_on_black_tea_basis', 'kaki', 'smoothie', 'crepe_with_flour_plain', 'nuggets', 'chili_con_carne_prepared', 'veggie_burger', 'chinese_cabbage', 'hamburger', 'soup_pumpkin', 'sushi', 'chestnuts_ch', 'sauce_soya', 'balsamic_salad_dressing', 'pasta_twist', 'bolognaise_sauce', 'leek', 'fajita_bread_only', 'potato_gnocchi', 'rice_noodles_vermicelli', 'bread_whole_wheat', 'onion', 'garlic', 'hummus', 'pizza_with_vegetables_baked', 'beer', 'glucose_drink_50g', 'ratatouille', 'peanut', 'cauliflower', 'green_olives', 'bread_pita', 'pasta_wholemeal', 'sauce_pesto', 'couscous', 'sauce', 'bread_toast', 'water_with_lemon_juice', 'espresso', 'egg_scrambled', 'juice_orange', 'braided_white_loaf_ch', 'emmental_cheese_ch', 'hazelnut_chocolate_spread_nutella_ovomaltine_caotina', 'tomme_ch', 'hazelnut', 'peach', 'figs', 'mashed_potatoes_prepared_with_full_fat_milk_with_butter', 'pumpkin', 'swiss_chard', 'red_cabbage_raw', 'spinach_raw', 'chicken_curry_cream_coconut_milk_curry_spices_paste', 'crunch_muesli', 'biscuit', 'meatloaf_ch', 'fresh_cheese_n_s', 'honey', 'vegetable_mix_peas_and_carrots', 'parsley', 'brownie', 'ice_cream_n_s', 'salad_dressing', 'dried_meat_n_s', 'chicken_breast', 'mixed_salad_chopped_without_sauce', 'feta', 'praline_n_s', 'walnut', 'potato_salad', 'kolhrabi', 'alfa_sprouts', 'brussel_sprouts', 'gruyere_ch', 'bulgur', 'grapes', 'chocolate_egg_small', 'cappuccino', 'crisp_bread', 'bread_black', 'rosti_n_s', 'mango', 'muesli_dry', 'spinach', 'fish_n_s', 'risotto', 'crisps_ch', 'pork_n_s', 'pomegranate', 'sweet_corn', 'flakes', 'greek_salad', 'sesame_seeds', 'bouillon', 'baked_potato', 'fennel', 'meat_n_s', 'croutons', 'bell_pepper_red_stewed', 'nuts', 'breadcrumbs_unspiced', 'fondue', 'sauce_mushroom', 'strawberries', 'pie_plum_baked_with_cake_dough', 'potatoes_au_gratin_dauphinois_prepared', 'capers', 'bread_wholemeal_toast', 'red_radish', 'fruit_tart', 'beans_kidney', 'sauerkraut', 'mustard', 'country_fries', 'ketchup', 'pasta_linguini_parpadelle_tagliatelle', 'chicken_cut_into_stripes_only_meat', 'cookies', 'sun_dried_tomatoe', 'bread_ticino_ch', 'semi_hard_cheese', 'porridge_prepared_with_partially_skimmed_milk', 'juice', 'chocolate_milk', 'bread_fruit', 'corn', 'dates', 'pistachio', 'cream_cheese_n_s', 'bread_rye', 'witloof_chicory', 'goat_cheese_soft', 'grapefruit_pomelo', 'blue_mould_cheese', 'guacamole', 'tofu', 'cordon_bleu', 'quinoa', 'kefir_drink', 'salad_rocket', 'pizza_with_ham_with_mushrooms_baked', 'fruit_coulis', 'plums', 'pizza_with_ham_baked', 'pineapple', 'seeds_n_s', 'focaccia', 'mixed_milk_beverage', 'coleslaw_chopped_without_sauce', 'sweet_potato', 'chicken_leg', 'croissant', 'cheesecake', 'sauce_cocktail', 'croissant_with_chocolate_filling', 'pumpkin_seeds', 'artichoke', 'soft_drink_with_a_taste', 'apple_pie', 'white_bread_with_butter_eggs_and_milk', 'savoury_pastry_stick', 'tuna_in_oil_drained', 'meat_terrine_pate', 'falafel_balls', 'berries_n_s', 'latte_macchiato', 'sugar_melon_galia_honeydew_cantaloupe', 'mixed_seeds_n_s', 'oil_vinegar_salad_dressing', 'celeriac', 'chocolate_mousse', 'lemon', 'chocolate_cookies', 'birchermuesli_prepared_no_sugar_added', 'muffin', 'pine_nuts', 'french_pizza_from_alsace_baked', 'chocolate_n_s', 'grits_polenta_maize_flour', 'wine_rose', 'cola_based_drink', 'raspberries', 'roll_with_pieces_of_chocolate', 'cake_lemon', 'rice_wild', 'gluten_free_bread', 'pearl_onion', 'tzatziki', 'ham_croissant_ch', 'corn_crisps', 'lentils_green_du_puy_du_berry', 'rice_whole_grain', 'cervelat_ch', 'aperitif_with_alcohol_n_s_aperol_spritz', 'peas', 'tiramisu', 'apricots', 'lasagne_meat_prepared', 'brioche', 'vegetable_au_gratin_baked', 'basil', 'butter_spread_puree_almond', 'pie_apricot', 'rusk_wholemeal', 'pasta_in_conch_form', 'pasta_in_butterfly_form_farfalle', 'damson_plum', 'shoots_n_s', 'coconut', 'banana_cake', 'sauce_curry', 'watermelon_fresh', 'white_asparagus', 'cherries', 'nectarine']\n",
        "# albu_train_transforms = [\n",
        "#     dict(\n",
        "#         type='ShiftScaleRotate',\n",
        "#         shift_limit=0.0725,\n",
        "#         scale_limit=0.125,\n",
        "#         rotate_limit=15,\n",
        "#         interpolation=1,\n",
        "#         p=0.4),\n",
        "#     dict(\n",
        "#         type='OneOf',\n",
        "#         transforms=[\n",
        "#             dict(\n",
        "#                 type='RGBShift',\n",
        "#                 r_shift_limit=5,\n",
        "#                 g_shift_limit=5,\n",
        "#                 b_shift_limit=5,\n",
        "#                 p=1.0),\n",
        "#             dict(\n",
        "#                 type='HueSaturationValue',\n",
        "#                 hue_shift_limit=10,\n",
        "#                 sat_shift_limit=15,\n",
        "#                 val_shift_limit=10,\n",
        "#                 p=1.0),\n",
        "#             dict(\n",
        "#                 type='RandomBrightnessContrast',\n",
        "#                 brightness_limit=0.2,\n",
        "#                 contrast_limit=0.2,\n",
        "#                 p=1.0\n",
        "#             )\n",
        "#         ],\n",
        "#         p=0.2),\n",
        "#     dict(\n",
        "#         type=\"HorizontalFlip\",\n",
        "#         p=0.4\n",
        "#     ),\n",
        "#     dict(\n",
        "#         type=\"VerticalFlip\",\n",
        "#         p=0.2\n",
        "#     ),\n",
        "#     dict(\n",
        "#         type=\"RandomRotate90\",\n",
        "#         p=0.3\n",
        "#     ),\n",
        "#     dict(\n",
        "#         type=\"OneOf\",\n",
        "#         transforms=[\n",
        "#             dict(\n",
        "#                 type=\"Sequential\",\n",
        "#                 transforms = [\n",
        "#                     dict(\n",
        "#                         type='Resize',\n",
        "#                         height=800,\n",
        "#                         width=800\n",
        "#                     ),\n",
        "#                     dict(\n",
        "#                         type='RandomCrop',\n",
        "#                         height=600,\n",
        "#                         width=600\n",
        "#                     )\n",
        "#                 ]\n",
        "#             ),\n",
        "#             dict(\n",
        "#                 type=\"Sequential\",\n",
        "#                 transforms = [\n",
        "#                     dict(\n",
        "#                         type='Resize',\n",
        "#                         height=800,\n",
        "#                         width=800\n",
        "#                     ),\n",
        "#                     dict(\n",
        "#                         type='RandomCrop',\n",
        "#                         height=400,\n",
        "#                         width=400\n",
        "#                     )\n",
        "#                 ]\n",
        "#             ),\n",
        "#             dict(\n",
        "#                 type=\"Sequential\",\n",
        "#                 transforms = [\n",
        "#                     dict(\n",
        "#                         type='Resize',\n",
        "#                         height=800,\n",
        "#                         width=800\n",
        "#                     ),\n",
        "#                     dict(\n",
        "#                         type='CenterCrop',\n",
        "#                         height=500,\n",
        "#                         width=500\n",
        "#                     )\n",
        "#                 ]\n",
        "#             ),\n",
        "#         ],\n",
        "#         p=0.5\n",
        "#     ),\n",
        "#     dict(\n",
        "#         type='OneOf',\n",
        "#         transforms=[\n",
        "#             dict(type='Blur', blur_limit=5, p=1.0),\n",
        "#             dict(type='MedianBlur', blur_limit=5, p=1.0),\n",
        "#             dict(type='GaussNoise', var_limit=25, p=1.0)\n",
        "#         ],\n",
        "#         p=0.3),\n",
        "# ]\n",
        "\n",
        "# train_pipeline = [\n",
        "#     dict(type='LoadImageFromFile'),\n",
        "#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "#     dict(type='Resize', img_scale=[(448, 448), (864, 864), (1100, 1100)], keep_ratio=True, multiscale_mode='value'),\n",
        "#     dict(type='Pad', size_divisor=32),\n",
        "#     dict(\n",
        "#         type='Albu',\n",
        "#         transforms=albu_train_transforms,\n",
        "#         bbox_params=dict(\n",
        "#             type='BboxParams',\n",
        "#             format='pascal_voc',\n",
        "#             label_fields=['gt_labels'],\n",
        "#             min_visibility=0.3,\n",
        "#             filter_lost_elements=True),\n",
        "#         keymap={\n",
        "#             'img': 'image',\n",
        "#             'gt_masks': 'masks',\n",
        "#             'gt_bboxes': 'bboxes'\n",
        "#         },\n",
        "#         update_pad_shape=False,\n",
        "#         skip_img_without_anno=True),\n",
        "#     dict(type='Normalize', **img_norm_cfg),\n",
        "#     dict(type='Pad', size_divisor=32),\n",
        "#     dict(type='DefaultFormatBundle'),\n",
        "#         dict(\n",
        "#         type='Collect',\n",
        "#         keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
        "#         meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
        "#                    'pad_shape', 'scale_factor'))\n",
        "# ]\n",
        "\n",
        "\n",
        "test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=[(1000, 1000)],\n",
        "        flip=True,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **img_norm_cfg),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "# train_pipeline = [\n",
        "#     dict(type='LoadImageFromFile'),\n",
        "#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "#     dict(type='Resize', img_scale=(512, 512), keep_ratio=True), # from 512 to 1000\n",
        "#     dict(type='Normalize', **img_norm_cfg),\n",
        "#     dict(type='Pad', size_divisor=32),\n",
        "#     dict(type='DefaultFormatBundle'),\n",
        "#     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n",
        "# ]\n",
        "train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "    dict(type='Resize', img_scale=(1333, 1000), keep_ratio=True),  ### trail 1 with 1000\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(\n",
        "        type='Normalize',\n",
        "        mean=[123.675, 116.28, 103.53],\n",
        "        std=[58.395, 57.12, 57.375],\n",
        "        to_rgb=True),\n",
        "    dict(type='Pad', size_divisor=32),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(\n",
        "        type='Collect',\n",
        "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'] )\n",
        "]\n",
        "\n",
        "\n",
        "data = dict(\n",
        "    samples_per_gpu=1,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file= '/content/data/train/annotations.json',    #'/content/slice_ann.json',\n",
        "        img_prefix='/content/data/train/images' ,  #'/content/images/',\n",
        "\n",
        "        pipeline=train_pipeline\n",
        "        ,\n",
        "        classes=CLASSES),\n",
        "    val=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file='data/val/annotations.json',\n",
        "        img_prefix='data/val/images/',\n",
        "        pipeline=test_pipeline,classes=CLASSES),\n",
        "    test=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file='data/val/annotations.json',\n",
        "        img_prefix='data/val/images/',\n",
        "        pipeline=test_pipeline))\n",
        "evaluation = dict(metric=['segm'],interval=1)\n",
        "optimizer = dict(\n",
        "    type='AdamW',\n",
        "    lr=2.5e-05,\n",
        "    weight_decay=0.0001,\n",
        "    paramwise_cfg=dict(\n",
        "        custom_keys=dict(\n",
        "            absolute_pos_embed=dict(decay_mult=0.0),\n",
        "            relative_position_bias_table=dict(decay_mult=0.0),\n",
        "            norm=dict(decay_mult=0.0))))\n",
        "# optimizer_config = dict(\n",
        "#     grad_clip=dict(max_norm=1, norm_type=2),\n",
        "#     type='DistOptimizerHook',\n",
        "#     update_interval=1,\n",
        "#     coalesce=True,\n",
        "#     bucket_size_mb=-1,\n",
        "#     use_fp16=False)\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    gamma=0.5,\n",
        "    warmup='linear',\n",
        "    warmup_iters=1000,\n",
        "    warmup_ratio=0.001,\n",
        "    step=[12,20])\n",
        "runner = dict(type='EpochBasedRunner', max_epochs=30)\n",
        "checkpoint_config = dict(max_keep_ckpts=3, interval=1)\n",
        "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
        "custom_hooks = [dict(type='NumClassCheckHook')]\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "load_from = None   #'/content/drive/MyDrive/queryinst_swin_large_patch4_window7_fpn_300_queries-832c5813.pth' #None\n",
        "resume_from = '/content/drive/MyDrive/log_mmdetQuery/epoch_22.pth'     #None\n",
        "workflow = [('train', 1)]\n",
        "num_stages = 6\n",
        "num_proposals = 300\n",
        "model = dict(\n",
        "    type='QueryInst',\n",
        "    pretrained=None,\n",
        "    backbone=dict(\n",
        "        type='SwinTransformer',\n",
        "        embed_dim=192,\n",
        "        depths=[2, 2, 18, 2],\n",
        "        num_heads=[6, 12, 24, 48],\n",
        "        window_size=7,\n",
        "        mlp_ratio=4.0,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        drop_rate=0.0,\n",
        "        attn_drop_rate=0.0,\n",
        "        drop_path_rate=0.3,\n",
        "        ape=False,\n",
        "        patch_norm=True,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        use_checkpoint=False),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[192, 384, 768, 1536],\n",
        "        out_channels=256,\n",
        "        start_level=0,\n",
        "        add_extra_convs='on_input',\n",
        "        num_outs=4),\n",
        "    rpn_head=dict(\n",
        "        type='EmbeddingRPNHead',\n",
        "        num_proposals=300,\n",
        "        proposal_feature_channel=256),\n",
        "    roi_head=dict(\n",
        "        type='QueryRoIHead',\n",
        "        num_stages=6,\n",
        "        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n",
        "        proposal_feature_channel=256,\n",
        "        bbox_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        mask_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        bbox_head=[\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n",
        "        ],\n",
        "        mask_head=[\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n",
        "        ]),\n",
        "    train_cfg=dict(\n",
        "        rpn=None,\n",
        "        rcnn=[\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False)\n",
        "        ]),\n",
        "    #test_cfg=dict(rpn=None, rcnn=dict(max_per_img=300, mask_thr_binary=0.5)))\n",
        "    test_cfg=dict(rpn=None, rcnn=dict(max_per_img=70, mask_thr_binary=0.45, nms=dict(type='nms', iou_threshold=0.7))))\n",
        "total_epochs = 30\n",
        "min_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=15, norm_type=2))\n",
        "fp16 = dict(loss_scale=512.0)\n",
        "work_dir = '/content/drive/MyDrive/log_mmdetQuery'\n",
        "gpu_ids = range(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79sTIvs15Dn5"
      },
      "source": [
        "## Myconfig w/o album"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQ-fGqR5BLl",
        "outputId": "1c744953-6038-479d-f24a-a921845db562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting query_large.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile query_large.py\n",
        "\n",
        "dataset_type = 'CocoDataset'\n",
        "data_root = 'data/coco/'\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "CLASSES = ['beetroot-steamed-without-addition-of-salt', 'bread_wholemeal', 'jam', 'water', 'bread', 'banana', 'soft_cheese', 'ham_raw', 'hard_cheese', 'cottage_cheese', 'coffee', 'fruit_mixed', 'pancake', 'tea', 'salmon_smoked', 'avocado', 'spring_onion_scallion', 'ristretto_with_caffeine', 'ham_n_s', 'egg', 'bacon', 'chips_french_fries', 'juice_apple', 'chicken', 'tomato', 'broccoli', 'shrimp_prawn', 'carrot', 'chickpeas', 'french_salad_dressing', 'pasta_hornli_ch', 'sauce_cream', 'pasta_n_s', 'tomato_sauce', 'cheese_n_s', 'pear', 'cashew_nut', 'almonds', 'lentil_n_s', 'mixed_vegetables', 'peanut_butter', 'apple', 'blueberries', 'cucumber', 'yogurt', 'butter', 'mayonnaise', 'soup', 'wine_red', 'wine_white', 'green_bean_steamed_without_addition_of_salt', 'sausage', 'pizza_margherita_baked', 'salami_ch', 'mushroom', 'tart_n_s', 'rice', 'white_coffee', 'sunflower_seeds', 'bell_pepper_red_raw', 'zucchini', 'asparagus', 'tartar_sauce', 'lye_pretzel_soft', 'cucumber_pickled_ch', 'curry_vegetarian', 'soup_of_lentils_dahl_dhal', 'salmon', 'salt_cake_ch_vegetables_filled', 'orange', 'pasta_noodles', 'cream_double_cream_heavy_cream_45', 'cake_chocolate', 'pasta_spaghetti', 'black_olives', 'parmesan', 'spaetzle', 'salad_lambs_ear', 'salad_leaf_salad_green', 'potato', 'white_cabbage', 'halloumi', 'beetroot_raw', 'bread_grain', 'applesauce', 'cheese_for_raclette_ch', 'bread_white', 'curds_natural', 'quiche', 'beef_n_s', 'taboule_prepared_with_couscous', 'aubergine_eggplant', 'mozzarella', 'pasta_penne', 'lasagne_vegetable_prepared', 'mandarine', 'kiwi', 'french_beans', 'spring_roll_fried', 'caprese_salad_tomato_mozzarella', 'leaf_spinach', 'roll_of_half_white_or_white_flour_with_large_void', 'omelette_with_flour_thick_crepe_plain', 'tuna', 'dark_chocolate', 'sauce_savoury_n_s', 'raisins_dried', 'ice_tea_on_black_tea_basis', 'kaki', 'smoothie', 'crepe_with_flour_plain', 'nuggets', 'chili_con_carne_prepared', 'veggie_burger', 'chinese_cabbage', 'hamburger', 'soup_pumpkin', 'sushi', 'chestnuts_ch', 'sauce_soya', 'balsamic_salad_dressing', 'pasta_twist', 'bolognaise_sauce', 'leek', 'fajita_bread_only', 'potato_gnocchi', 'rice_noodles_vermicelli', 'bread_whole_wheat', 'onion', 'garlic', 'hummus', 'pizza_with_vegetables_baked', 'beer', 'glucose_drink_50g', 'ratatouille', 'peanut', 'cauliflower', 'green_olives', 'bread_pita', 'pasta_wholemeal', 'sauce_pesto', 'couscous', 'sauce', 'bread_toast', 'water_with_lemon_juice', 'espresso', 'egg_scrambled', 'juice_orange', 'braided_white_loaf_ch', 'emmental_cheese_ch', 'hazelnut_chocolate_spread_nutella_ovomaltine_caotina', 'tomme_ch', 'hazelnut', 'peach', 'figs', 'mashed_potatoes_prepared_with_full_fat_milk_with_butter', 'pumpkin', 'swiss_chard', 'red_cabbage_raw', 'spinach_raw', 'chicken_curry_cream_coconut_milk_curry_spices_paste', 'crunch_muesli', 'biscuit', 'meatloaf_ch', 'fresh_cheese_n_s', 'honey', 'vegetable_mix_peas_and_carrots', 'parsley', 'brownie', 'ice_cream_n_s', 'salad_dressing', 'dried_meat_n_s', 'chicken_breast', 'mixed_salad_chopped_without_sauce', 'feta', 'praline_n_s', 'walnut', 'potato_salad', 'kolhrabi', 'alfa_sprouts', 'brussel_sprouts', 'gruyere_ch', 'bulgur', 'grapes', 'chocolate_egg_small', 'cappuccino', 'crisp_bread', 'bread_black', 'rosti_n_s', 'mango', 'muesli_dry', 'spinach', 'fish_n_s', 'risotto', 'crisps_ch', 'pork_n_s', 'pomegranate', 'sweet_corn', 'flakes', 'greek_salad', 'sesame_seeds', 'bouillon', 'baked_potato', 'fennel', 'meat_n_s', 'croutons', 'bell_pepper_red_stewed', 'nuts', 'breadcrumbs_unspiced', 'fondue', 'sauce_mushroom', 'strawberries', 'pie_plum_baked_with_cake_dough', 'potatoes_au_gratin_dauphinois_prepared', 'capers', 'bread_wholemeal_toast', 'red_radish', 'fruit_tart', 'beans_kidney', 'sauerkraut', 'mustard', 'country_fries', 'ketchup', 'pasta_linguini_parpadelle_tagliatelle', 'chicken_cut_into_stripes_only_meat', 'cookies', 'sun_dried_tomatoe', 'bread_ticino_ch', 'semi_hard_cheese', 'porridge_prepared_with_partially_skimmed_milk', 'juice', 'chocolate_milk', 'bread_fruit', 'corn', 'dates', 'pistachio', 'cream_cheese_n_s', 'bread_rye', 'witloof_chicory', 'goat_cheese_soft', 'grapefruit_pomelo', 'blue_mould_cheese', 'guacamole', 'tofu', 'cordon_bleu', 'quinoa', 'kefir_drink', 'salad_rocket', 'pizza_with_ham_with_mushrooms_baked', 'fruit_coulis', 'plums', 'pizza_with_ham_baked', 'pineapple', 'seeds_n_s', 'focaccia', 'mixed_milk_beverage', 'coleslaw_chopped_without_sauce', 'sweet_potato', 'chicken_leg', 'croissant', 'cheesecake', 'sauce_cocktail', 'croissant_with_chocolate_filling', 'pumpkin_seeds', 'artichoke', 'soft_drink_with_a_taste', 'apple_pie', 'white_bread_with_butter_eggs_and_milk', 'savoury_pastry_stick', 'tuna_in_oil_drained', 'meat_terrine_pate', 'falafel_balls', 'berries_n_s', 'latte_macchiato', 'sugar_melon_galia_honeydew_cantaloupe', 'mixed_seeds_n_s', 'oil_vinegar_salad_dressing', 'celeriac', 'chocolate_mousse', 'lemon', 'chocolate_cookies', 'birchermuesli_prepared_no_sugar_added', 'muffin', 'pine_nuts', 'french_pizza_from_alsace_baked', 'chocolate_n_s', 'grits_polenta_maize_flour', 'wine_rose', 'cola_based_drink', 'raspberries', 'roll_with_pieces_of_chocolate', 'cake_lemon', 'rice_wild', 'gluten_free_bread', 'pearl_onion', 'tzatziki', 'ham_croissant_ch', 'corn_crisps', 'lentils_green_du_puy_du_berry', 'rice_whole_grain', 'cervelat_ch', 'aperitif_with_alcohol_n_s_aperol_spritz', 'peas', 'tiramisu', 'apricots', 'lasagne_meat_prepared', 'brioche', 'vegetable_au_gratin_baked', 'basil', 'butter_spread_puree_almond', 'pie_apricot', 'rusk_wholemeal', 'pasta_in_conch_form', 'pasta_in_butterfly_form_farfalle', 'damson_plum', 'shoots_n_s', 'coconut', 'banana_cake', 'sauce_curry', 'watermelon_fresh', 'white_asparagus', 'cherries', 'nectarine']\n",
        "# albu_train_transforms = [\n",
        "#     # dict(\n",
        "#     #     type='ShiftScaleRotate',\n",
        "#     #     shift_limit=0.0625,\n",
        "#     #     scale_limit=0.0,\n",
        "#     #     rotate_limit=30,\n",
        "#     #     interpolation=2,\n",
        "#     #     p=0.3),\n",
        "#     dict(\n",
        "#         type=\"HorizontalFlip\",\n",
        "#         p=0.5\n",
        "#     ),\n",
        "#     dict(\n",
        "#         type=\"RandomRotate90\",\n",
        "#         p=0.3,\n",
        "#     ),\n",
        "\n",
        "#     # dict(type='CLAHE',\n",
        "#     #     p=0.15),\n",
        "#     dict(\n",
        "#         type='RandomBrightnessContrast',\n",
        "#         brightness_limit=[0.1, 0.3],\n",
        "#         contrast_limit=[0.1, 0.3],\n",
        "#         p=0.3),\n",
        "#      dict(\n",
        "#         type=\"OneOf\",\n",
        "#         transforms=[\n",
        "#             dict(type=\"Blur\"),\n",
        "#             dict(type=\"MotionBlur\"),\n",
        "#             dict(type=\"GaussNoise\"),\n",
        "#             dict(type=\"ImageCompression\", quality_lower=75),\n",
        "#         ],\n",
        "#         p=0.4,\n",
        "#     )\n",
        "#     #  ,\n",
        "#     #  dict(\n",
        "#     #     type=\"CoarseDropout\",\n",
        "#     #     max_holes=30,\n",
        "#     #     max_height=30,\n",
        "#     #     max_width=30,\n",
        "#     #     min_holes=5,\n",
        "#     #     min_height=10,\n",
        "#     #     min_width=10,\n",
        "#     #     fill_value=img_norm_cfg[\"mean\"][::-1],\n",
        "#     #     p=0.4,)\n",
        "    \n",
        "# ]\n",
        "# train_pipeline = [\n",
        "#     dict(type='LoadImageFromFile'),\n",
        "#     dict(\n",
        "#         type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "#     dict(type='Resize', img_scale=(1333, 1000), keep_ratio=True),  ### trail 1 with 1000\n",
        "#     dict(type='RandomFlip', flip_ratio=0.5),\n",
        "#     dict(\n",
        "#         type='Albu',\n",
        "#         transforms=albu_train_transforms,\n",
        "#         bbox_params=dict(\n",
        "#             type='BboxParams',\n",
        "#             format='pascal_voc',\n",
        "#             label_fields=['gt_labels'],\n",
        "#             min_visibility=0.3,\n",
        "#             filter_lost_elements=True),\n",
        "#         keymap={\n",
        "#             'img': 'image',\n",
        "#             'gt_masks': 'masks',\n",
        "#             'gt_bboxes': 'bboxes'\n",
        "#         },\n",
        "#         update_pad_shape=False,\n",
        "#         skip_img_without_anno=True),\n",
        "#         dict(\n",
        "#         type='Normalize',\n",
        "#         mean=[123.675, 116.28, 103.53],\n",
        "#         std=[58.395, 57.12, 57.375],\n",
        "#         to_rgb=True),\n",
        "#     dict(type='Pad', size_divisor=32),\n",
        "\n",
        "#     dict(type='DefaultFormatBundle'),\n",
        "#     dict(\n",
        "#         type='Collect',\n",
        "#         keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'] ,\n",
        "#                  meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg','pad_shape', 'scale_factor')\n",
        "# )\n",
        "# ]\n",
        "\n",
        "data = dict(\n",
        "    samples_per_gpu=1,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file='data/train/new_ann.json',\n",
        "        img_prefix='data/train/images/',\n",
        "\n",
        "        pipeline=\n",
        "        [\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "            dict(type='RandomFlip', flip_ratio=0.5),\n",
        "            dict(\n",
        "                type='AutoAugment',\n",
        "                policies=[[{\n",
        "                    'type': 'Resize',\n",
        "                   # 'img_scale': [(490, 1333), (950, 1333)],\n",
        "                    'img_scale': [(490, 1333), (1100, 1333)],\n",
        "                    'multiscale_mode': 'range',\n",
        "                    'keep_ratio': True\n",
        "                }],\n",
        "                          [{\n",
        "                              'type': 'Resize',\n",
        "                              'img_scale': [(500, 1333), (700, 1333),\n",
        "                                            (800, 1333)],\n",
        "                              'multiscale_mode': 'value',\n",
        "                              'keep_ratio': True\n",
        "                          },\n",
        "                          #  {\n",
        "                          #     'type': 'RandomCrop',\n",
        "                          #     'crop_type': 'absolute_range',\n",
        "                          #     'crop_size': (384, 600),\n",
        "                          #     'allow_negative_crop': True\n",
        "                          # }, \n",
        "                           {\n",
        "                              'type': 'Resize',\n",
        "                             # 'img_scale': [(600, 1333), (950, 1333)],\n",
        "                             'img_scale': [(600, 1333), (1100, 1333)],\n",
        "                              'multiscale_mode': 'range',\n",
        "                              'override': True,\n",
        "                              'keep_ratio': True\n",
        "                          }]]),\n",
        "            dict(\n",
        "                type='Normalize',\n",
        "                mean=[123.675, 116.28, 103.53],\n",
        "                std=[58.395, 57.12, 57.375],\n",
        "                to_rgb=True),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='DefaultFormatBundle'),\n",
        "            dict(\n",
        "                type='Collect',\n",
        "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
        "        ],\n",
        "        classes=CLASSES),\n",
        "    val=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file='data/val/new_ann.json',\n",
        "        img_prefix='data/val/images/',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(1333, 800),\n",
        "                flip=False,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ],classes=CLASSES),\n",
        "    test=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file='data/val/new_ann.json',\n",
        "        img_prefix='data/val/images/',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(1333, 800),\n",
        "                flip=True,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ]))\n",
        "evaluation = dict(metric=['segm'],interval=1)\n",
        "optimizer = dict(\n",
        "    type='AdamW',\n",
        "    lr=2.5e-05,\n",
        "    weight_decay=0.0001,\n",
        "    paramwise_cfg=dict(\n",
        "        custom_keys=dict(\n",
        "            absolute_pos_embed=dict(decay_mult=0.0),\n",
        "            relative_position_bias_table=dict(decay_mult=0.0),\n",
        "            norm=dict(decay_mult=0.0))))\n",
        "# optimizer_config = dict(\n",
        "#     grad_clip=dict(max_norm=1, norm_type=2),\n",
        "#     type='DistOptimizerHook',\n",
        "#     update_interval=1,\n",
        "#     coalesce=True,\n",
        "#     bucket_size_mb=-1,\n",
        "#     use_fp16=False)\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    # gamma=0.5,\n",
        "    warmup='linear',\n",
        "    warmup_iters=1000,\n",
        "    warmup_ratio=0.001,\n",
        "    step=[12])\n",
        "runner = dict(type='EpochBasedRunner', max_epochs=22)\n",
        "checkpoint_config = dict(max_keep_ckpts=2, interval=1)\n",
        "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
        "custom_hooks = [dict(type='NumClassCheckHook')]\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "load_from = None   #'/content/drive/MyDrive/queryinst_swin_large_patch4_window7_fpn_300_queries-832c5813.pth' #None\n",
        "resume_from = '/content/drive/MyDrive/log_mmdetQuery/epoch_16.pth'     #None\n",
        "workflow = [('train', 1)]\n",
        "num_stages = 6\n",
        "num_proposals = 300\n",
        "model = dict(\n",
        "    type='QueryInst',\n",
        "    pretrained=None,\n",
        "    backbone=dict(\n",
        "        type='SwinTransformer',\n",
        "        embed_dim=192,\n",
        "        depths=[2, 2, 18, 2],\n",
        "        num_heads=[6, 12, 24, 48],\n",
        "        window_size=7,\n",
        "        mlp_ratio=4.0,\n",
        "        qkv_bias=True,\n",
        "        qk_scale=None,\n",
        "        drop_rate=0.0,\n",
        "        attn_drop_rate=0.0,\n",
        "        drop_path_rate=0.3,\n",
        "        ape=False,\n",
        "        patch_norm=True,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        use_checkpoint=False),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[192, 384, 768, 1536],\n",
        "        out_channels=256,\n",
        "        start_level=0,\n",
        "        add_extra_convs='on_input',\n",
        "        num_outs=4),\n",
        "    rpn_head=dict(\n",
        "        type='EmbeddingRPNHead',\n",
        "        num_proposals=300,\n",
        "        proposal_feature_channel=256),\n",
        "    roi_head=dict(\n",
        "        type='QueryRoIHead',\n",
        "        num_stages=6,\n",
        "        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n",
        "        proposal_feature_channel=256,\n",
        "        bbox_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        mask_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        bbox_head=[\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n",
        "            dict(\n",
        "                type='DIIHead',\n",
        "                num_classes=323,\n",
        "                num_ffn_fcs=2,\n",
        "                num_heads=8,\n",
        "                num_cls_fcs=1,\n",
        "                num_reg_fcs=3,\n",
        "                feedforward_channels=2048,\n",
        "                in_channels=256,\n",
        "                dropout=0.0,\n",
        "                ffn_act_cfg=dict(type='ReLU', inplace=True),\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=7,\n",
        "                    with_proj=True,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
        "                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n",
        "                loss_cls=dict(\n",
        "                    type='FocalLoss',\n",
        "                    use_sigmoid=True,\n",
        "                    gamma=2.0,\n",
        "                    alpha=0.25,\n",
        "                    loss_weight=2.0),\n",
        "                bbox_coder=dict(\n",
        "                    type='DeltaXYWHBBoxCoder',\n",
        "                    clip_border=False,\n",
        "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n",
        "        ],\n",
        "        mask_head=[\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "               \n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n",
        "            dict(\n",
        "                type='DynamicMaskHead',\n",
        "                dynamic_conv_cfg=dict(\n",
        "                    type='DynamicConv',\n",
        "                    in_channels=256,\n",
        "                    feat_channels=64,\n",
        "                    out_channels=256,\n",
        "                    input_feat_shape=14,\n",
        "                    with_proj=False,\n",
        "                    act_cfg=dict(type='ReLU', inplace=True),\n",
        "                    norm_cfg=dict(type='LN')),\n",
        "                dropout=0.0,\n",
        "                num_convs=4,\n",
        "                 num_classes=323,\n",
        "                roi_feat_size=14,\n",
        "                in_channels=256,\n",
        "                conv_kernel_size=3,\n",
        "                conv_out_channels=256,\n",
        "                class_agnostic=False,\n",
        "                norm_cfg=dict(type='BN'),\n",
        "                upsample_cfg=dict(type='deconv', scale_factor=2),\n",
        "                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n",
        "        ]),\n",
        "    train_cfg=dict(\n",
        "        rpn=None,\n",
        "        rcnn=[\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='HungarianAssigner',\n",
        "                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n",
        "                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n",
        "                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n",
        "                                  weight=2.0)),\n",
        "                sampler=dict(type='PseudoSampler'),\n",
        "                pos_weight=1,\n",
        "                mask_size=28,\n",
        "                debug=False)\n",
        "        ]),\n",
        "    #test_cfg=dict(rpn=None, rcnn=dict(max_per_img=300, mask_thr_binary=0.5)))\n",
        "    test_cfg=dict(rpn=None, rcnn=dict(max_per_img=100, mask_thr_binary=0.45, nms=dict(type='nms', iou_threshold=0.7))))\n",
        "total_epochs = 22\n",
        "min_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=15, norm_type=2))\n",
        "fp16 = dict(loss_scale=512.0)\n",
        "work_dir = '/content/drive/MyDrive/log_mmdetQuery'\n",
        "gpu_ids = range(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhQH3RZ3DTR7",
        "outputId": "2071eb6f-1088-438e-907f-cb9201271a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-25 00:21:16--  https://drive.google.com/file/d/1tqkpaArF0a0WVEolsCC8yrvgoydY7_Ha/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.195.139, 74.125.195.113, 74.125.195.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.195.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‚Äòpre.pth‚Äô\n",
            "\n",
            "pre.pth                 [ <=>                ]  64.85K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-04-25 00:21:16 (2.14 MB/s) - ‚Äòpre.pth‚Äô saved [66410]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O pre.pth 'https://drive.google.com/file/d/1tqkpaArF0a0WVEolsCC8yrvgoydY7_Ha/view?usp=sharing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a__jsg3SZZjI",
        "outputId": "97bb68f9-6cb7-4c30-b8a7-2047be40b6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "!unzip *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xstkfNrfe16"
      },
      "source": [
        "# Training the Model üöÇ\n",
        "\n",
        "Finally training our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1Zs__yhiZo2"
      },
      "outputs": [],
      "source": [
        "# #Lets train the model\n",
        "!pip uninstall pycocotools -y\n",
        "!pip install mmpycocotools\n",
        "!pip install --upgrade albumentations\n",
        "!pip uninstall opencv-python-headless -y\n",
        "!pip install opencv-python-headless==4.5.2.52\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:128'\n",
        "!python mmdetection/tools/train.py query_large.py --work-dir '/content/drive/MyDrive/log_mmdetQuery' #--no-validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRAJ5NcJPg35"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgUGLRIW3EVM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:128'\n",
        "# !pip uninstall pycocotools -y\n",
        "# !pip install mmpycocotools\n",
        "!python mmdetection/tools/train.py query_large.py --work-dir '/content/drive/MyDrive/trailsQuery' #--no-validate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "hO6L1LQyV4Nz",
        "outputId": "a52679d2-d616-4dcb-ae2e-273b7e4f7191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDlb1YZHAVxL"
      },
      "outputs": [],
      "source": [
        "!du -sh log_mmdet/epoch_1.pth\n",
        "!ls log_mmdet\n",
        "## loss at epoch3 1.0179 and s0.loss_mask=0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q-g3EAviAVxL"
      },
      "outputs": [],
      "source": [
        "!pip install ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_unLu4QUaB5"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1-yrXVmhUlp"
      },
      "outputs": [],
      "source": [
        "#lets get the latest checkpoint file \n",
        "\n",
        "work_dir = \"/content/drive/MyDrive/log_mmdet\"\n",
        "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n",
        "assert os.path.isfile(\n",
        "    checkpoint_file), '`{}` not exist'.format(checkpoint_file)\n",
        "checkpoint_file = os.path.abspath(checkpoint_file)\n",
        "checkpoint_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF7gRgCPhUh6"
      },
      "outputs": [],
      "source": [
        "#Lets visualize some results\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "\n",
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "import mmcv.visualization.image as mmcv_image\n",
        "# fix for colab\n",
        "\n",
        "def imshow(img, win_name='', wait_time=0): plt.figure(\n",
        "    figsize=(50, 50)); plt.imshow(img)\n",
        "\n",
        "\n",
        "mmcv_image.imshow = imshow\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import inference_detector, show_result_pyplot, init_detector\n",
        "\n",
        "\n",
        "score_thr = 0.1 #decrease the threshold if you feel like you are missing some predictions\n",
        "\n",
        "\n",
        "# build the model from a config file and a checkpoint file\n",
        "model = init_detector(config_fname, checkpoint_file)\n",
        "\n",
        "# test a single image and show the results\n",
        "img = '/content/data/val/images/008082.jpg'   #you can change this to any image you want!\n",
        "\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result, score_thr=0.1, title='result', wait_time=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DZypqZS0GVD"
      },
      "source": [
        "## Create categories files for correct annotations during inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MM7vkq0UgCg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json, os\n",
        "annotation_path = os.path.join(\"data\", \"val/annotations.json\")\n",
        "json_file = open(annotation_path)\n",
        "coco = json.load(json_file)\n",
        "\n",
        "with open(\"classes.json\",'w') as f:\n",
        "    json.dump(coco[\"categories\"],f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PKWw5xpLZB5"
      },
      "source": [
        "## Copy the config file and trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snj_hOld14N6"
      },
      "outputs": [],
      "source": [
        "#copy the trained model and config file to home directory\n",
        "%cp /content/query_large.py /content/htc_without_semantic_r50_fpn_1x_coco.py\n",
        "%cp /content/drive/MyDrive/trailsQuery/epoch_23.pth /content/latest.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxkRJocSI6li"
      },
      "source": [
        "# Quick Submission üí™\n",
        "\n",
        "## Inference on the public test set\n",
        "*   loading the model config and setting up related paths\n",
        "*   running inference and generating json file for submission\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3I3dlegLmxA",
        "outputId": "3f4ef622-a34a-4e1b-809e-682f305538bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inference_mmdet.py\n"
          ]
        }
      ],
      "source": [
        "##@title Inference code from myfood exp repo, Used for quick submission\n",
        "%%writefile inference_mmdet.py\n",
        "'''\n",
        "@Author: Gaurav Singhal\n",
        "@Description: Standalone file for testing and evaluating\n",
        "the models. It doesn't do any post-processing or ensembling.\n",
        "'''\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import warnings\n",
        "import glob\n",
        "import json\n",
        "import mmcv\n",
        "import torch\n",
        "from mmcv import Config, DictAction\n",
        "from mmcv.cnn import fuse_conv_bn\n",
        "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
        "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
        "                         wrap_fp16_model)\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "\n",
        "from mmdet.apis import multi_gpu_test\n",
        "from mmdet.datasets import (build_dataloader, build_dataset,\n",
        "                            replace_ImageToTensor)\n",
        "from mmdet.models import build_detector\n",
        "# import aicrowd_helpers\n",
        "import os.path as osp\n",
        "import traceback\n",
        "import pickle\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "import torch.distributed as dist\n",
        "from mmcv.image import tensor2imgs\n",
        "from mmdet.core import encode_mask_results\n",
        "\n",
        "import uuid\n",
        "\n",
        "# TEST_IMAGES_PATH = \"/mnt/public/xxx/imrec/data/val/images\"\n",
        "\n",
        "def create_test_predictions(images_path):\n",
        "    test_predictions_file = tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\")\n",
        "\t\n",
        "    annotations = {'categories': [], 'info': {}, 'images': []}\n",
        "    for item in glob.glob(images_path+'/*.jpg'):\n",
        "        image_dict = dict()\n",
        "        img = mmcv.imread(item)\n",
        "        height,width,__ = img.shape\n",
        "        id = int(os.path.basename(item).split('.')[0])\n",
        "        image_dict['id'] = id\n",
        "        image_dict['file_name'] = os.path.basename(item)\n",
        "        image_dict['width'] = width\n",
        "        image_dict['height'] = height\n",
        "        annotations['images'].append(image_dict)\n",
        "    annotations['categories'] = json.loads(open(\"classes.json\").read())\n",
        "    json.dump(annotations, open(test_predictions_file.name, 'w'))\n",
        "\n",
        "    return test_predictions_file\n",
        "\n",
        "def single_gpu_test(model,\n",
        "                    data_loader,\n",
        "                    show=False,\n",
        "                    out_dir=None,\n",
        "                    show_score_thr=0.3):\n",
        "    \n",
        "    model.eval()\n",
        "    results = []\n",
        "    dataset = data_loader.dataset\n",
        "    prog_bar = mmcv.ProgressBar(len(dataset))\n",
        "    for i, data in enumerate(data_loader):\n",
        "        # aicrowd_helpers.execution_progress({\"image_ids\" : [i]})\n",
        "        with torch.no_grad():\n",
        "            result = model(return_loss=False, rescale=True, **data)\n",
        "\n",
        "        batch_size = len(result)\n",
        "        if show or out_dir:\n",
        "            if batch_size == 1 and isinstance(data['img'][0], torch.Tensor):\n",
        "                img_tensor = data['img'][0]\n",
        "            else:\n",
        "                img_tensor = data['img'][0].data[0]\n",
        "            img_metas = data['img_metas'][0].data[0]\n",
        "            imgs = tensor2imgs(img_tensor, **img_metas[0]['img_norm_cfg'])\n",
        "            assert len(imgs) == len(img_metas)\n",
        "\n",
        "            for i, (img, img_meta) in enumerate(zip(imgs, img_metas)):\n",
        "                h, w, _ = img_meta['img_shape']\n",
        "                img_show = img[:h, :w, :]\n",
        "\n",
        "                ori_h, ori_w = img_meta['ori_shape'][:-1]\n",
        "                img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n",
        "\n",
        "                if out_dir:\n",
        "                    out_file = osp.join(out_dir, img_meta['ori_filename'])\n",
        "                else:\n",
        "                    out_file = None\n",
        "\n",
        "                model.module.show_result(\n",
        "                    img_show,\n",
        "                    result[i],\n",
        "                    show=show,\n",
        "                    out_file=out_file,\n",
        "                    score_thr=show_score_thr)\n",
        "\n",
        "        # Perform RLE encode for masks\n",
        "        if isinstance(result[0], tuple):\n",
        "            result = [(bbox_results, encode_mask_results(mask_results))\n",
        "                      for bbox_results, mask_results in result]\n",
        "        results.extend(result)\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            prog_bar.update()\n",
        "    return results\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='MMDet test (and eval) a model')\n",
        "    parser.add_argument('--config', help='test config file path')\n",
        "    parser.add_argument('--checkpoint', help='checkpoint file')\n",
        "    parser.add_argument('--data', help='test data folder path')\n",
        "    parser.add_argument('--out', help='output result file in pickle format')\n",
        "    parser.add_argument(\n",
        "        '--fuse-conv-bn',\n",
        "        action='store_true',\n",
        "        help='Whether to fuse conv and bn, this will slightly increase'\n",
        "        'the inference speed')\n",
        "    parser.add_argument(\n",
        "        '--format-only',\n",
        "        action='store_true',\n",
        "        help='Format the output results without perform evaluation. It is'\n",
        "        'useful when you want to format the result to a specific format and '\n",
        "        'submit it to the test server')\n",
        "    parser.add_argument(\n",
        "        '--eval',\n",
        "        type=str,\n",
        "        nargs='+',\n",
        "        help='evaluation metrics, which depends on the dataset, e.g., \"bbox\",'\n",
        "        ' \"segm\", \"proposal\" for COCO, and \"mAP\", \"recall\" for PASCAL VOC')\n",
        "    parser.add_argument('--show', action='store_true', help='show results')\n",
        "    parser.add_argument(\n",
        "        '--show-dir', help='directory where painted images will be saved')\n",
        "    parser.add_argument(\n",
        "        '--show-score-thr',\n",
        "        type=float,\n",
        "        default=0.3,\n",
        "        help='score threshold (default: 0.3)')\n",
        "    parser.add_argument(\n",
        "        '--gpu-collect',\n",
        "        action='store_true',\n",
        "        help='whether to use gpu to collect results.')\n",
        "    parser.add_argument(\n",
        "        '--tmpdir',\n",
        "        help='tmp directory used for collecting results from multiple '\n",
        "        'workers, available when gpu-collect is not specified')\n",
        "    parser.add_argument(\n",
        "        '--cfg-options',\n",
        "        nargs='+',\n",
        "        action=DictAction,\n",
        "        help='override some settings in the used config, the key-value pair '\n",
        "        'in xxx=yyy format will be merged into config file.')\n",
        "    parser.add_argument(\n",
        "        '--options',\n",
        "        nargs='+',\n",
        "        action=DictAction,\n",
        "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
        "        'format will be kwargs for dataset.evaluate() function (deprecate), '\n",
        "        'change to --eval-options instead.')\n",
        "    parser.add_argument(\n",
        "        '--eval-options',\n",
        "        nargs='+',\n",
        "        action=DictAction,\n",
        "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
        "        'format will be kwargs for dataset.evaluate() function')\n",
        "    parser.add_argument(\n",
        "        '--launcher',\n",
        "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
        "        default='none',\n",
        "        help='job launcher')\n",
        "    parser.add_argument('--out_file', help='output result file')\n",
        "    parser.add_argument('--local_rank', type=int, default=0)\n",
        "    parser.add_argument('--type', type=str, choices=['val', 'test'], default='test')\n",
        "    parser.add_argument('--reduce_ms', action='store_true',\n",
        "        help='Whether to reduce the multi-scale aug')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if 'LOCAL_RANK' not in os.environ:\n",
        "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
        "\n",
        "    if args.options and args.eval_options:\n",
        "        raise ValueError(\n",
        "            '--options and --eval-options cannot be both '\n",
        "            'specified, --options is deprecated in favor of --eval-options')\n",
        "    if args.options:\n",
        "        warnings.warn('--options is deprecated in favor of --eval-options')\n",
        "        args.eval_options = args.options\n",
        "    return args\n",
        "\n",
        "def reduce_multiscale_TTA(cfg):\n",
        "    '''\n",
        "    Keep only 1st and last image sizes from Multi-Scale TTA\n",
        "    \n",
        "    @input\n",
        "    cfg -> Configuration file\n",
        "    '''\n",
        "\n",
        "    scale = cfg.data.test.pipeline[1]['img_scale']\n",
        "    if len(scale) > 2:\n",
        "        new_scale = [scale[0], scale[-1]]\n",
        "        cfg.data.test.pipeline[1]['img_scale'] = new_scale   \n",
        "    return cfg\n",
        "\n",
        "def main():\n",
        "    ########################################################################\n",
        "    # Register Prediction Start\n",
        "    ########################################################################\n",
        "\n",
        "    # aicrowd_helpers.execution_start()\n",
        "    args = parse_args()\n",
        "    data_folder = args.data\n",
        "    # Create annotations if not already created\n",
        "    test_predictions_file = create_test_predictions(data_folder)\n",
        "    \n",
        "    # Load annotations\n",
        "    with open(test_predictions_file.name) as f:\n",
        "        annotations = json.loads(f.read())\n",
        "\n",
        "    assert args.out or args.eval or args.format_only or args.show \\\n",
        "        or args.show_dir, \\\n",
        "        ('Please specify at least one operation (save/eval/format/show the '\n",
        "         'results / save the results) with the argument \"--out\", \"--eval\"'\n",
        "         ', \"--format-only\", \"--show\" or \"--show-dir\"')\n",
        "\n",
        "    if args.eval and args.format_only:\n",
        "        raise ValueError('--eval and --format_only cannot be both specified')\n",
        "\n",
        "    if args.out is not None and not args.out.endswith(('.pkl', '.pickle')):\n",
        "        raise ValueError('The output file must be a pkl file.')\n",
        "\n",
        "    cfg = Config.fromfile(args.config)\n",
        "    if args.cfg_options is not None:\n",
        "        cfg.merge_from_dict(args.cfg_options)\n",
        "    \n",
        "    JSONFILE_PREFIX=\"predictions_{}\".format(str(uuid.uuid4())) \n",
        "    # import modules present in list of strings.\n",
        "    if cfg.get('custom_imports', None):\n",
        "        from mmcv.utils import import_modules_from_strings\n",
        "        import_modules_from_strings(**cfg['custom_imports'])\n",
        "    \n",
        "    # set cudnn_benchmark\n",
        "    if cfg.get('cudnn_benchmark', False):\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "    cfg.data.samples_per_gpu = 2\n",
        "    cfg.data.workers_per_gpu = 2\n",
        "    cfg.model.pretrained = None\n",
        "    cfg.data.test.test_mode = True\n",
        "    cfg.data.test.ann_file = test_predictions_file.name\n",
        "    cfg.data.test.img_prefix = data_folder\n",
        "\n",
        "    if cfg.model.get('neck'):\n",
        "        if isinstance(cfg.model.neck, list):\n",
        "            for neck_cfg in cfg.model.neck:\n",
        "                if neck_cfg.get('rfp_backbone'):\n",
        "                    if neck_cfg.rfp_backbone.get('pretrained'):\n",
        "                        neck_cfg.rfp_backbone.pretrained = None\n",
        "        elif cfg.model.neck.get('rfp_backbone'):\n",
        "            if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
        "                cfg.model.neck.rfp_backbone.pretrained = None\n",
        "\n",
        "    # in case the test dataset is concatenated\n",
        "    if isinstance(cfg.data.test, dict):\n",
        "        cfg.data.test.test_mode = True\n",
        "    elif isinstance(cfg.data.test, list):\n",
        "        for ds_cfg in cfg.data.test:\n",
        "            ds_cfg.test_mode = True\n",
        "\n",
        "    cfg.data.test.ann_file = test_predictions_file.name\n",
        "    cfg.data.test.img_prefix = data_folder\n",
        "        \n",
        "    # if args.reduce_ms:\n",
        "    #     print(\"Reduce multi-scale TTA\")\n",
        "    #     cfg = reduce_multiscale_tta(cfg)\n",
        "    #     print(cfg.data.test.pipeline[1]['img_scale'])\n",
        "        \n",
        "    if args.launcher == 'none':\n",
        "        distributed = False\n",
        "    else:\n",
        "        distributed = True\n",
        "        init_dist(args.launcher, **cfg.dist_params)\n",
        "    \n",
        "    # build the dataloader\n",
        "    samples_per_gpu = cfg.data.test.pop('samples_per_gpu', 1)\n",
        "    if samples_per_gpu > 1:\n",
        "        # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
        "        cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
        "    dataset = build_dataset(cfg.data.test)\n",
        "    print(dataset)\n",
        "    dataset.cat_ids = [category[\"id\"] for category in annotations[\"categories\"]]\n",
        "    data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        samples_per_gpu=1,\n",
        "        workers_per_gpu=2,\n",
        "        dist=distributed,\n",
        "        shuffle=False)\n",
        "\n",
        "    # build the model and load checkpoint\n",
        "    # model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.model.test_cfg)\n",
        "    model = init_detector(args.config,args.checkpoint,device='cuda:0')\n",
        "\n",
        "    fp16_cfg = cfg.get('fp16', None)\n",
        "    if fp16_cfg is not None:\n",
        "        wrap_fp16_model(model)\n",
        "    # checkpoint = load_checkpoint(model, args.checkpoint, map_location='cuda')\n",
        "    if args.fuse_conv_bn:\n",
        "        model = fuse_conv_bn(model)\n",
        "\n",
        "    model.CLASSES = [category['name'] for category in annotations['categories']]\n",
        "    # if 'CLASSES' in checkpoint['meta']:\n",
        "        # model.CLASSES = checkpoint['meta']['CLASSES']\n",
        "    # else:\n",
        "        # model.CLASSES = dataset.CLASSES\n",
        "\n",
        "    if not distributed:\n",
        "        model = MMDataParallel(model, device_ids=[0])\n",
        "        outputs = single_gpu_test(model, data_loader, args.show, args.show_dir,\n",
        "                                  args.show_score_thr)\n",
        "    else:\n",
        "        model = MMDistributedDataParallel(\n",
        "            model.cuda(),\n",
        "            device_ids=[torch.cuda.current_device()],\n",
        "            broadcast_buffers=False)\n",
        "        outputs = multi_gpu_test(model, data_loader, args.tmpdir,\n",
        "                                 args.gpu_collect)\n",
        "\n",
        "    rank, _ = get_dist_info()\n",
        "    if rank == 0:\n",
        "        if args.out:\n",
        "            print(f'\\nwriting results to {args.out}')\n",
        "            mmcv.dump(outputs, args.out)\n",
        "        kwargs = {} if args.eval_options is None else args.eval_options\n",
        "        if args.format_only:\n",
        "            dataset.format_results(outputs, **kwargs)\n",
        "        if args.eval:\n",
        "            eval_kwargs = cfg.get('evaluation', {}).copy()\n",
        "            for key in ['interval', 'tmpdir', 'start', 'gpu_collect']:\n",
        "                eval_kwargs.pop(key, None)\n",
        "            eval_kwargs.update(dict(metric=args.eval, **kwargs))\n",
        "            print(dataset.evaluate(outputs, **eval_kwargs))\n",
        "    \n",
        "    # consolidate_results([\"predictions.segm.json\"], 'test_predictions.json', args.out_file)\n",
        "    ########################################################################\n",
        "    # Register Prediction Complete\n",
        "    ########################################################################\n",
        "    # aicrowd_helpers.execution_success({\n",
        "    #     \"predictions_output_path\" : args.out_file\n",
        "    # })\n",
        "    print(\"\\nAICrowd register complete\")\n",
        "    # preds = []\n",
        "    # with open(\"predictions.segm.json\", \"r\") as pred_file:\n",
        "    #     preds.extend(json.loads(pred_file.read()))\n",
        "    # print(preds)\n",
        "    JSONFILE_PREFIX = args.eval_options['jsonfile_prefix']\n",
        "    shutil.move(\"{}.segm.json\".format(JSONFILE_PREFIX), args.out_file)\n",
        "    os.remove(\"{}.bbox.json\".format(JSONFILE_PREFIX))\n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        error = traceback.format_exc()\n",
        "        print(error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaRs_44KVWje"
      },
      "outputs": [],
      "source": [
        "#setting the paths for images and output file\n",
        "test_images_dir=\"/content/data/test/images\"\n",
        "output_filepath=\"/content/drive/MyDrive/trailsQuery/query_ep23_test_preds.json\"\n",
        "\n",
        "#path of trained model & config\n",
        "model_path=\"/content/latest.pth\"\n",
        "config_file=\"/content/htc_without_semantic_r50_fpn_1x_coco.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N_pxuV4O6vie",
        "outputId": "a4998b75-9794-4d43-c376-24d6cd9eb3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apex is not installed\n",
            "apex is not installed\n",
            "apex is not installed\n",
            "apex is not installed\n",
            "/content/mmdetection/mmdet/datasets/api_wrappers/coco_api.py:21: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by \"pip install pycocotools\"\n",
            "  UserWarning)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\n",
            "CocoDataset Test dataset with number of images 2819, and instance counts: \n",
            "+---------------------+-------+-----------------+-------+--------------------+-------+--------------------+-------+-------------------+-------+\n",
            "| category            | count | category        | count | category           | count | category           | count | category          | count |\n",
            "+---------------------+-------+-----------------+-------+--------------------+-------+--------------------+-------+-------------------+-------+\n",
            "| 0 [person]          | 0     | 1 [bicycle]     | 0     | 2 [car]            | 0     | 3 [motorcycle]     | 0     | 4 [airplane]      | 0     |\n",
            "| 5 [bus]             | 0     | 6 [train]       | 0     | 7 [truck]          | 0     | 8 [boat]           | 0     | 9 [traffic light] | 0     |\n",
            "| 10 [fire hydrant]   | 0     | 11 [stop sign]  | 0     | 12 [parking meter] | 0     | 13 [bench]         | 0     | 14 [bird]         | 0     |\n",
            "| 15 [cat]            | 0     | 16 [dog]        | 0     | 17 [horse]         | 0     | 18 [sheep]         | 0     | 19 [cow]          | 0     |\n",
            "| 20 [elephant]       | 0     | 21 [bear]       | 0     | 22 [zebra]         | 0     | 23 [giraffe]       | 0     | 24 [backpack]     | 0     |\n",
            "| 25 [umbrella]       | 0     | 26 [handbag]    | 0     | 27 [tie]           | 0     | 28 [suitcase]      | 0     | 29 [frisbee]      | 0     |\n",
            "| 30 [skis]           | 0     | 31 [snowboard]  | 0     | 32 [sports ball]   | 0     | 33 [kite]          | 0     | 34 [baseball bat] | 0     |\n",
            "| 35 [baseball glove] | 0     | 36 [skateboard] | 0     | 37 [surfboard]     | 0     | 38 [tennis racket] | 0     | 39 [bottle]       | 0     |\n",
            "| 40 [wine glass]     | 0     | 41 [cup]        | 0     | 42 [fork]          | 0     | 43 [knife]         | 0     | 44 [spoon]        | 0     |\n",
            "| 45 [bowl]           | 0     | 46 [banana]     | 0     | 47 [apple]         | 0     | 48 [sandwich]      | 0     | 49 [orange]       | 0     |\n",
            "| 50 [broccoli]       | 0     | 51 [carrot]     | 0     | 52 [hot dog]       | 0     | 53 [pizza]         | 0     | 54 [donut]        | 0     |\n",
            "| 55 [cake]           | 0     | 56 [chair]      | 0     | 57 [couch]         | 0     | 58 [potted plant]  | 0     | 59 [bed]          | 0     |\n",
            "| 60 [dining table]   | 0     | 61 [toilet]     | 0     | 62 [tv]            | 0     | 63 [laptop]        | 0     | 64 [mouse]        | 0     |\n",
            "| 65 [remote]         | 0     | 66 [keyboard]   | 0     | 67 [cell phone]    | 0     | 68 [microwave]     | 0     | 69 [oven]         | 0     |\n",
            "| 70 [toaster]        | 0     | 71 [sink]       | 0     | 72 [refrigerator]  | 0     | 73 [book]          | 0     | 74 [clock]        | 0     |\n",
            "| 75 [vase]           | 0     | 76 [scissors]   | 0     | 77 [teddy bear]    | 0     | 78 [hair drier]    | 0     | 79 [toothbrush]   | 0     |\n",
            "+---------------------+-------+-----------------+-------+--------------------+-------+--------------------+-------+-------------------+-------+\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/conv_module.py:151: UserWarning: Unnecessary conv bias before batch/instance norm\n",
            "  'Unnecessary conv bias before batch/instance norm')\n",
            "load checkpoint from local path: /content/latest.pth\n",
            "[                                                  ] 0/2819, elapsed: 0s, ETA:/content/mmdetection/mmdet/models/roi_heads/query_roi_head.py:474: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  num_classes]\n",
            "[  ] 340/2819, 1.0 task/s, elapsed: 354s, ETA:  2582stcmalloc: large alloc 1706991616 bytes == 0x186018000 @  0x7f6b207fb1e7 0x7f6b1e10c0ce 0x7f6b1e162cf5 0x7f6b1e20b86d 0x7f6b1e20c17f 0x7f6b1e20c2d0 0x4bc4ab 0x7f6b1e14d944 0x59371f 0x515244 0x549576 0x593fce 0x548ae9 0x51566f 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x5134a6\n",
            "[> ] 1559/2819, 1.0 task/s, elapsed: 1626s, ETA:  1314stcmalloc: large alloc 1706991616 bytes == 0x186018000 @  0x7f6b207fb1e7 0x7f6b1e10c0ce 0x7f6b1e162cf5 0x7f6b1e20b86d 0x7f6b1e20c17f 0x7f6b1e20c2d0 0x4bc4ab 0x7f6b1e14d944 0x59371f 0x515244 0x549576 0x593fce 0x548ae9 0x51566f 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x5134a6\n",
            "[>>] 2819/2819, 1.0 task/s, elapsed: 2940s, ETA:     0s\n",
            "AICrowd register complete\n"
          ]
        }
      ],
      "source": [
        "!python inference_mmdet.py --config $config_file --checkpoint $model_path \\\n",
        "--data $test_images_dir \\\n",
        "--format-only --eval-options \"jsonfile_prefix=preds\" --out_file $output_filepath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tALk5JdRkJsk"
      },
      "source": [
        "Now that the prediction file is generated for public test set, To make quick submission:\n",
        "* Use AIcrowd CLL `aicrowd submit` command to do a quick submission. </br>\n",
        "\n",
        "**Alternatively:**\n",
        "* download the `predictions_mmdetection.json` file by running below cell\n",
        "* visit the [create submission page](https://www.aicrowd.com/challenges/food-recognition-benchmark-2022/submissions/new) \n",
        "* Upload the `predictions_mmdetection.json` file \n",
        "* Voila!! You just made your first submission!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk-T7fKAxR2c"
      },
      "outputs": [],
      "source": [
        "#use aicrowd CLI to make quick submission\n",
        "!aicrowd submission create -c food-recognition-benchmark-2022 -f $output_filepath >> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iijfdw1VgXke"
      },
      "source": [
        "#Active submission ü§©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTtj3n0RrcjH"
      },
      "source": [
        "Step 0 : Fork the baseline to make your own changes to it. Go to settings and make the repo private.\n",
        "\n",
        "\n",
        "Step 1 : For first time setup, Setting up SSH to login to Gitlab.\n",
        "\n",
        "  0. Run the next cell to check if you already have SSH keys in your drive, if yes, skip this step. \n",
        "  1. Run `ssh-keygen -t ecdsa -b 521` \n",
        "  2. Run `cat ~./ssh/id_ecdsa.pub` and copy the output\n",
        "  3. Go to [Gitlab SSH Keys](https://gitlab.aicrowd.com/profile/keys) and then paste the output inside the key and use whaever title you like. \n",
        "\n",
        "\n",
        "Step 2: Clone your forked Repo & Add Models & Push Changes\n",
        "\n",
        "  1. Run `git clone git@gitlab.aicrowd.com:[Your Username]/mmdetection-starter-food-2022.git`\n",
        "  2. Put your model inside the models directioary and then run `git-lfs track \"*.pth\"`\n",
        "  3. Run `git add .` then `git commit -m \" adding model\"`\n",
        "  3. Run `git push origin master`\n",
        "\n",
        "Step 3. Create Submission\n",
        "\n",
        "  1. Go to the repo and then tags and then New Tag. \n",
        "  2. In the tag name,you can use `submission_v1`, ( Everytime you make a new submission, just increase the no. like - `submission_v2`,  `submission_v3` )\n",
        "  3. A new issue will be created with showing the process. Enjoy!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "If you do not have SSH Keys, Check this [Page](https://docs.gitlab.com/ee/ssh/index.html#generate-an-ssh-key-pair)\n",
        "\n",
        "Add your SSH Keys to your GitLab account by following the instructions here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMX3ttbbnRLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f918a1da-ddf5-4522-bb28-13e178d928c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSH Key found! ‚úÖ\\n\n",
            "SSH key successfully copied to local!\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "SSH_PRIV_KEY=/content/drive/MyDrive/id_ecdsa\n",
        "SSH_PUB_KEY=/content/drive/MyDrive/id_ecdsa.pub\n",
        "if [ -f \"$SSH_PRIV_KEY\" ]; then\n",
        "    echo \"SSH Key found! ‚úÖ\\n\"\n",
        "    mkdir -p /root/.ssh\n",
        "    cp /content/drive/MyDrive/id_ecdsa ~/.ssh/id_ecdsa\n",
        "    cp /content/drive/MyDrive/id_ecdsa.pub ~/.ssh/id_ecdsa.pub\n",
        "    echo \"SSH key successfully copied to local!\"\n",
        "else\n",
        "    echo \"SSH Key does not exist.\"\n",
        "    ssh-keygen -t ecdsa -b521 -f ~/.ssh/id_ecdsa\n",
        "    cat ~/.ssh/id_ecdsa.pub\n",
        "    echo \"‚ùóÔ∏èPlease open https://gitlab.aicrowd.com/profile/keys and copy-paste the above text in the **key** textbox.\"\n",
        "    cp  ~/.ssh/id_ecdsa /content/drive/MyDrive/id_ecdsa\n",
        "    cp  ~/.ssh/id_ecdsa.pub /content/drive/MyDrive/id_ecdsa.pub\n",
        "    echo \"SSH key successfully created and copied to drive!\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5NUAlB1ONYZ"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "html = \"<b>Copy paste below SSH key in your GitLab account here (one time):</b><br/>\"\n",
        "html += '<a href=\"https://gitlab.aicrowd.com/-/profile/keys\" target=\"_blank\">https://gitlab.aicrowd.com/-/profile/keys</a><br><br>'\n",
        "\n",
        "public_key = open(\"/content/drive/MyDrive/id_ecdsa.pub\").read()\n",
        "html += '<br/><textarea>'+public_key+'</textarea><button onclick=\"navigator.clipboard.writeText(\\''+public_key.strip()+'\\');this.innerHTML=\\'Copied ‚úÖ\\'\">Click to copy</button>'\n",
        "IPython.display.HTML(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4bMsMOuqXWG"
      },
      "source": [
        "Clone the gitlab starter repo and add submission files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8VOx9WUWvqW"
      },
      "outputs": [],
      "source": [
        "# Set your AIcrowd username for action submission.\n",
        "# This username will store repository and used for submitter's username, etc\n",
        "username = \"saidinesh_pola\"\n",
        "!echo -n {username} > author.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX54KjC7qKXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05c41f1-286f-44a7-93cc-67bae5aabe99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username saidinesh_pola\n",
            "Git LFS initialized.\n",
            "Checking if repository already exist, otherwise create one\n",
            "cloning the git@gitlab.aicrowd.com:saidinesh_pola/mmdetection-starter-food-2022.git\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Cloning into 'mmdetection-starter-food-2022'...\n",
            "Warning: Permanently added the ECDSA host key for IP address '18.195.37.41' to the list of known hosts.\r\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x5570707bc000 @  0x7efc5e2fa2a4 0x557033e9fe8f 0x557033e7cfcb 0x557033e31f33 0x557033dd622a 0x557033dd66e6 0x557033df3451 0x557033df39e9 0x557033df3f13 0x557033e98b82 0x557033d3a162 0x557033d20a65 0x557033d21725 0x557033d2072a 0x7efc5d640c87 0x557033d2077a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x5570c82ac000 @  0x7efc5e2fa2a4 0x557033e9fe8f 0x557033e7cfcb 0x557033e31f33 0x557033dd622a 0x557033dd66e6 0x557033df3451 0x557033df39e9 0x557033df3f13 0x557033e98b82 0x557033d3a162 0x557033d20a65 0x557033d21725 0x557033d2072a 0x7efc5d640c87 0x557033d2077a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x55714bb12000 @  0x7efc5e2fa2a4 0x557033e9fe8f 0x557033e7cfcb 0x557033e31f33 0x557033dd622a 0x557033dd66e6 0x557033df3451 0x557033df39e9 0x557033df3f13 0x557033e98b82 0x557033d3a162 0x557033d20a65 0x557033d21725 0x557033d2072a 0x7efc5d640c87 0x557033d2077a\n",
            "tcmalloc: large alloc 4964900864 bytes == 0x557243146000 @  0x7efc5e2fa2a4 0x557033e9fe8f 0x557033e7cfcb 0x557033e31f33 0x557033dd622a 0x557033dd66e6 0x557033df3451 0x557033df39e9 0x557033df3f13 0x557033e98b82 0x557033d3a162 0x557033d20a65 0x557033d21725 0x557033d2072a 0x7efc5d640c87 0x557033d2077a\n",
            "Filtering content: 100% (2/2), 3.86 GiB | 18.27 MiB/s   \rFiltering content: 100% (2/2), 3.86 GiB | 17.96 MiB/s, done.\n",
            "Encountered %!d(MISSING) file(s) that may not have been copied correctly on Windows:\n",
            "\tmodels/latest.pth\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "username=$(cat author.txt)\n",
        "echo \"Username $username\"\n",
        "\n",
        "git config --global user.name \"$username\"\n",
        "git config --global user.email \"$username@noreply.gitlab.aicrowd.com\"\n",
        "\n",
        "touch ${HOME}/.ssh/known_hosts\n",
        "ssh-keyscan -H gitlab.aicrowd.com >> ${HOME}/.ssh/known_hosts 2> /dev/null\n",
        "\n",
        "\n",
        "apt install -qq -y jq git-lfs &> /dev/null\n",
        "\n",
        "git lfs install\n",
        "cd /content/\n",
        "\n",
        "echo \"Checking if repository already exist, otherwise create one\"\n",
        "export SUBMISSION_REPO=\"git@gitlab.aicrowd.com:$username/mmdetection-starter-food-2022.git\"\n",
        "echo \"cloning the $SUBMISSION_REPO\"\n",
        "git clone $SUBMISSION_REPO mmdetection-starter-food-2022\n",
        "ALREADYEXIST=$?\n",
        "\n",
        "if [ $ALREADYEXIST -ne 0 ]; then\n",
        "  echo \"Project didn't exist, forking from upstream\"\n",
        "  git clone https://github.com/AIcrowd/food-recognition-benchmark-starter-kit.git mmdetection-starter-food-2022\n",
        "fi\n",
        "\n",
        "cd /content/mmdetection-starter-food-2022\n",
        "git remote remove origin\n",
        "git remote add origin \"$SUBMISSION_REPO\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXGI6THoJglP"
      },
      "source": [
        "## To make active submission:\n",
        "* Required Files are `aicrowd.json, apt.txt, requirements.txt, predict.py` (already configured for mmdetection)\n",
        "* **[IMP]** Copy mmdetection trained model, corresponding config file to repo\n",
        "* for inference place these files : `predict_mmdetection.py mmdet_inference.py` (already present in repo)\n",
        "* Modify requirements.txt and `predict.py` for mmdetection\n",
        "* **[IMP]** Modify `aicrowd.json` for your submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy7mjKukKKMH"
      },
      "source": [
        "**Note:** You only need to place your trained model and modify aicrowd.json to create your first easy submission. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QdHHINoCb9bD"
      },
      "outputs": [],
      "source": [
        "#@title Modify mmdet_inference.py (modify and run only if you want to change the inference)\n",
        "%%writefile /content/mmdetection-starter-food-2022/utils/mmdet_inference.py\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import torch\n",
        "from mmcv.ops import RoIPool\n",
        "from mmcv.parallel import collate, scatter\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmdet.core import get_classes\n",
        "from mmdet.datasets import replace_ImageToTensor\n",
        "from mmdet.datasets.pipelines import Compose\n",
        "from mmdet.models import build_detector\n",
        "# import time\n",
        "\n",
        "\n",
        "def inference(model, imgs):\n",
        "\n",
        "    # start = time.process_time()\n",
        "    imgs = [imgs]\n",
        "    cfg = model.cfg\n",
        "    device = 'cuda:0'\n",
        "    if isinstance(imgs[0], np.ndarray):\n",
        "        cfg = cfg.copy()\n",
        "        # set loading pipeline type\n",
        "        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
        "\n",
        "    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
        "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
        "\n",
        "    datas = []\n",
        "    data = dict(img_info=dict(filename=imgs[0]), img_prefix=None)\n",
        "    # build the data pipeline\n",
        "    data = test_pipeline(data)\n",
        "    datas.append(data)\n",
        "\n",
        "    data = collate(datas, samples_per_gpu=len(imgs))\n",
        "    # just get the actual data from DataContainer\n",
        "    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
        "    data['img'] = [img.data[0] for img in data['img']]\n",
        "    # scatter to specified GPU\n",
        "    data = scatter(data, [device])[0]\n",
        "    \n",
        "    # forward the model\n",
        "    with torch.no_grad():\n",
        "        results = model(return_loss=False, rescale=True, **data)\n",
        "    # your code here    \n",
        "    # print(time.process_time() - start)\n",
        "    return results[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "66EXvv_OAeB4"
      },
      "outputs": [],
      "source": [
        "#@title Modify predict_mmdetection.py (modify & run this only if you want to change inference code part)\n",
        "%%writefile /content/mmdetection-starter-food-2022/predict_mmdetection.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from PIL import Image\n",
        "import importlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import traceback\n",
        "import pickle\n",
        "import shutil\n",
        "import glob\n",
        "import tempfile\n",
        "import time\n",
        "import mmcv\n",
        "import torch.distributed as dist\n",
        "from mmcv.image import tensor2imgs\n",
        "from mmdet.core import encode_mask_results\n",
        "from mmcv import Config, DictAction\n",
        "from mmcv.cnn import fuse_conv_bn\n",
        "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
        "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
        "                         wrap_fp16_model)\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "\n",
        "from mmdet.apis import multi_gpu_test\n",
        "from mmdet.datasets import (build_dataloader, build_dataset,\n",
        "                            replace_ImageToTensor)\n",
        "from mmdet.models import build_detector\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "from utils.mmdet_inference import inference\n",
        "from evaluator.food_challenge import FoodChallengePredictor\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Expected ENVIRONMENT Variables\n",
        "* AICROWD_TEST_IMAGES_PATH : abs path to  folder containing all the test images\n",
        "* AICROWD_PREDICTIONS_OUTPUT_PATH : path where you are supposed to write the output predictions.json\n",
        "\"\"\"\n",
        "\n",
        "class MMDetectionPredictor(FoodChallengePredictor):\n",
        "\n",
        "    \"\"\"\n",
        "    PARTICIPANT_TODO:\n",
        "    You can do any preprocessing required for your codebase here like loading up models into memory, etc.\n",
        "    \"\"\"\n",
        "    def prediction_setup(self):\n",
        "        # self.PADDING = 50\n",
        "        # self.SEGMENTATION_LENGTH = 10\n",
        "        # self.MAX_NUMBER_OF_ANNOTATIONS = 10\n",
        "\n",
        "        #set the config parameters, including the architecture which was previously used\n",
        "        self.cfg_name, self.checkpoint_name = self.get_mmdetection_config()\n",
        "        self.cfg = Config.fromfile(self.cfg_name)\n",
        "        # self.test_img_path = os.getenv(\"AICROWD_TEST_IMAGES_PATH\", os.getcwd() + \"/data/images/\")\n",
        "        self.test_predictions_file = self.create_test_predictions(self.test_data_path)\n",
        "\n",
        "        if self.cfg.get('cudnn_benchmark', False):\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "        self.cfg.data.samples_per_gpu = 1\n",
        "        self.cfg.data.workers_per_gpu = 2\n",
        "        self.cfg.model.pretrained = None\n",
        "        self.cfg.data.test.test_mode = True\n",
        "        self.cfg.data.test.ann_file = self.test_predictions_file.name\n",
        "        self.cfg.data.test.img_prefix = self.test_data_path\n",
        "\n",
        "        self.model = init_detector(self.cfg_name,self.checkpoint_name,device='cuda:0')\n",
        "\n",
        "        fp16_cfg = self.cfg.get('fp16', None)\n",
        "        if fp16_cfg is not None:\n",
        "            wrap_fp16_model(self.model)\n",
        "\n",
        "         # Load annotations\n",
        "        with open(self.test_predictions_file.name) as f:\n",
        "            self.annotations = json.loads(f.read())\n",
        "        self.cat_ids = [category[\"id\"] for category in self.annotations[\"categories\"]]\n",
        "\n",
        "        self.model.CLASSES = [category['name'] for category in self.annotations['categories']]\n",
        "\n",
        "    \"\"\"\n",
        "    PARTICIPANT_TODO:\n",
        "    During the evaluation all image file path will be provided one by one.\n",
        "    NOTE: In case you want to load your model, please do so in `predict_setup` function.\n",
        "    \"\"\"\n",
        "    def prediction(self, image_path):\n",
        "        print(\"Generating for\", image_path)\n",
        "        # read the image\n",
        "        result = inference(self.model, image_path)\n",
        "        #RLE Encode the masks\n",
        "        result = (result[0], encode_mask_results(result[1]))\n",
        "        result = self.segm2jsonformat(result,image_path)\n",
        "        return result\n",
        "\n",
        "    def xyxy2xywh(self,bbox):\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0] + 1,\n",
        "            _bbox[3] - _bbox[1] + 1,\n",
        "        ]\n",
        "\n",
        "    def segm2jsonformat(self, result,image_path):\n",
        "        segm_json_results = []\n",
        "        img_id = int(os.path.basename(image_path).split(\".\")[0])\n",
        "        det, seg = result\n",
        "        # print(\"image:\",img_id)\n",
        "        for label in range(len(det)):\n",
        "                bboxes = det[label]\n",
        "                #print(type(bboxes))\n",
        "                segms = seg[label]\n",
        "                mask_score = [bbox[4] for bbox in bboxes]\n",
        "                for i in range(len(bboxes)):\n",
        "                        data = dict()\n",
        "                        data['image_id'] = img_id\n",
        "                        data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                        data['score'] = float(mask_score[i])\n",
        "                        data['category_id'] = self.cat_ids[label]\n",
        "                        if isinstance(segms[i]['counts'], bytes):\n",
        "                                segms[i]['counts'] = segms[i]['counts'].decode()\n",
        "                        data['segmentation'] = segms[i]\n",
        "                        segm_json_results.append(data)\n",
        "        return segm_json_results\n",
        "\n",
        "\n",
        "    def create_test_predictions(self,images_path):\n",
        "        test_predictions_file = tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\")\n",
        "        annotations = {'categories': [], 'info': {}, 'images': []}\n",
        "        for item in glob.glob(images_path+'/*.jpg'):\n",
        "            image_dict = dict()\n",
        "            img = mmcv.imread(item)\n",
        "            height,width,__ = img.shape\n",
        "            id = int(os.path.basename(item).split('.')[0])\n",
        "            image_dict['image_id'] = id\n",
        "            image_dict['file_name'] = os.path.basename(item)\n",
        "            image_dict['width'] = width\n",
        "            image_dict['height'] = height\n",
        "            annotations['images'].append(image_dict)\n",
        "        annotations['categories'] = json.loads(open(\"classes.json\").read())\n",
        "        json.dump(annotations, open(test_predictions_file.name, 'w'))\n",
        "\n",
        "        return test_predictions_file\n",
        "\n",
        "    def get_mmdetection_config(self):\n",
        "        with open('aicrowd.json') as f:\n",
        "            content = json.load(f)\n",
        "            config_fname = content['model_config_file']\n",
        "            checkpoint_fname = content['model_path']\n",
        "        # config = Config.fromfile(config_fname)\n",
        "        return (config_fname, checkpoint_fname)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    submission = MMDetectionPredictor()\n",
        "    submission.run()\n",
        "    print(\"Successfully generated predictions!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIekmrfZLOJD"
      },
      "outputs": [],
      "source": [
        "MODEL_ARCH = \"htc_without_semantic_r50_fpn_1x_coco.py\"\n",
        "aicrowd_json = {\n",
        "  \"challenge_id\" : \"food-recognition-benchmark-2022\",\n",
        "  \"authors\" : [\"pola_saidinesh\"],\n",
        "  \"description\" : \"Food Recognition Benchmark 2022 Submission mmdetection\",\n",
        "  \"license\" : \"MIT\",\n",
        "  \"gpu\": True,\n",
        "  \"debug\": False,\n",
        "  \"model_path\": \"models/latest.pth\",\n",
        "  \"model_type\": \"mmdetection\",\n",
        "  \"model_config_file\": \"models/\" + MODEL_ARCH\n",
        "}\n",
        "import json\n",
        "with open('/content/mmdetection-starter-food-2022/aicrowd.json', 'w') as fp:\n",
        "  fp.write(json.dumps(aicrowd_json, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aRgmsuQPBUJ"
      },
      "source": [
        "### Copy required files (trained model, config, classes.json) to mmdetection repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WorE1uF3OTJH"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/mmdetection-starter-food-2022/models\n",
        "#!cp /content/classes.json /content/mmdetection-starter-food-2022/utils/classes.json\n",
        "!cp /content/drive/MyDrive/log_mmdetQuery/epoch_23.pth /content/mmdetection-starter-food-2022/models/latest.pth\n",
        "#!cp $MODEL_ARCH /content/mmdetection-starter-food-2022/models/$MODEL_ARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJnxrSS0PZAp"
      },
      "source": [
        "### Finally push the repo for active submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO1Zu8V5MH_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81deb196-e4c5-4096-edff-b6820e41c7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username saidinesh_pola\n",
            "\"*.pth\" already supported\n",
            "[ep14 62b6eaa] mmdetection_submission_v2_ep23_old\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Error scanning for Git LFS files in the \"master\" ref\n",
            "\rGit LFS: (0 of 1 files, 10 skipped) 0 B / 3.85 GB, 19.59 GB skipped            \rGit LFS: (0 of 1 files, 10 skipped) 192.00 KB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 288.00 KB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 864.00 KB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 1.66 MB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 5.34 MB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 7.12 MB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 10.34 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 16.97 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 20.44 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 23.94 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 31.00 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 34.59 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 39.78 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 44.94 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 48.44 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 53.72 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 58.94 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 62.38 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 69.19 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 72.81 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 76.34 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 83.19 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 86.75 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 90.25 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 97.22 MB / 3.85 GB, 19.59 GB skipped       \rGit LFS: (0 of 1 files, 10 skipped) 100.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 104.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 111.16 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 113.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 118.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 124.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 127.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 133.12 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 137.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 141.00 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 147.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 151.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 154.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 161.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 164.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 168.12 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 175.28 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 178.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 182.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 188.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 192.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 197.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 202.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 205.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 212.41 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 215.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 219.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 225.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 229.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 232.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 240.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 243.56 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 246.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 253.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 257.41 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 260.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 267.69 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 271.16 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 276.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 281.41 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 284.94 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 290.22 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 295.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 298.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 305.47 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 309.09 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 312.59 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 319.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 322.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 326.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 333.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 336.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 340.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 347.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 350.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 355.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 360.56 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 364.09 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 369.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 374.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 377.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 384.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 387.62 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 390.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 397.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 401.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 404.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 411.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 414.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 419.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 424.72 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 428.09 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 433.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 438.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 441.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 448.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 451.69 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 455.16 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 461.88 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 465.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 468.94 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 475.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 479.16 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 483.69 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 489.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 493.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 498.56 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 503.59 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 507.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 512.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 517.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 520.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 527.00 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 530.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 533.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 540.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 544.12 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 547.41 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 554.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 557.88 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 562.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 568.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 571.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 576.59 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 581.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 585.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 591.88 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 595.47 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 598.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 605.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 608.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 612.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 618.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 622.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 627.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 632.72 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 636.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 641.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 646.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 650.28 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 655.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 660.59 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 663.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 670.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 674.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 677.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 684.62 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 688.22 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 691.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 698.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 702.28 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 705.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 712.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 715.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 720.88 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 725.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 729.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 734.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 739.88 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 743.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 749.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 753.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 757.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 764.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 767.59 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 770.94 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 777.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 781.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 784.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 791.66 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 795.12 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 799.44 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 805.19 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 808.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 814.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 818.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 822.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 829.00 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 832.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 836.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 842.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 846.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 849.22 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 855.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 859.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 864.22 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 869.41 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 872.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 877.84 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 883.03 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 886.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 892.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 896.47 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 899.81 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 907.00 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 910.16 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 913.75 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 920.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 923.91 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 927.56 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 934.25 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 937.53 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 942.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 947.47 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 950.69 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 957.50 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 961.00 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 964.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 971.34 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 974.78 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 978.31 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 985.06 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 988.38 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 991.97 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 998.69 MB / 3.85 GB, 19.59 GB skipped      \rGit LFS: (0 of 1 files, 10 skipped) 1002.22 MB / 3.85 GB, 19.59 GB skipped     \rGit LFS: (0 of 1 files, 10 skipped) 1007.12 MB / 3.85 GB, 19.59 GB skipped     \rGit LFS: (0 of 1 files, 10 skipped) 1012.41 MB / 3.85 GB, 19.59 GB skipped     \rGit LFS: (0 of 1 files, 10 skipped) 1015.81 MB / 3.85 GB, 19.59 GB skipped     \rGit LFS: (0 of 1 files, 10 skipped) 1021.16 MB / 3.85 GB, 19.59 GB skipped     \rGit LFS: (0 of 1 files, 10 skipped) 1.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.67 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.67 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.86 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.86 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.86 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.87 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.87 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.88 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.88 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.89 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.89 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.90 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.90 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.91 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.91 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.92 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.92 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.93 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.93 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.93 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.94 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.94 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.95 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.95 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.96 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.96 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.97 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.97 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.98 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.98 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.98 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.99 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 1.99 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.67 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.67 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.86 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.86 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.87 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.87 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.88 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.88 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.89 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.89 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.90 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.90 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.91 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.91 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.92 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.92 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.92 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.93 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.93 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.94 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.94 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.95 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.95 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.96 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.96 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.96 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.97 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.97 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.98 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.98 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.99 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 2.99 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.00 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.01 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.02 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.03 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.04 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.05 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.06 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.07 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.08 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.09 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.10 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.11 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.12 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.13 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.14 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.15 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.16 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.17 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.18 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.19 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.20 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.21 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.22 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.23 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.24 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.25 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.26 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.27 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.28 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.29 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.30 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.31 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.32 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.33 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.34 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.35 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.36 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.37 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.38 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.39 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.40 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.41 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.42 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.43 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.44 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.45 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.46 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.47 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.48 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.49 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.50 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.51 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.52 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.53 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.54 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.55 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.56 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.57 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.58 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.59 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.60 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.61 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.62 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.63 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.64 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.65 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.66 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.67 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.68 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.69 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.70 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.71 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.72 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.73 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.74 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.75 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.76 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.77 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.78 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.79 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.80 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.81 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.82 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.83 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.84 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (0 of 1 files, 10 skipped) 3.85 GB / 3.85 GB, 19.59 GB skipped        \rGit LFS: (1 of 1 files, 10 skipped) 3.85 GB / 3.85 GB, 19.59 GB skipped        \n",
            "Track your submission status here: https://gitlab.aicrowd.com/saidinesh_pola/mmdetection-starter-food-2022/issues\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encountered %!d(MISSING) file(s) that may not have been copied correctly on Windows:\n",
            "\tmodels/latest.pth\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n",
            "Error in git rev-list --objects master --not --remotes=origin --: exit status 128 fatal: bad revision 'master'\n",
            "\n",
            "error: src refspec master does not match any.\n",
            "error: failed to push some refs to 'git@gitlab.aicrowd.com:saidinesh_pola/mmdetection-starter-food-2022.git'\n",
            "remote: \n",
            "remote:           #///(            )///#        \n",
            "remote:          ////      ///      ////        \n",
            "remote:         /////   //////////   ////        \n",
            "remote:         /////////////////////////        \n",
            "remote:      /// /////////////////////// ///        \n",
            "remote:    ///////////////////////////////////        \n",
            "remote:   /////////////////////////////////////        \n",
            "remote:     )////////////////////////////////(        \n",
            "remote:      /////                      /////        \n",
            "remote:    (///////   ///       ///    //////)        \n",
            "remote:   ///////////    ///////     //////////        \n",
            "remote: (///////////////////////////////////////)        \n",
            "remote:           /////           /////        \n",
            "remote:             /////////////////        \n",
            "remote:                ///////////        \n",
            "remote: \n",
            "To gitlab.aicrowd.com:saidinesh_pola/mmdetection-starter-food-2022.git\n",
            " * [new tag]         submission_mmdetection_submission_v2_ep23_old -> submission_mmdetection_submission_v2_ep23_old\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "## Set your unique tag for this submission (no spaces), example:\n",
        "# export MSG=\"v1\"\n",
        "# export MSG=\"v2\" ...\n",
        "# or something more informative...\n",
        "export MSG=\"mmdetection_submission_v2_ep23_old\"\n",
        "\n",
        "username=$(cat author.txt)\n",
        "echo \"Username $username\"\n",
        "\n",
        "\n",
        "cd /content/mmdetection-starter-food-2022\n",
        "git lfs track \"*.pth\"\n",
        "git add .gitattributes\n",
        "git add --all\n",
        "git commit -m \"$MSG\" || true\n",
        "\n",
        "find . -type f -size +5M -exec git lfs migrate import --include={} &> /dev/null \\;\n",
        "\n",
        "git tag -am \"submission_$MSG\" \"submission_$MSG\"\n",
        "git config lfs.https://gitlab.aicrowd.com/$username/mmdetection-starter-food-2022.git/info/lfs.locksverify false\n",
        "\n",
        "git remote remove origin\n",
        "git remote add origin git@gitlab.aicrowd.com:$username/mmdetection-starter-food-2022.git\n",
        "\n",
        "git lfs push origin master\n",
        "git push origin master\n",
        "git push origin \"submission_$MSG\"\n",
        "\n",
        "echo \"Track your submission status here: https://gitlab.aicrowd.com/$username/mmdetection-starter-food-2022/issues\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKuN7XOKJFT2"
      },
      "source": [
        "## Local Evaluation for Active Submission Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOATB0cWXbt2"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/mmdetection-starter-food-2022\n",
        "\n",
        "export TEST_DATASET_PATH=../data/test/images\n",
        "export RESULTS_DATASET_PATH=../data\n",
        "./run.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sahi Stuff"
      ],
      "metadata": {
        "id": "rEjB3hR0Retr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sahi coco evaluate --result_json_path  /content/drive/MyDrive/Preds/query_ep22_val_preds.json --dataset_json_path data/val/annotations.json --type segm --out_dir output/directory"
      ],
      "metadata": {
        "id": "PG8lfld8-ImQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/sahi_error_analysis.py --result_json_path  /content/drive/MyDrive/Preds/query_ep22_val_preds.json --dataset_json_path data/val/annotations.json --type segm  --iou_thrs 0.1 --out_dir output/directory --export_visual"
      ],
      "metadata": {
        "id": "1HekkJ2hRdtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## coco_test prediction"
      ],
      "metadata": {
        "id": "dzPlm8VdaL_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# arrange an instance segmentation model for test\n",
        "from sahi.utils.mmdet import (\n",
        "    download_mmdet_cascade_mask_rcnn_model,\n",
        "    download_mmdet_config,\n",
        ")\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi.model import MmdetDetectionModel\n",
        "from sahi.utils.cv import read_image\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "qgWgrbXDaLTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/saidineshpola/QueryInst.git@main"
      ],
      "metadata": {
        "id": "8ja_oczRauog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model = MmdetDetectionModel(\n",
        "    model_path='/content/drive/MyDrive/log_mmdetQuery/epoch_22.pth',\n",
        "    config_path='/content/drive/MyDrive/log_mmdetQuery/query_large.py',\n",
        "    confidence_threshold=0.1,\n",
        "    device='cuda:0'\n",
        ")\n",
        "import tempfile\n",
        "import json, os\n",
        "annotation_path = os.path.join(\"data\", \"val/annotations.json\")\n",
        "json_file = open(annotation_path)\n",
        "coco = json.load(json_file)\n",
        "\n",
        "with open(\"classes.json\",'w') as f:\n",
        "    json.dump(coco[\"categories\"],f)\n",
        "\n"
      ],
      "metadata": {
        "id": "mimaZMNkZCdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import mmcv\n",
        "def create_test_predictions(images_path):\n",
        "    #test_predictions_file = tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\")\n",
        "    annotations = {'categories': [], 'info': {}, 'images': []}\n",
        "    for item in glob.glob(images_path+'/*.jpg'):\n",
        "        image_dict = dict()\n",
        "        img = mmcv.imread(item)\n",
        "        height,width,__ = img.shape\n",
        "        #print(item)\n",
        "        if len(os.path.basename(item).split('.')[0]) > 10:\n",
        "          print('big value')\n",
        "          continue\n",
        "        id = int(str(os.path.basename(item).split('.')[0]))\n",
        "        image_dict['id'] = id\n",
        "        image_dict['file_name'] = os.path.basename(item)\n",
        "        image_dict['width'] = width\n",
        "        image_dict['height'] = height\n",
        "        annotations['images'].append(image_dict)\n",
        "    annotations['categories'] = json.loads(open(\"classes.json\").read())\n",
        "    print(len(annotations['images']))\n",
        "    json.dump(annotations, open('test_predictions_file.json', 'w'))\n",
        "food_item='65' #brocoli    \n",
        "create_test_predictions(f'/content/viper/Images/{food_item}')\n",
        "#food_item='broccoli'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEE98IDtbXbP",
        "outputId": "afd34db5-7469-490f-83fa-69066320fad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big value\n",
            "big value\n",
            "big value\n",
            "big value\n",
            "172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import glob\n",
        "import json\n",
        "import cv2\n",
        "from pycocotools import mask\n",
        "result_list=[]\n",
        "from tqdm import tqdm\n",
        "img_ids=[]\n",
        "count=0\n",
        "for image in tqdm(glob.glob(f'/content/viper/Images/{food_item}/*.jpg')):\n",
        "  h,w=cv2.imread(image).shape[:2]\n",
        "  result = get_prediction(image, detection_model)\n",
        "  if len(os.path.basename(image).split('.')[0]) > 10:\n",
        "          print('big value')\n",
        "          continue\n",
        "  id = int(os.path.basename(image).split('.')[0])\n",
        "  result=result.to_coco_predictions(image_id=id) #[0]\n",
        "  # print(result)\n",
        "\n",
        "  # break\n",
        "  for _ in result:\n",
        "    # This is for food101-cheesecake\n",
        "    if _['category_name']=='shrimp_prawn': #food_item:\n",
        "      result_list.append(_)\n",
        "      count=count+1\n",
        "      print(f'found {count}')\n",
        "    # if _['segmentation']: #isinstance(_, 'segmentation'):\n",
        "    #   mask_poly=_['segmentation']\n",
        "    #   _.pop('segmentation', None)\n",
        "    # _['segmentation']=mask.merge(mask.frPyObjects(mask_poly, h, w))\n",
        "    # result_list.append(_)\n"
      ],
      "metadata": {
        "id": "vADO0ce2ZptM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################## converting 0:323 ids into category Ids\n",
        "print(len(result_list))\n",
        "with open('/content/classes.json') as f:\n",
        "  classes=json.load(f)\n",
        "#newlist = sorted(classes, key=lambda d: d['id'])  \n",
        "class_to={}\n",
        "for i,x in enumerate(classes):\n",
        "  class_to[str(i)]=str(x['id'])\n",
        "  # print(x['id'],i)\n",
        "  # break"
      ],
      "metadata": {
        "id": "eChw1vteRRDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_item='shrimp_prawn'"
      ],
      "metadata": {
        "id": "TvcmAOH-PD0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/classes.json') as f:\n",
        "#   classes=json.load(f)\n",
        "for i,each in enumerate(classes):\n",
        "  if each['name']==food_item:\n",
        "    print(each)\n",
        "    print(i)\n",
        "    print(result_list[0]['category_id'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84805_Wwb2Wf",
        "outputId": "b3e0ff48-8037-421e-fd7b-66c1e4226c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 101279, 'name': 'shrimp_prawn', 'name_readable': 'shrimp_prawn', 'supercategory': 'food'}\n",
            "26\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## saving pred file \n",
        "print(result_list[0]['category_id']  )\n",
        "for each in result_list:\n",
        "  each['category_id']=int(class_to[str(each['category_id'])])\n",
        "  #print(each)\n",
        "  # break\n",
        "print(result_list[0]['category_id'] ) \n",
        "\n",
        "with open('/content/test_predictions_file.json','r') as f:\n",
        "  result_coco=json.load(f)\n",
        "result_coco['annotations']=result_list\n",
        "with open(f'/content/drive/MyDrive/Preds/{food_item}.json','w') as f:\n",
        "  json.dump(result_coco,f)\n",
        "print(f\"{food_item}.json file saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU9qTR45PSZX",
        "outputId": "2279fbaf-e8fe-43d9-a812-dc846e976ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "101279\n",
            "shrimp_prawn.json file saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/Preds/query_ep22_test_preds_coco_th0.1.json','r') as f:\n",
        "  result_coco=json.load(f)\n",
        "#result_coco = json.load('/content/test_predictions_file.json')\n",
        "#result_coco['annotations']=result_list"
      ],
      "metadata": {
        "id": "l7TpdTkvhlc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in result_coco:\n",
        "  print(len(result_coco[key]))\n",
        "  print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vPLO0C2adFH",
        "outputId": "35e4f1d3-643d-44cc-e749-dc71325a4f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323\n",
            "categories\n",
            "0\n",
            "info\n",
            "2819\n",
            "images\n",
            "25095\n",
            "annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each in result_coco['annotations']:\n",
        "  each['category_id']=class_to[str(each['category_id'])]\n"
      ],
      "metadata": {
        "id": "B4KumvczZwLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_coco['annotations'][4]['category_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgKy2PEzCzUu",
        "outputId": "ec2a5ed9-6e66-417a-b313-ce373a663641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101254"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Preds/query_ep22_test_preds_coco_th0.1_new.json','w') as f:\n",
        "  json.dump(result_coco,f)"
      ],
      "metadata": {
        "id": "CqeLNnpAEQrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes from food dataset\n",
        "classes=['apple_pie','cheesecake 100958','chocolate_cake','falafel','fish_and_chips','greek_salad','guacamole','hamburger','lasagna',\n",
        "         'omelette','onion_rings'\n",
        "         'pancakes','','','','spring_rolls','sushi','tiramisu']"
      ],
      "metadata": {
        "id": "-JwaXibOFpp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Food101"
      ],
      "metadata": {
        "id": "BkXYEoFFKpET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O food101.tar.gz 'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz'\n",
        "!tar -xvf *.gz"
      ],
      "metadata": {
        "id": "AcXfzDBhKDVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O viper.zip 'https://lorenz.ecn.purdue.edu/~vfn/vfn_1_0.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHRXjCngJNwV",
        "outputId": "f5d4cf3b-2be6-49aa-ea4a-53fae2f43967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-01 15:02:54--  https://lorenz.ecn.purdue.edu/~vfn/vfn_1_0.zip\n",
            "Resolving lorenz.ecn.purdue.edu (lorenz.ecn.purdue.edu)... 128.46.69.116\n",
            "Connecting to lorenz.ecn.purdue.edu (lorenz.ecn.purdue.edu)|128.46.69.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2747826050 (2.6G) [application/zip]\n",
            "Saving to: ‚Äòviper.zip‚Äô\n",
            "\n",
            "viper.zip           100%[===================>]   2.56G  88.9MB/s    in 30s     \n",
            "\n",
            "2022-05-01 15:03:24 (87.6 MB/s) - ‚Äòviper.zip‚Äô saved [2747826050/2747826050]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip *.zip"
      ],
      "metadata": {
        "id": "Xul_je5ZJVxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\n",
        "    model_type = \"mmdet\",\n",
        "    model_path='/content/drive/MyDrive/log_mmdetQuery/epoch_22.pth',\n",
        "    model_config_path='/content/drive/MyDrive/log_mmdetQuery/query_large.py',\n",
        "    model_device='cuda:0',\n",
        "    model_confidence_threshold=0.01,\n",
        "    source='/content/data/test/images',\n",
        "    slice_height=512,\n",
        "    slice_width=512,\n",
        "    overlap_height_ratio=0.2,\n",
        "    overlap_width_ratio=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "4Z2IRZZWJiK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ViSLsRVBnzAG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oswZEmthIcAf",
        "Q4Uwa47-XuNu",
        "pZ0LiLXFI9k4",
        "4-rglUXYaB8g",
        "_TOQaXMDfWo4",
        "1pEFUeZH1JEp",
        "SPmik-f4VE-W",
        "2A8_s1WAv29h",
        "iwrJY9SekxTi",
        "79sTIvs15Dn5",
        "6_unLu4QUaB5",
        "_DZypqZS0GVD",
        "0PKWw5xpLZB5",
        "fxkRJocSI6li",
        "8aRgmsuQPBUJ",
        "wJnxrSS0PZAp",
        "gKuN7XOKJFT2"
      ],
      "machine_shape": "hm",
      "name": "Copy of queryInst for testing-mmdet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}